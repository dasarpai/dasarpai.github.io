<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on </title>
    <link>http://localhost:1313/tags/python/</link>
    <description>Recent content in Python on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <managingEditor>hari@dasarpai.com (Dr. Hari Thapliyaal)</managingEditor>
    <webMaster>hari@dasarpai.com (Dr. Hari Thapliyaal)</webMaster>
    <copyright>© 2025 Dr. Hari Thapliyaal</copyright>
    <lastBuildDate>Thu, 17 Oct 2024 00:00:00 +0000</lastBuildDate><atom:link href="http://localhost:1313/tags/python/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Understanding HTML Templating with Python, Ruby, and PHP</title>
      <link>http://localhost:1313/dsblog/Understanding-HTML-Templating-with-Python-Ruby-PHP/</link>
      <pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Understanding-HTML-Templating-with-Python-Ruby-PHP/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../assets/images/dspost/dsp6164-Understanding-HTML-Templating-with-Python-Ruby-PHP.jpg&#34; alt=&#34;Understanding HTML Templating with Python, Ruby, and PHP&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Understanding HTML Templating with Python, Ruby, and PHP 
    &lt;div id=&#34;understanding-html-templating-with-python-ruby-and-php&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#understanding-html-templating-with-python-ruby-and-php&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What is HTML Templating? 
    &lt;div id=&#34;what-is-html-templating&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-html-templating&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;This concept is widely used across different frameworks and languages to build dynamic, server-rendered web applications.&lt;/p&gt;
&lt;p&gt;The concept of mixing a programming or scripting language with HTML is commonly referred to as &lt;strong&gt;&amp;ldquo;Server-Side Templating&amp;rdquo;&lt;/strong&gt; or &lt;strong&gt;&amp;ldquo;Embedding Server-Side Code in HTML&amp;rdquo;&lt;/strong&gt;. This approach allows dynamic generation of web pages by combining HTML (for structure and presentation) with server-side logic (like PHP, Python, Ruby, etc.) to create dynamic content.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Exploring Python Package Manager</title>
      <link>http://localhost:1313/dsblog/Exploring-Python-Package-Manager/</link>
      <pubDate>Mon, 14 Oct 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Exploring-Python-Package-Manager/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../assets/images/dspost/dsp6161-Exploring-Python-Package-Managers.jpg&#34; alt=&#34;Exploring Python Package Managers&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Exploring Python Package Managers 
    &lt;div id=&#34;exploring-python-package-managers&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#exploring-python-package-managers&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What is Package Manager? 
    &lt;div id=&#34;what-is-package-manager&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-package-manager&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;A &lt;strong&gt;package manager&lt;/strong&gt; is a tool that automates the process of installing, upgrading, configuring, and removing software packages (libraries, frameworks, tools, etc.). It helps manage dependencies between packages and ensures that the correct versions are installed.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Python Code Snippnet from Colab</title>
      <link>http://localhost:1313/dsblog/Python-Code-Snippnet-from-Colab/</link>
      <pubDate>Mon, 30 Sep 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Python-Code-Snippnet-from-Colab/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../assets/images/dspost/dsp6149-Python-Code-Snippnet-from-Colab.jpg&#34; alt=&#34;Python Code Snippnet from Colab&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Python Code Snippnet from Colab 
    &lt;div id=&#34;python-code-snippnet-from-colab&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#python-code-snippnet-from-colab&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What is snippet? 
    &lt;div id=&#34;what-is-snippet&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-snippet&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;A &lt;strong&gt;snippet&lt;/strong&gt; is a small, reusable piece of code designed to perform a specific task or solve a particular problem. It’s often just a few lines long and is meant to be quickly inserted into a larger program to save time or avoid re-writing commonly used functions.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Python Project Folders and Files</title>
      <link>http://localhost:1313/dsblog/Python-Project-Folders-and-Files/</link>
      <pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Python-Project-Folders-and-Files/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../assets/images/dspost/dsp6145-Python-Project-Folders-and-Files.jpg&#34; alt=&#34;Python Project Folders and Files&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Understanding Python Project Folder Structures: Essential Directories Explained 
    &lt;div id=&#34;understanding-python-project-folder-structures-essential-directories-explained&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#understanding-python-project-folder-structures-essential-directories-explained&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Introduction 
    &lt;div id=&#34;introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;In Python projects, certain folders and files serve specific purposes to help with organizing code, managing dependencies, setting up environments, and handling version control. These important directories and files are often seen in most well-structured Python projects. Here are some of the most common ones:&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Decoding pip install operations</title>
      <link>http://localhost:1313/dsblog/Decoding-pip-install-operations/</link>
      <pubDate>Sat, 29 Jun 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Decoding-pip-install-operations/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../assets/images/dspost/dsp6118-Decoding-pip-install-operations.jpg&#34; alt=&#34;Decoding-pip-install-operations&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Decoding pip install operations 
    &lt;div id=&#34;decoding-pip-install-operations&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#decoding-pip-install-operations&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;Your draft provides useful insights into using &lt;code&gt;pip&lt;/code&gt; for Python package management. Here&amp;rsquo;s a refined version of your article with improved structure, grammar, and clarity:&lt;/p&gt;
&lt;hr&gt;


&lt;h3 class=&#34;relative group&#34;&gt;Managing Python Environments and Packages with &lt;code&gt;pip&lt;/code&gt; 
    &lt;div id=&#34;managing-python-environments-and-packages-with-pip&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#managing-python-environments-and-packages-with-pip&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h3&gt;
&lt;p&gt;In today&amp;rsquo;s technology landscape, where we deal with numerous programming languages, diverse hardware (CPU, GPU, TPU, etc.), various operating systems, and an extensive open-source community, building software from scratch can be quite challenging. Even when leveraging existing packages or solutions, there are still numerous challenges to consider, including security, safety, and privacy concerns.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Python APIs for Data</title>
      <link>http://localhost:1313/dsblog/python-apis-for-data/</link>
      <pubDate>Mon, 28 Aug 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/python-apis-for-data/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../assets/images/dspost/dsp6094-Python-APIs-for-Data.jpg&#34; alt=&#34;Python APIs for Data&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Python APIs for Data 
    &lt;div id=&#34;python-apis-for-data&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#python-apis-for-data&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bing.com/&#34; target=&#34;_blank&#34;&gt;Bing&lt;/a&gt; Bing is a search engine that brings together the best of search and people in your social networks to help you spend less time searching and more time doing.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.bing.com/dev/en-us/dev-center&#34; target=&#34;_blank&#34;&gt;Api Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://code.google.com/p/pybing/&#34; target=&#34;_blank&#34;&gt;Python wrapper for the Bing search API&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;http://www.bitly.com/&#34; target=&#34;_blank&#34;&gt;Bitly&lt;/a&gt; URL shortening and bookmarking service&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://dev.bitly.com/get_started.html&#34; target=&#34;_blank&#34;&gt;Api Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://code.google.com/p/python-bitly/&#34; target=&#34;_blank&#34;&gt;Python wrapper around the bit.ly API&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://blogger.com/&#34; target=&#34;_blank&#34;&gt;Blogger&lt;/a&gt; Blog-publishing service&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>AWS SageMaker Jumpstart Models</title>
      <link>http://localhost:1313/dsblog/AWS-SageMaker-Jumpstart-Models/</link>
      <pubDate>Tue, 18 Jul 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/AWS-SageMaker-Jumpstart-Models/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../assets/images/dspost/dsp6076-AWS-SageMaker-Jumpstart-Models.jpg&#34; alt=&#34;AWS SageMaker Jumpstart Models&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;AWS SageMaker Jumpstart Models 
    &lt;div id=&#34;aws-sagemaker-jumpstart-models&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#aws-sagemaker-jumpstart-models&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;As of 17-Jul-23, AWS Sagemaker has 463 models in its Model Zoo. They call these models as Jumstart Models. What are the capabilities of these models, who are the developer of these models, where these models are hosted in given in the table below.&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;SNo.&lt;/th&gt;
          &lt;th&gt;Task Type&lt;/th&gt;
          &lt;th&gt;Company&lt;/th&gt;
          &lt;th&gt;Model Description&lt;/th&gt;
          &lt;th&gt;Model ID&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;1.&lt;/td&gt;
          &lt;td&gt;Text Generation&lt;/td&gt;
          &lt;td&gt;Huggingface&lt;/td&gt;
          &lt;td&gt;Falcon-40B-Instruct is a 40B parameters causal decoder-only model built by TII based on Falcon-40B and finetuned on a mixture of Baize It is ready-to-use chat/instruct model based on Falcon 40B&lt;/td&gt;
          &lt;td&gt;Model draft: false&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;id: huggingface-textgeneration-falcon-40b-instruct-bf16
|2. |Text Generation |Huggingface |This is a Text Generation model built upon a Transformer model from Hugging Face |Model draft: false
id: huggingface-textgeneration-open-llama
|3. |Text to Image |StabilityAI |Extend beyond just text-to-image prompting. Stable Diffusion XL offers several ways to modify the images: Inpainting - edit inside the image, Outpainting - extend the image outside of the original image, Image-to-image - prompt a new image using a sourced image. |
|4. |Text Generation |Cohere |Generative model that responds well with instruction-like prompts. This model provides businesses and enterprises with best quality, performance and accuracy in all generative tasks. And with our intuitive SDK, unlocking the full potential of LLMs for your applications has never been easier. |
|5. |Text Generation |AI21 Labs |Jurassic-2 Ultra is optimized to follow natural language instructions and context, so there is no need to provide it with any examples. |
|6. |Text Generation |AI21 Labs | |
|7. |Text Generation |AI21 Labs |Condense lengthy texts into short, easy-to-read bites that remain factually consistent with the source. No prompting needed – simply input the text that needs to be summarized. The model is specifically trained to generate summaries that capture the essence and key ideas of the original text. |
|8. |Text Generation |AI21 Labs |Get the AI21 Paraphrase model, the top-of-the-line paraphrasing engine, and deploy it in your private environment. The model aims to generate 10 alternative suggestions with every activation. It may return fewer suggestions when rewriting very short texts for which it cannot produce as many as 10 sensible paraphrases. |
|9. |Text Generation |AI21 Labs |Jurassic-2 Mid is optimized to follow natural language instructions and context, so there is no need to provide it with any examples. Pre-trained language model trained by AI21 Labs on a corpus of web text including natural language and computer programs with recent data - updated to mid 2022. This model has a 8192 token context window (i.e. the length of the prompt + completion should be at most 8192 tokens). |
|10. |Text Generation |AI21 Labs |Detects and suggests corrections for Grammar, Spelling, Punctuation mistakes, as well as word misuse, and accidental repetition or omission. |
|11. |Text to Image |StabilityAI |Extend beyond just text-to-image prompting. Stable Diffusion XL offers several ways to modify the images: Inpainting - edit inside the image, Outpainting - extend the image outside of the original image, Image-to-image - prompt a new image using a sourced image. |
|12. |Text to Image |Stabilityai |This is a text-to-image model from Stability AI and downloaded from HuggingFace It takes a textual description as input and returns a generated image from the description |Model draft: false
id: model-txt2img-stabilityai-stable-diffusion-v2-1-base
|13. | |Huggingface |This is a Text2Text Generation model built upon a T5 model from Hugging Face The deployed model can be used for running inference on any input text |Model draft: false
id: huggingface-text2text-flan-t5-xl
|14. | |Huggingface |This is a Text Generation model built upon a Transformer model from Hugging Face It takes a text string as input and predicts next words in the sequence |Model draft: false
id: huggingface-textgeneration1-gpt-j-6b
|15. | |Huggingface |This is a Text2Text Generation model built upon a T5 model from Hugging Face The deployed model can be used for running inference on any input text |Model draft: false
id: huggingface-text2text-flan-ul2-bf16
|16. |Text Generation |Pytorch |AlexaTM 20B is a multitask, multilingual, large-scale sequence-to-sequence (seq2seq) model, trained on a mixture of Common Crawl (mC4) and Wikipedia data across 12 languages, using denoising and Causal Language Modeling (CLM) tasks |Model draft: false
id: pytorch-textgeneration1-alexa20b
|17. |Text Generation |Huggingface |This is a Text Generation model built upon a Transformer model from Hugging Face It takes a text string as input and predicts next words in the sequence |Model draft: false
id: huggingface-textgeneration-bloom-1b7
|18. |Image Classification |Tensorflow |This is an Image Classification model from TensorFlow Hub It takes an image as input and classifies the image to one of the 1001 classes |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v2-100-224-classification-4
|19. |Object Detection |Tensorflow |This is an object detection model from Tensorflow It takes an image as input and returns bounding boxes for the objects in the image |Model draft: false
id: tensorflow-od1-ssd-resnet50-v1-fpn-640x640-coco17-tpu-8
|20. |Object Detection |Pytorch |This is an object detection model from PyTorch Hub It takes an image as input and returns bounding boxes for the objects in the image |Model draft: false
id: pytorch-od1-fasterrcnn-resnet50-fpn
|21. |Text Classification |Tensorflow |This is a Text Classification model built upon a Text Embedding model from TensorFlow Hub It takes a text string as input and classifies the input text as either a positive or negative movie review |Model draft: false
id: tensorflow-tc-bert-en-uncased-L-12-H-768-A-12-2
|22. |Question Answering |Huggingface |This is an Extractive Question Answering model built on a Transformer model from Hugging Face It takes two strings as inputs: the first string is a question and the second string is the context or any text you want to use to find the answer of the question, and it returns a sub-string from the context as an answer to the question |Model draft: false
id: huggingface-eqa-distilbert-base-uncased
|23. |Zero-Shot Text Classification |Huggingface |This is Zero Shot Text Classification model built on a Transformer model from Hugging Face It can classify sentences in English language It takes a sequence and a list of candidate labels as inputs and predicts score that the sequence is associated with the particular label |Model draft: false
id: huggingface-zstc-facebook-bart-large-mnli
|24. |Semantic Segmentation |Mxnet |This is an Semantic Segmentation model from Gluon CV It takes an image as input and returns class label for each pixel in the image |Model draft: false
id: mxnet-semseg-fcn-resnet101-coco
|25. |Sentence Pair Classification |Huggingface |This is a Sentence Pair Classification model built upon a Text Embedding model from Hugging Face It takes a pair of sentences as input and classifies the input pair to &amp;rsquo;entailment&amp;rsquo; or &amp;rsquo;no-entailment&amp;rsquo; |Model draft: false
id: huggingface-spc-distilbert-base-uncased
|26. |Named Entity Recognition |Huggingface |This is a Named Entity Generation model built upon a Transformer model from Hugging Face It takes a text string as input and predicts named entities in the input text |Model draft: false
id: huggingface-ner-distilbert-base-cased-finetuned-conll03-english
|27. |Text Summarization |Huggingface |This is a Text Summarization model built upon a Transformer model from Hugging Face It takes a text string as input and returns a summary of the text |Model draft: false
id: huggingface-summarization-distilbart-xsum-1-1
|28. |Machine Translation |Huggingface |This is a Machine Translation model built upon a Transformer model from Hugging Face It takes a text string as input and predicts its translation |Model draft: false
id: huggingface-translation-t5-small
|29. |Text Embedding |Tensorflow |This is a Text Embedding model from TensorFlow Hub It takes a text string as input and outputs an embedding vector The Text Embedding model is pre-trained on Wikipedia and BookCorpus datasets |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-2-H-128-A-2-2
|30. |Text Embedding |Mxnet |This is a Text Embedding model from GluonNLP pre-trained on the decade (2010-2019) of S&amp;amp;P 500 10-K/10-Q reports It takes a text string as input and outputs an embedding vector For pre-training, the entire text of the 10K/Q filing was used, not just the MD&amp;amp;A (Management Discussion and Analysis) section, so as to ensure that a broader context of financial language is captured Embeddings from the pre-trained modelare then used for fine-tuning specific classifiers |Model draft: false
id: mxnet-tcembedding-robertafin-base-uncased
|31. |Sentence Pair Classification |Tensorflow |This is a Sentence Pair Classification model built upon a Text Embedding model from TensorFlow Hub It takes a pair of sentences as input and classifies the input pair to &amp;rsquo;entailment&amp;rsquo; or &amp;rsquo;no-entailment&amp;rsquo; |Model draft: false
id: tensorflow-spc-bert-en-uncased-L-12-H-768-A-12-2
|32. |Instance Segmentation |Mxnet |This is an Instance Segmentation model from Gluon CV It detects and delineates each distinct object in the image |Model draft: false
id: mxnet-is-mask-rcnn-fpn-resnet101-v1d-coco
|33. |Image Embedding |Tensorflow |This is an Image Feature Vector model from TensorFlow Hub It takes an image as input and returns a feature vector (embedding) of the image |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v2-100-224-featurevector-4
|34. |Image Classification |Pytorch |This is an Image Classification model from PyTorch Hub It takes an image as input and classifies the image to one of the 1000 classes |Model draft: false
id: pytorch-ic-mobilenet-v2
|35. |Object Detection |Mxnet |This is an object detection model from Gluon CV It takes an image as input and returns bounding boxes for the objects in the image |Model draft: false
id: mxnet-od-ssd-512-mobilenet1-0-coco
|36. |Object Detection |Tensorflow |This is an object detection model from TensorFlow Hub It takes an image as input and returns bounding boxes for the objects in the image |Model draft: false
id: tensorflow-od-ssd-mobilenet-v2-fpnlite-320x320-1
|37. |Object Detection |Pytorch |This is an object detection model from PyTorch Hub It takes an image as input and returns bounding boxes for the objects in the image |Model draft: false
id: pytorch-od-nvidia-ssd
|38. |Image Classification |Tensorflow |This is an Image Classification model from TensorFlow Hub It takes an image as input and classifies the image to one of the 1001 classes |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v2-075-224-classification-4
|39. |Image Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v2-050-224-classification-4
|40. |Image Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v2-035-224-classification-4
|41. |Image Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v2-140-224-classification-4
|42. |Image Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v2-130-224-classification-4
|43. |Object Detection |Pytorch |This is an object detection model from PyTorch Hub It takes an image as input and returns bounding boxes for the objects in the image |Model draft: false
id: pytorch-od1-fasterrcnn-mobilenet-v3-large-320-fpn
|44. |Object Detection |Pytorch |Same |Model draft: false
id: pytorch-od1-fasterrcnn-mobilenet-v3-large-fpn
|45. |Semantic Segmentation |Mxnet |This is an Semantic Segmentation model from Gluon CV It takes an image as input and returns class label for each pixel in the image |Model draft: false
id: mxnet-semseg-fcn-resnet101-voc
|46. |Semantic Segmentation |Mxnet |Same as above |Model draft: false
id: mxnet-semseg-fcn-resnet101-ade
|47. |Instance Segmentation |Mxnet |Same as above |Model draft: false
id: mxnet-semseg-fcn-resnet50-ade
|48. |Image Classification |Pytorch |This is an Image Classification model from PyTorch Hub It takes an image as input and classifies the image to one of the 1000 classes |Model draft: false
id: pytorch-ic-resnet18
|49. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-resnet34
|50. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-resnet50
|51. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-resnet101
|52. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-resnet152
|53. |Object Detection |Mxnet |This is an object detection model from Gluon CV It takes an image as input and returns bounding boxes for the objects in the image |Model draft: false
id: mxnet-od-ssd-512-mobilenet1-0-voc
|54. |Object Detection |Mxnet |Same |Model draft: false
id: mxnet-od-ssd-512-resnet50-v1-coco
|55. |Object Detection |Mxnet |Same |Model draft: false
id: mxnet-od-ssd-512-resnet50-v1-voc
|56. |Object Detection |Mxnet |Same |Model draft: false
id: mxnet-od-ssd-300-vgg16-atrous-coco
|57. |Object Detection |Mxnet |Same |Model draft: false
id: mxnet-od-ssd-300-vgg16-atrous-voc
|58. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od1-ssd-efficientdet-d0-512x512-coco17-tpu-8
|59. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od1-ssd-efficientdet-d1-640x640-coco17-tpu-8
|60. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od1-ssd-efficientdet-d2-768x768-coco17-tpu-8
|61. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od1-ssd-efficientdet-d3-896x896-coco17-tpu-32
|62. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od1-ssd-mobilenet-v1-fpn-640x640-coco17-tpu-8
|63. |Instance Segmentation |Mxnet |This is an Instance Segmentation model from Gluon CV It detects and delineates each distinct object in the image |Model draft: false
id: mxnet-is-mask-rcnn-fpn-resnet50-v1b-coco
|64. |Instance Segmentation |Mxnet |Same |Model draft: false
id: mxnet-is-mask-rcnn-fpn-resnet18-v1b-coco
|65. | |Mxnet |Same |Model draft: false
id: mxnet-is-mask-rcnn-resnet18-v1b-coco
|66. |Image Embedding |Tensorflow |This is an Image Feature Vector model from TensorFlow Hub It takes an image as input and returns a feature vector (embedding) of the image |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v2-075-224-featurevector-4
|67. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v2-050-224-featurevector-4
|68. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v2-035-224-featurevector-4
|69. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v2-140-224-featurevector-4
|70. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v2-130-224-featurevector-4
|71. |Object Detection |Tensorflow |This is an object detection model from TensorFlow Hub It takes an image as input and returns bounding boxes for the objects in the image |Model draft: false
id: tensorflow-od-ssd-mobilenet-v2-fpnlite-640x640-1
|72. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-ssd-mobilenet-v2-2
|73. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-ssd-mobilenet-v1-fpn-640x640-1
|74. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-faster-rcnn-resnet50-v1-640x640-1
|75. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-faster-rcnn-resnet50-v1-800x1333-1
|76. |Zero-Shot Text Classification |Huggingface |This is Zero Shot Text Classification model built on a Transformer model from Hugging Face It can classify sentences in English language It takes a sequence and a list of candidate labels as inputs and predicts score that the sequence is associated with the particular label |Model draft: false
id: huggingface-zstc-narsil-deberta-large-mnli-zero-cls
|77. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-moritzlaurer-deberta-v3-large-mnli-fever-anli-ling-wanli
|78. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-cross-encoder-nli-distilroberta-base
|79. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-recognai-bert-base-spanish-wwm-cased-xnli
|80. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-moritzlaurer-mdeberta-v3-base-xnli-multilingual-nli-2mil7
|81. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-cross-encoder-nli-roberta-base
|82. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-cross-encoder-nli-deberta-base
|83. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-cross-encoder-nli-minilm2-l6-h768
|84. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-recognai-zeroshot-selectra-medium
|85. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-navteca-bart-large-mnli
|86. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-jiva-xlm-roberta-large-it-mnli
|87. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-digitalepidemiologylab-covid-twitter-bert-v2-mnli
|88. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-recognai-zeroshot-selectra-small
|89. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-emrecan-distilbert-base-turkish-cased-snli-tr
|90. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-emrecan-bert-base-turkish-cased-allnli-tr
|91. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-emrecan-bert-base-turkish-cased-snli-tr
|92. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-emrecan-bert-base-multilingual-cased-allnli-tr
|93. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-narsil-bart-large-mnli-opti
|94. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-emrecan-convbert-base-turkish-mc4-cased-allnli-tr
|95. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-lighteternal-nli-xlm-r-greek
|96. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-emrecan-distilbert-base-turkish-cased-allnli-tr
|97. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-emrecan-bert-base-multilingual-cased-multinli-tr
|98. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-eleldar-theme-classification
|99. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-emrecan-bert-base-turkish-cased-multinli-tr
|100. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-emrecan-bert-base-multilingual-cased-snli-tr
|101. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-emrecan-convbert-base-turkish-mc4-cased-multinli-tr
|102. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-emrecan-distilbert-base-turkish-cased-multinli-tr
|103. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-emrecan-convbert-base-turkish-mc4-cased-snli-tr
|104. |Image Classification |Tensorflow |This is an Image Classification model from TensorFlow Hub It takes an image as input and classifies the image to one of the 1001 classes |Model draft: false
id: tensorflow-ic-tf2-preview-mobilenet-v2-classification-4
|105. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-inception-v3-classification-4
|106. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-inception-v2-classification-4
|107. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-inception-v1-classification-4
|108. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-tf2-preview-inception-v3-classification-4
|109. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-inception-resnet-v2-classification-4
|110. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-resnet-v2-50-classification-4
|111. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-resnet-v2-101-classification-4
|112. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-resnet-v2-152-classification-4
|113. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-resnet-v1-50-classification-4
|114. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-resnet-v1-101-classification-4
|115. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-resnet-v1-152-classification-4
|116. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-resnet-50-classification-1
|117. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-efficientnet-b0-classification-1
|118. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-efficientnet-b1-classification-1
|119. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-efficientnet-b2-classification-1
|120. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-efficientnet-b3-classification-1
|121. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-efficientnet-b4-classification-1
|122. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-efficientnet-b5-classification-1
|123. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-efficientnet-b6-classification-1
|124. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-efficientnet-b7-classification-1
|125. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-efficientnet-lite0-classification-2
|126. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-efficientnet-lite1-classification-2
|127. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-efficientnet-lite2-classification-2
|128. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-efficientnet-lite3-classification-2
|129. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-efficientnet-lite4-classification-2
|130. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v1-100-224-classification-4
|131. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v1-100-192-classification-4
|132. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v1-100-160-classification-4
|133. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v1-100-128-classification-4
|134. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v1-075-224-classification-4
|135. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v1-075-192-classification-4
|136. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v1-075-160-classification-4
|137. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v1-075-128-classification-4
|138. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v1-050-224-classification-4
|139. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v1-050-192-classification-4
|140. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v1-050-160-classification-4
|141. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v1-050-128-classification-4
|142. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v1-025-224-classification-4
|143. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v1-025-192-classification-4
|144. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v1-025-160-classification-4
|145. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v1-025-128-classification-4
|146. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-bit-s-r50x1-ilsvrc2012-classification-1
|147. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-bit-s-r50x3-ilsvrc2012-classification-1
|148. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-bit-s-r101x1-ilsvrc2012-classification-1
|149. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-bit-s-r101x3-ilsvrc2012-classification-1
|150. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-bit-m-r50x1-ilsvrc2012-classification-1
|151. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-bit-m-r50x3-ilsvrc2012-classification-1
|152. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-bit-m-r101x1-ilsvrc2012-classification-1
|153. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-bit-m-r101x3-ilsvrc2012-classification-1
|154. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-bit-m-r50x1-imagenet21k-classification-1
|155. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-bit-m-r50x3-imagenet21k-classification-1
|156. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-bit-m-r101x1-imagenet21k-classification-1
|157. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-bit-m-r101x3-imagenet21k-classification-1
|158. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-alexnet
|159. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-densenet121
|160. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-densenet169
|161. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-densenet201
|162. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-densenet161
|163. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-resnext50-32x4d
|164. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-resnext101-32x8d
|165. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-shufflenet-v2-x1-0
|166. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-squeezenet1-0
|167. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-squeezenet1-1
|168. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-vgg11
|169. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-vgg11-bn
|170. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-vgg13
|171. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-vgg13-bn
|172. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-vgg16
|173. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-vgg16-bn
|174. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-vgg19
|175. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-vgg19-bn
|176. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-wide-resnet50-2
|177. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-wide-resnet101-2
|178. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-googlenet
|179. |Object Detection |Mxnet |This is an object detection model from Gluon CV It takes an image as input and returns bounding boxes for the objects in the image |Model draft: false
id: mxnet-od-ssd-512-vgg16-atrous-coco
|180. |Object Detection |Mxnet |Same |Model draft: false
id: mxnet-od-ssd-512-vgg16-atrous-voc
|181. |Object Detection |Mxnet |Same |Model draft: false
id: mxnet-od-yolo3-darknet53-voc
|182. |Object Detection |Mxnet |Same |Model draft: false
id: mxnet-od-yolo3-mobilenet1-0-voc
|183. |Object Detection |Mxnet |Same |Model draft: false
id: mxnet-od-yolo3-darknet53-coco
|184. |Object Detection |Mxnet |Same |Model draft: false
id: mxnet-od-yolo3-mobilenet1-0-coco
|185. |Object Detection |Mxnet |Same |Model draft: false
id: mxnet-od-faster-rcnn-resnet50-v1b-voc
|186. |Object Detection |Mxnet |Same |Model draft: false
id: mxnet-od-faster-rcnn-resnet50-v1b-coco
|187. |Object Detection |Mxnet |Same |Model draft: false
id: mxnet-od-faster-rcnn-resnet101-v1d-coco
|188. |Object Detection |Mxnet |Same |Model draft: false
id: mxnet-od-faster-rcnn-fpn-resnet50-v1b-coco
|189. |Object Detection |Mxnet |Same |Model draft: false
id: mxnet-od-faster-rcnn-fpn-resnet101-v1d-coco
|190. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od1-ssd-mobilenet-v2-fpnlite-320x320-coco17-tpu-8
|191. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od1-ssd-mobilenet-v2-fpnlite-640x640-coco17-tpu-8
|192. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od1-ssd-resnet50-v1-fpn-1024x1024-coco17-tpu-8
|193. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od1-ssd-resnet101-v1-fpn-640x640-coco17-tpu-8
|194. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od1-ssd-resnet101-v1-fpn-1024x1024-coco17-tpu-8
|195. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od1-ssd-resnet152-v1-fpn-640x640-coco17-tpu-8
|196. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od1-ssd-resnet152-v1-fpn-1024x1024-coco17-tpu-8
|197. |Image Embedding |Tensorflow |This is an Image Feature Vector model from TensorFlow Hub It takes an image as input and returns a feature vector (embedding) of the image |Model draft: false
id: tensorflow-icembedding-imagenet-inception-v3-featurevector-4
|198. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-inception-v2-featurevector-4
|199. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-inception-v1-featurevector-4
|200. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-tf2-preview-inception-v3-featurevector-4
|201. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-tf2-preview-mobilenet-v2-featurevector-4
|202. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-resnet-v2-50-featurevector-4
|203. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-resnet-v2-101-featurevector-4
|204. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-resnet-v2-152-featurevector-4
|205. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-resnet-v1-50-featurevector-4
|206. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-resnet-v1-101-featurevector-4
|207. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-resnet-v1-152-featurevector-4
|208. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-resnet-50-featurevector-1
|209. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-efficientnet-b0-featurevector-1
|210. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-efficientnet-b1-featurevector-1
|211. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-efficientnet-b2-featurevector-1
|212. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-efficientnet-b3-featurevector-1
|213. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-efficientnet-b6-featurevector-1
|214. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-efficientnet-lite0-featurevector-2
|215. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-efficientnet-lite1-featurevector-2
|216. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-efficientnet-lite2-featurevector-2
|217. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-efficientnet-lite3-featurevector-2
|218. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-efficientnet-lite4-featurevector-2
|219. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v1-100-224-featurevector-4
|220. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v1-100-192-featurevector-4
|221. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v1-100-160-featurevector-4
|222. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v1-100-128-featurevector-4
|223. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v1-075-224-featurevector-4
|224. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v1-075-192-featurevector-4
|225. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v1-075-160-featurevector-4
|226. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v1-075-128-featurevector-4
|227. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v1-050-224-featurevector-4
|228. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v1-050-192-featurevector-4
|229. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v1-050-160-featurevector-4
|230. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v1-050-128-featurevector-4
|231. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v1-025-224-featurevector-4
|232. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v1-025-192-featurevector-4
|233. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v1-025-160-featurevector-4
|234. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v1-025-128-featurevector-4
|235. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-bit-s-r50x1-ilsvrc2012-featurevector-1
|236. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-bit-s-r50x3-ilsvrc2012-featurevector-1
|237. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-bit-s-r101x1-ilsvrc2012-featurevector-1
|238. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-bit-s-r101x3-ilsvrc2012-featurevector-1
|239. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-bit-m-r50x1-ilsvrc2012-featurevector-1
|240. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-bit-m-r50x3-imagenet21k-featurevector-1
|241. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-bit-m-r101x1-ilsvrc2012-featurevector-1
|242. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-bit-m-r101x3-imagenet21k-featurevector-1
|243. |Object Detection |Tensorflow |This is an object detection model from TensorFlow Hub It takes an image as input and returns bounding boxes for the objects in the image |Model draft: false
id: tensorflow-od-faster-rcnn-resnet50-v1-1024x1024-1
|244. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-faster-rcnn-resnet101-v1-640x640-1
|245. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-faster-rcnn-resnet101-v1-800x1333-1
|246. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-faster-rcnn-resnet101-v1-1024x1024-1
|247. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-faster-rcnn-resnet152-v1-640x640-1
|248. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-faster-rcnn-resnet152-v1-800x1333-1
|249. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-faster-rcnn-resnet152-v1-1024x1024-1
|250. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-faster-rcnn-inception-resnet-v2-640x640-1
|251. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-faster-rcnn-inception-resnet-v2-1024x1024-1
|252. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-efficientdet-d0-1
|253. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-efficientdet-d1-1
|254. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-efficientdet-d2-1
|255. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-efficientdet-d3-1
|256. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-efficientdet-d4-1
|257. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-efficientdet-d5-1
|258. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-retinanet-resnet50-v1-fpn-640x640-1
|259. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-retinanet-resnet50-v1-fpn-1024x1024-1
|260. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-retinanet-resnet101-v1-fpn-640x640-1
|261. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-retinanet-resnet101-v1-fpn-1024x1024-1
|262. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-retinanet-resnet152-v1-fpn-640x640-1
|263. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-retinanet-resnet152-v1-fpn-1024x1024-1
|264. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-centernet-hourglass-512x512-1
|265. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-centernet-hourglass-512x512-kpts-1
|266. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-centernet-hourglass-1024x1024-1
|267. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-centernet-hourglass-1024x1024-kpts-1
|268. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-centernet-resnet50v1-fpn-512x512-1
|269. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-centernet-resnet50v1-fpn-512x512-kpts-1
|270. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-centernet-resnet50v2-512x512-1
|271. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-centernet-resnet50v2-512x512-kpts-1
|272. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-centernet-resnet101v1-fpn-512x512-1
|273. |Text Classification |Tensorflow |This is a Text Classification model built upon a Text Embedding model from TensorFlow Hub It takes a text string as input and classifies the input text as either a positive or negative movie review |Model draft: false
id: tensorflow-tc-bert-en-cased-L-12-H-768-A-12-2
|274. |Text Classification |Tensorflow |Same |Model draft: false
id: tensorflow-tc-bert-multi-cased-L-12-H-768-A-12-2
|275. |Text Classification |Tensorflow |Same |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-2-H-128-A-2
|276. |Text Classification |Tensorflow |Same |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-2-H-256-A-4
|277. |Text Classification |Tensorflow |Same |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-2-H-512-A-8
|278. |Question Answering |Huggingface |This is an Extractive Question Answering model built on a Transformer model from Hugging Face It takes two strings as inputs: the first string is a question and the second string is the context or any text you want to use to find the answer of the question, and it returns a sub-string from the context as an answer to the question |Model draft: false
id: huggingface-eqa-distilbert-base-cased
|279. |Question Answering |Huggingface |Same |Model draft: false
id: huggingface-eqa-distilbert-base-multilingual-cased
|280. |Question Answering |Huggingface |Same |Model draft: false
id: huggingface-eqa-bert-base-uncased
|281. |Question Answering |Huggingface |Same |Model draft: false
id: huggingface-eqa-bert-base-cased
|282. |Question Answering |Huggingface |Same |Model draft: false
id: huggingface-eqa-bert-base-multilingual-uncased
|283. |Sentence Pair Classification |Tensorflow |This is a Sentence Pair Classification model built upon a Text Embedding model from TensorFlow Hub It takes a pair of sentences as input and classifies the input pair to &amp;rsquo;entailment&amp;rsquo; or &amp;rsquo;no-entailment&amp;rsquo; |Model draft: false
id: tensorflow-spc-bert-en-cased-L-12-H-768-A-12-2
|284. |Sentence Pair Classification |Tensorflow |Same |Model draft: false
id: tensorflow-spc-bert-multi-cased-L-12-H-768-A-12-2
|285. |Sentence Pair Classification |Tensorflow |Same |Model draft: false
id: tensorflow-spc-bert-en-uncased-L-24-H-1024-A-16-2
|286. |Sentence Pair Classification |Tensorflow |Same |Model draft: false
id: tensorflow-spc-electra-small-1
|287. |Sentence Pair Classification |Tensorflow |Same |Model draft: false
id: tensorflow-spc-electra-base-1
|288. |Sentence Pair Classification |Huggingface |Same |Model draft: false
id: huggingface-spc-distilbert-base-cased
|289. |Sentence Pair Classification |Huggingface |Same |Model draft: false
id: huggingface-spc-distilbert-base-multilingual-cased
|290. |Sentence Pair Classification |Huggingface |Same |Model draft: false
id: huggingface-spc-bert-base-uncased
|291. |Sentence Pair Classification |Huggingface |Same |Model draft: false
id: huggingface-spc-bert-base-cased
|292. |Sentence Pair Classification |Huggingface |Same |Model draft: false
id: huggingface-spc-bert-base-multilingual-uncased
|293. |Named Entity Recognition |Huggingface |This is a Named Entity Generation model built upon a Transformer model from Hugging Face It takes a text string as input and predicts named entities in the input text |Model draft: false
id: huggingface-ner-distilbert-base-uncased-finetuned-conll03-english
|294. |Text Generation |Huggingface |Same |Model draft: false
id: huggingface-textgeneration-bloom-1b1
|295. |Text Generation |Huggingface |Same |Model draft: false
id: huggingface-textgeneration-bloom-560m
|296. |Text Generation |Huggingface |Same |Model draft: false
id: huggingface-textgeneration-gpt2
|297. |Text Generation |Huggingface |Same |Model draft: false
id: huggingface-textgeneration-distilgpt2
|298. |Text Summarization |Huggingface |This is a Text Summarization model built upon a Transformer model from Hugging Face It takes a text string as input and returns a summary of the text |Model draft: false
id: huggingface-summarization-bert-small2bert-small-finetuned-cnn-daily-mail-summarization
|299. |Text Summarization |Huggingface |Same |Model draft: false
id: huggingface-summarization-distilbart-cnn-6-6
|300. |Text Summarization |Huggingface |Same |Model draft: false
id: huggingface-summarization-distilbart-xsum-12-3
|301. |Text Summarization |Huggingface |Same |Model draft: false
id: huggingface-summarization-distilbart-cnn-12-6
|302. |Text Summarization |Huggingface |Same |Model draft: false
id: huggingface-summarization-bart-large-cnn-samsum
|303. |Machine Translation |Huggingface |This is a Machine Translation model built upon a Transformer model from Hugging Face It takes a text string as input and predicts its translation |Model draft: false
id: huggingface-translation-t5-base
|304. |Machine Translation |Huggingface |Same |Model draft: false
id: huggingface-translation-t5-large
|305. |Machine Translation |Huggingface |Same |Model draft: false
id: huggingface-translation-opus-mt-en-es
|306. |Machine Translation |Huggingface |Same |Model draft: false
id: huggingface-translation-opus-mt-en-vi
|307. |Text Embedding |Tensorflow |This is a Text Embedding model from TensorFlow Hub It takes a text string as input and outputs an embedding vector The Text Embedding model is pre-trained on Wikipedia and BookCorpus datasets |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-2-H-256-A-4
|308. |Text Embedding |Tensorflow |same |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-2-H-512-A-8-2
|309. |Text Embedding |Tensorflow |same |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-2-H-768-A-12-2
|310. |Text to Image |Stabilityai |This is a text-to-image model from Stability AI and downloaded from HuggingFace It takes a textual description as input and returns a generated image from the description |Model draft: false
id: model-txt2img-stabilityai-stable-diffusion-v2
|311. |Text Embedding |Tensorflow |This is a Text Embedding model from TensorFlow Hub It takes a text string as input and outputs an embedding vector The Text Embedding model is pre-trained on Wikipedia and BookCorpus datasets |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-4-H-128-A-2-2
|312. |Text Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-4-H-256-A-4-2
|313. |Text Embedding |Mxnet |Same |Model draft: false
id: mxnet-tcembedding-robertafin-base-wiki-uncased
|314. |Text Embedding |Mxnet |Same |Model draft: false
id: mxnet-tcembedding-robertafin-large-uncased
|315. |Text Embedding |Mxnet |Same |Model draft: false
id: mxnet-tcembedding-robertafin-large-wiki-uncased
|316. |Text Classification |Tensorflow |This is a Text Classification model built upon a Text Embedding model from TensorFlow Hub It takes a text string as input and classifies the input text as either a positive or negative movie review |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-2-H-768-A-12
|317. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-4-H-128-A-2
|318. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-4-H-256-A-4
|319. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-4-H-512-A-8
|320. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-4-H-768-A-12
|321. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-6-H-128-A-2
|322. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-6-H-256-A-4
|323. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-6-H-512-A-8
|324. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-6-H-768-A-12
|325. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-8-H-128-A-2
|326. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-8-H-256-A-4
|327. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-8-H-512-A-8
|328. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-8-H-768-A-12
|329. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-10-H-128-A-2
|330. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-10-H-256-A-4
|331. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-10-H-512-A-8
|332. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-10-H-768-A-12
|333. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-12-H-128-A-2
|334. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-12-H-256-A-4
|335. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-12-H-512-A-8
|336. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-12-H-768-A-12
|337. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-bert-en-uncased-L-24-H-1024-A-16-2
|338. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-bert-en-cased-L-24-H-1024-A-16-2
|339. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-bert-en-wwm-uncased-L-24-H-1024-A-16-2
|340. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-bert-en-wwm-cased-L-24-H-1024-A-16-2
|341. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-albert-en-base
|342. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-electra-small-1
|343. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-electra-base-1
|344. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-experts-bert-wiki-books-1
|345. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-experts-bert-pubmed-1
|346. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-talking-heads-base
|347. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-talking-heads-large
|348. |Question Answering |Huggingface |This is an Extractive Question Answering model built on a Transformer model from Hugging Face It takes two strings as inputs: the first string is a question and the second string is the context or any text you want to use to find the answer of the question, and it returns a sub-string from the context as an answer to the question |Model draft: false
id: huggingface-eqa-bert-base-multilingual-cased
|349. |Question Answering |Huggingface |Same as above |Model draft: false
id: huggingface-eqa-bert-large-uncased
|350. |Question Answering |Huggingface |Same as above |Model draft: false
id: huggingface-eqa-bert-large-cased
|351. |Question Answering |Huggingface |Same as above |Model draft: false
id: huggingface-eqa-bert-large-uncased-whole-word-masking
|352. |Question Answering |Huggingface |Same as above |Model draft: false
id: huggingface-eqa-bert-large-cased-whole-word-masking
|353. |Question Answering |Huggingface |Same as above |Model draft: false
id: huggingface-eqa-distilroberta-base
|354. |Question Answering |Huggingface |Same as above |Model draft: false
id: huggingface-eqa-roberta-base
|355. |Question Answering |Huggingface |Same as above |Model draft: false
id: huggingface-eqa-roberta-base-openai-detector
|356. |Question Answering |Huggingface |Same as above |Model draft: false
id: huggingface-eqa-roberta-large
|357. |Sentence Pair Classification |Tensorflow |This is a Sentence Pair Classification model built upon a Text Embedding model from TensorFlow Hub It takes a pair of sentences as input and classifies the input pair to &amp;rsquo;entailment&amp;rsquo; or &amp;rsquo;no-entailment&amp;rsquo; |Model draft: false
id: tensorflow-spc-bert-en-wwm-uncased-L-24-H-1024-A-16-2
|358. |Sentence Pair Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-spc-bert-en-wwm-cased-L-24-H-1024-A-16-2
|359. |Sentence Pair Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-spc-experts-bert-wiki-books-1
|360. |Sentence Pair Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-spc-experts-bert-pubmed-1
|361. |Sentence Pair Classification |Huggingface |Same as above |Model draft: false
id: huggingface-spc-bert-base-multilingual-cased
|362. |Sentence Pair Classification |Huggingface |Same as above |Model draft: false
id: huggingface-spc-bert-large-uncased
|363. |Sentence Pair Classification |Huggingface |Same as above |Model draft: false
id: huggingface-spc-bert-large-cased
|364. |Sentence Pair Classification |Huggingface |Same as above |Model draft: false
id: huggingface-spc-bert-large-uncased-whole-word-masking
|365. |Sentence Pair Classification |Huggingface |Same as above |Model draft: false
id: huggingface-spc-bert-large-cased-whole-word-masking
|366. |Sentence Pair Classification |Huggingface |Same as above |Model draft: false
id: huggingface-spc-distilroberta-base
|367. |Sentence Pair Classification |Huggingface |Same as above |Model draft: false
id: huggingface-spc-roberta-base
|368. |Sentence Pair Classification |Huggingface |Same as above |Model draft: false
id: huggingface-spc-roberta-base-openai-detector
|369. |Sentence Pair Classification |Huggingface |Same as above |Model draft: false
id: huggingface-spc-roberta-large
|370. |Sentence Pair Classification |Huggingface |Same as above |Model draft: false
id: huggingface-spc-roberta-large-openai-detector
|371. |Sentence Pair Classification |Huggingface |Same as above |Model draft: false
id: huggingface-spc-xlm-mlm-ende-1024
|372. |Sentence Pair Classification |Huggingface |Same as above |Model draft: false
id: huggingface-spc-xlm-mlm-enro-1024
|373. |Sentence Pair Classification |Huggingface |Same as above |Model draft: false
id: huggingface-spc-xlm-mlm-xnli15-1024
|374. |Sentence Pair Classification |Huggingface |Same as above |Model draft: false
id: huggingface-spc-xlm-mlm-tlm-xnli15-1024
|375. |Sentence Pair Classification |Huggingface |Same as above |Model draft: false
id: huggingface-spc-xlm-clm-ende-1024
|376. |Text Summarization |Huggingface |This is a Text Summarization model built upon a Transformer model from Hugging Face It takes a text string as input and returns a summary of the text |Model draft: false
id: huggingface-summarization-bigbird-pegasus-large-arxiv
|377. |Text Summarization |Huggingface |Same as above |Model draft: false
id: huggingface-summarization-bigbird-pegasus-large-pubmed
|378. |Text Embedding |Tensorflow |This is a Text Embedding model from TensorFlow Hub It takes a text string as input and outputs an embedding vector The Text Embedding model is pre-trained on Wikipedia and BookCorpus datasets |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-4-H-512-A-8-2
|379. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-4-H-768-A-12-2
|380. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-6-H-128-A-2-2
|381. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-6-H-256-A-4
|382. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-6-H-512-A-8-2
|383. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-6-H-768-A-12-2
|384. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-8-H-256-A-4-2
|385. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-8-H-512-A-8-2
|386. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-8-H-768-A-12-2
|387. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-10-H-128-A-2-2
|388. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-10-H-256-A-4-2
|389. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-10-H-512-A-8-2
|390. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-10-H-768-A-12-2
|391. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-12-H-128-A-2-2
|392. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-12-H-256-A-4
|393. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-12-H-512-A-8-2
|394. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-12-H-768-A-12-2
|395. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-12-H-768-A-12-4
|396. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-wiki-books-sst2
|397. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-wiki-books-mnli-2
|398. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-universal-sentence-encoder-cmlm-en-large-1
|399. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-universal-sentence-encoder-cmlm-en-base-1
|400. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-talkheads-ggelu-bert-en-base-2
|401. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-talkheads-ggelu-bert-en-large-2
|402. |Tabular Classification | |This is the LightGBM algorithm for tabular classification task LightGBM is a gradient boosting framework that uses tree based learning algorithms |Model draft: false
id: lightgbm-classification-model
|403. |Tabular Classification |Catboost |This is the CatBoost algorithm for tabular classification task CatBoost is a machine learning algorithm that uses gradient boosting on decision trees |Model draft: false
id: catboost-classification-model
|404. |Tabular Classification | |This is the AutoGluon-Tabular algorithm for tabular classification task AutoGluon-Tabular is an open-source AutoML framework that trains highly accurate machine learning models on an unprocessed tabular dataset Unlike existing AutoML frameworks that primarily focus on model/hyperparameter selection, AutoGluon-Tabular succeeds by ensembling multiple models and stacking them in multiple layers |Model draft: false
id: autogluon-classification-ensemble
|405. |Tabular Classification | |This is the TabTransformer algorithm for tabular classification task TabTransformer is a deep tabular data modeling architecture that built upon self-attention based Transformers |Model draft: false
id: pytorch-tabtransformerclassification-model
|406. |Tabular Classification |Sklearn |This is the scikit-learn linear algorithm for tabular classification task Linear Classification is a linear approach to classify data into labels (targets) based on a linear combination of its input features (predictors) |Model draft: false
id: sklearn-classification-linear
|407. |Tabular Classification |Xgboost |This is the XGBoost algorithm for tabular classification task XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable It implements machine learning algorithms under the Gradient Boosting framework |Model draft: false
id: xgboost-classification-model
|408. |Tabular Regression | |This is the LightGBM algorithm for tabular regression task LightGBM is a gradient boosting framework that uses tree based learning algorithms |Model draft: false
id: lightgbm-regression-model
|409. |Tabular Regression |Catboost |This is the CatBoost algorithm for tabular regression task CatBoost is a machine learning algorithm that uses gradient boosting on decision trees |Model draft: false
id: catboost-regression-model
|410. |Tabular Regression | |This is the AutoGluon-Tabular algorithm for tabular regression task AutoGluon-Tabular is an open-source AutoML framework that trains highly accurate machine learning models on an unprocessed tabular dataset Unlike existing AutoML frameworks that primarily focus on model/hyperparameter selection, AutoGluon-Tabular succeeds by ensembling multiple models and stacking them in multiple layers |Model draft: false
id: autogluon-regression-ensemble
|411. |Tabular Regression | |This is the TabTransformer algorithm for tabular regression task TabTransformer is a deep tabular data modeling architecture that built upon self-attention based Transformers |Model draft: false
id: pytorch-tabtransformerregression-model
|412. |Tabular Regression |Sklearn |This is the scikit-learn linear algorithm for tabular regression task Linear Regression is a linear approach for modelling the relationship between a scalar response and one or more explanatory variables |Model draft: false
id: sklearn-regression-linear
|413. |Tabular Regression |Xgboost |This is the XGBoost algorithm for tabular regression task XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable It implements machine learning algorithms under the Gradient Boosting framework |Model draft: false
id: xgboost-regression-model
|414. |Question Answering |Pytorch |This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question |Model draft: false
id: pytorch-eqa-distilbert-base-uncased
|415. |Question Answering |Pytorch |Same as above |Model draft: false
id: pytorch-eqa-bert-large-uncased-whole-word-masking
|416. |Question Answering |Pytorch |Same as above |Model draft: false
id: pytorch-eqa-bert-large-uncased
|417. |Question Answering |Pytorch |Same as above |Model draft: false
id: pytorch-eqa-bert-large-cased
|418. |Question Answering |Pytorch |Same as above |Model draft: false
id: pytorch-eqa-roberta-base
|419. |Question Answering |Pytorch |Same as above |Model draft: false
id: pytorch-eqa-distilbert-base-multilingual-cased
|420. |Object detection |SageMaker |Identify birds species in a scene using a SageMaker object detection model. |
|421. |Question Answering |Pytorch |This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question |Model draft: false
id: pytorch-eqa-distilroberta-base
|422. |Audio Embedding |Tensorflow |This is an audio embedding model from Tensorflow Hub It takes a wav (audio file format) file as input and outputs an embedding vector |Model draft: false
id: tensorflow-audioembedding-trill-distilled-3
|423. |Question Answering |Pytorch |This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question |Model draft: false
id: pytorch-eqa-roberta-large-openai-detector
|424. |Object detection |SageMaker |Identify defective regions in product images either by training an object detection model from scratch or fine-tuning pretrained SageMaker models. |
|425. |Audio Embedding |Tensorflow |This is an audio embedding model from Tensorflow Hub It takes a wav (audio file format) file as input and outputs an embedding vector |Model draft: false
id: tensorflow-audioembedding-trillsson2-1
|426. |Tabular classification |SageMaker |Automatically detect potentially fraudulent activity in transactions using SageMaker XGBoost with the over-sampling technique Synthetic Minority Over-sampling (SMOTE). |
|427. |Feature importance using shap |SageMaker | |
|428. |Question Answering |Pytorch |This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question |Model draft: false
id: pytorch-eqa-distilbert-base-cased
|429. |Graph neural network classification |SageMaker |Detect fraud in financial transactions by training a graph convolutional network with the deep graph library and a SageMaker XGBoost model. |
|430. |Tabular classification |SageMaker |Classify financial payments based on transaction information using SageMaker XGBoost. Use this solution template as an intermediate step in fraud detection, personalization, or anomaly detection. |
|431. |Tabular classification |SageMaker |Identify unhappy mobile phone customers using SageMaker XGBoost. |
|432. |Question Answering |Pytorch |This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question |Model draft: false
id: pytorch-eqa-bert-base-cased
|433. |RL |SageMaker |Distributed reinforcement learning starter kit for NeurIPS 2020 Procgen Reinforcement learning challenge. |
|434. |Question Answering |Pytorch |This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question |Model draft: false
id: pytorch-eqa-bert-large-cased-whole-word-masking-finetuned-squad
|435. |Tabular classification |SageMaker | |
|436. |RL |SageMaker | |
|437. |Entity resolution |SageMaker | |
|438. |Tabular classification |SageMaker | |
|439. |Tabular and text classification |SageMaker | |
|440. |Text classification |SageMaker |Anonymize text to better preserve user privacy in sentiment classification. |
|441. |Tabular, image, and text classification. |SageMaker | |
|442. |Tabular classification |SageMaker | |
|443. |Text to Image |Stabilityai |This is a text-to-image model from Stability AI and downloaded from HuggingFace It takes a textual description as input and returns a generated image from the description |Model draft: false
id: model-txt2img-stabilityai-stable-diffusion-v2-fp16
|444. |Text to Image |Stabilityai |Same |Model draft: false
id: model-txt2img-stabilityai-stable-diffusion-v1-4-fp16
|445. |ext to Image |Stabilityai |Same |Model draft: false
id: model-txt2img-stabilityai-stable-diffusion-v1-4
|446. |Question Answering |Pytorch |This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question |Model draft: false
id: pytorch-eqa-bert-base-multilingual-cased
|447. |Question Answering |Pytorch |This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question |Model draft: false
id: pytorch-eqa-roberta-large
|448. |Audio Embedding |Tensorflow |This is an audio embedding model from Tensorflow Hub It takes a wav (audio file format) file as input and outputs an embedding vector |Model draft: false
id: tensorflow-audioembedding-frill-1
|449. |Audio Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-audioembedding-trillsson3-1
|450. |Audio Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-audioembedding-trill-3
|451. |Tabular and text classification |SageMaker | |
|452. |Question Answering |Pytorch |This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question |Model draft: false
id: pytorch-eqa-roberta-base-openai-detector
|453. |Question Answering |Pytorch |Same |Model draft: false
id: pytorch-eqa-bert-large-cased-whole-word-masking
|454. |Time series |SageMaker |Demand forecasting for multivariate time series data using three state-of-the-art time series forecasting algorithms: LSTNet, Prophet, and SageMaker DeepAR. |
|455. |Question Answering |Pytorch |This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question |Model draft: false
id: pytorch-eqa-bert-large-uncased-whole-word-masking-finetuned-squad
|456. |Question Answering |Pytorch |Same |Model draft: false
id: pytorch-eqa-bert-base-multilingual-uncased
|457. |Question Answering |Pytorch |Same |Model draft: false
id: pytorch-eqa-bert-base-uncased
|458. |Audio Embedding |Tensorflow |This is an audio embedding model from Tensorflow Hub It takes a wav (audio file format) file as input and outputs an embedding vector |Model draft: false
id: tensorflow-audioembedding-trillsson1-1
|459. |Object detection |SageMaker | |
|460. |Causal inference |SageMaker |Generate a counterfactual analysis of corn response to nitrogen. This solution learns the crop phenology cycle in its entirety using multi-spectral satellite imagery and ground-level observations. |
|461. |Price optimization |SageMaker |Estimate price elasticity using Double Machine Learning (ML) for causal inference and the Prophet forecasting procedure. Use these estimates to optimize daily prices. |
|462. |Tabular and text classification |SageMaker | |
|463. |Upscaling |Stabilityai |This is a upscaling model from Stability AI downloaded from HuggingFace with FP16 precision Given a low resolution image and a textual prompt, it generates a higher resolution image with size up to four times the original image size |Model draft: false
id: model-upscaling-stabilityai-stable-diffusion-x4-upscaler-fp16&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Python Decorator Function</title>
      <link>http://localhost:1313/dsblog/Python-Decorator-Function/</link>
      <pubDate>Sat, 15 Jul 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Python-Decorator-Function/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../assets/images/dspost/dsp6074-Python-Decorator-Function.jpg&#34; alt=&#34;Python Decorator Function&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Python Decorator Function 
    &lt;div id=&#34;python-decorator-function&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#python-decorator-function&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What is Decorator Function in Python 
    &lt;div id=&#34;what-is-decorator-function-in-python&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-decorator-function-in-python&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;In Python, a decorator is a special type of function that allows you to modify or extend the behavior of other functions or methods. Decorators provide a convenient way to add functionality to functions without modifying their code directly. They are commonly used for tasks such as logging, authorization, caching, and more.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Python Naming Convention</title>
      <link>http://localhost:1313/dsblog/Python-Naming-Convention/</link>
      <pubDate>Tue, 11 Jul 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Python-Naming-Convention/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../assets/images/dspost/dsp6072-Python-Naming-Convention.jpg&#34; alt=&#34;Python Naming Convention&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Python Naming Convention 
    &lt;div id=&#34;python-naming-convention&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#python-naming-convention&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;UPPERCASE / UPPER_CASE_WITH_UNDERSCORES =&amp;gt; module-level constants&lt;/li&gt;
&lt;li&gt;lowercase / lower_case_with_underscores =&amp;gt; for variable and function name.&lt;/li&gt;
&lt;li&gt;CapitalizedWords (or CapWords, or CamelCase – so named because of the bumpy look of its letters [4]). This is also sometimes known as StudlyCaps. =&amp;gt; CamelCase =&amp;gt; Class
&lt;ul&gt;
&lt;li&gt;Note: When using acronyms in CapWords, capitalize all the letters of the acronym. Thus HTTPServerError is better than HttpServerError.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;mixedCase (differs from CapitalizedWords by initial lowercase character!)&lt;/li&gt;
&lt;li&gt;Capitalized_Words_With_Underscores (ugly!)&lt;/li&gt;
&lt;li&gt;_single_leading_underscore: weak “internal use” indicator. E.g. from M import * does not import objects whose names start with an underscore.&lt;/li&gt;
&lt;li&gt;single&lt;em&gt;trailing_underscore&lt;/em&gt;: used by convention to avoid conflicts with Python keyword, e.g.
tkinter.Toplevel(master, class_=&amp;lsquo;ClassName&amp;rsquo;)&lt;/li&gt;
&lt;li&gt;__double_leading_underscore: when naming a class attribute, invokes name mangling (inside class FooBar, &lt;strong&gt;boo becomes _FooBar&lt;/strong&gt;boo; see below).&lt;/li&gt;
&lt;li&gt;__double_leading_and_trailing_underscore**: “magic” objects or attributes that live in user-controlled namespaces. E.g. __init**, __import** or __file**. Never invent such names; only use them as documented.&lt;/li&gt;
&lt;li&gt;Never use the characters ‘l’ (lowercase letter el), ‘O’ (uppercase letter oh), or ‘I’ (uppercase letter eye) as single character variable names.&lt;/li&gt;
&lt;/ul&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Programming Recommendations 
    &lt;div id=&#34;programming-recommendations&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#programming-recommendations&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Use &amp;ldquo;is not&amp;rdquo; operator 
    &lt;div id=&#34;use-is-not-operator&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#use-is-not-operator&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Correct:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;foo&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Wrong:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;foo&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2 class=&#34;relative group&#34;&gt;Always use a def statement 
    &lt;div id=&#34;always-use-a-def-statement&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#always-use-a-def-statement&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Correct:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Wrong:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;f&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;lambda&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2 class=&#34;relative group&#34;&gt;all try/except clauses 
    &lt;div id=&#34;all-tryexcept-clauses&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#all-tryexcept-clauses&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Correct:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;try&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;value&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;collection&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;except&lt;/span&gt; &lt;span class=&#34;ne&#34;&gt;KeyError&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;key_not_found&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;handle_value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Wrong:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;try&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# Too broad!&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;handle_value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;collection&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;except&lt;/span&gt; &lt;span class=&#34;ne&#34;&gt;KeyError&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# Will also catch KeyError raised by handle_value()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;key_not_found&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2 class=&#34;relative group&#34;&gt;Context managers should be invoked through separate functions or methods 
    &lt;div id=&#34;context-managers-should-be-invoked-through-separate-functions-or-methods&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#context-managers-should-be-invoked-through-separate-functions-or-methods&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Correct:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;conn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;begin_transaction&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;do_stuff_in_transaction&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;conn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Wrong:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;conn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;do_stuff_in_transaction&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;conn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2 class=&#34;relative group&#34;&gt;Be consistent in return statements 
    &lt;div id=&#34;be-consistent-in-return-statements&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#be-consistent-in-return-statements&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Correct:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;foo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;math&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sqrt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;bar&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;math&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sqrt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Wrong:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;foo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;math&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sqrt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;bar&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;math&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sqrt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2 class=&#34;relative group&#34;&gt;startswith, endswith 
    &lt;div id=&#34;startswith-endswith&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#startswith-endswith&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Use &amp;lsquo;&amp;rsquo;.startswith() and &amp;lsquo;&amp;rsquo;.endswith() instead of string slicing to check for prefixes or suffixes.&lt;/li&gt;
&lt;li&gt;Correct:
if foo.startswith(&amp;lsquo;bar&amp;rsquo;):&lt;/li&gt;
&lt;li&gt;Wrong:
if foo[:3] == &amp;lsquo;bar&amp;rsquo;:&lt;/li&gt;
&lt;/ul&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Object type comparisons 
    &lt;div id=&#34;object-type-comparisons&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#object-type-comparisons&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Correct:
if isinstance(obj, int):&lt;/li&gt;
&lt;li&gt;Wrong:
if type(obj) is type(1):&lt;/li&gt;
&lt;/ul&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Sequences, (strings, lists, tuples) 
    &lt;div id=&#34;sequences-strings-lists-tuples&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#sequences-strings-lists-tuples&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;-For sequences, (strings, lists, tuples), use the fact that empty sequences are false:&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Timeseries Interview Questions</title>
      <link>http://localhost:1313/dsblog/Timeseries-Interview-Questions/</link>
      <pubDate>Sun, 08 Jan 2023 15:50:00 +0530</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Timeseries-Interview-Questions/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../assets/images/dspost/dsp6023-Timeseries-Interview-Questions.jpg&#34; alt=&#34;Timeseries Interview Questions&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Timeseries Interview Questions 
    &lt;div id=&#34;timeseries-interview-questions&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#timeseries-interview-questions&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What are the characterstics of time series data? 
    &lt;div id=&#34;what-are-the-characterstics-of-time-series-data&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-are-the-characterstics-of-time-series-data&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Time series data is a series of data points collected over time. Some characteristics of time series data include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Time dependence: Time series data is typically collected at regular time intervals, and the values of the time series are often dependent on the time at which they were collected.&lt;/li&gt;
&lt;li&gt;Equal duration gap between samples/ records&lt;/li&gt;
&lt;li&gt;No missing record in between&lt;/li&gt;
&lt;li&gt;Trend: Many time series exhibit a long-term trend, either upward or downward. This trend may be influenced by a variety of factors such as economic conditions, population growth, or technological changes.&lt;/li&gt;
&lt;li&gt;Seasonality: Many time series exhibit regular fluctuations due to seasonal factors such as weather, holidays, or other events. For example, retail sales may be higher in the months leading up to Christmas due to holiday shopping.&lt;/li&gt;
&lt;li&gt;Cyclicity: Time series may exhibit cyclical pattern. Like sales is highest in month start, body temprature is high at 6am, traffic is least on weekends etc.&lt;/li&gt;
&lt;li&gt;Noise: Time series data may also be affected by random noise or error, which can make it difficult to accurately forecast future values.&lt;/li&gt;
&lt;li&gt;Autocorrelation: Time series data may exhibit autocorrelation, which is the phenomenon of a value at a particular time being correlated with values at nearby times. This can make it challenging to model the time series, as the value at a given time may depend on the values at nearby times.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Example of time series data 
    &lt;div id=&#34;example-of-time-series-data&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#example-of-time-series-data&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Date&lt;/th&gt;
          &lt;th&gt;Sales (y)&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;2020-01-01&lt;/td&gt;
          &lt;td&gt;1000&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;2020-02-01&lt;/td&gt;
          &lt;td&gt;1100&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;2020-03-01&lt;/td&gt;
          &lt;td&gt;1200&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;2020-04-01&lt;/td&gt;
          &lt;td&gt;1100&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;2020-05-01&lt;/td&gt;
          &lt;td&gt;1000&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;2020-06-01&lt;/td&gt;
          &lt;td&gt;900&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;2020-07-01&lt;/td&gt;
          &lt;td&gt;1200&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;2020-08-01&lt;/td&gt;
          &lt;td&gt;1400&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;2020-09-01&lt;/td&gt;
          &lt;td&gt;1300&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;2020-10-01&lt;/td&gt;
          &lt;td&gt;1500&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This first column can be date or date or datetime. Interval between two rows must be equal. The unit of date or time or datetime may be milliosecond, or second, or minute, or hour, or day, week, month, quarter, year or dacade. This should be continuous without any gap.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Data Science Cheatsheets</title>
      <link>http://localhost:1313/dsblog/data-science-cheatsheets/</link>
      <pubDate>Sun, 03 Jul 2022 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/data-science-cheatsheets/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../assets/images/dsresources/dsr103-Data-Science-Cheatsheets.jpg&#34; alt=&#34;Data Science Cheatsheets&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Data Science Cheatsheets 
    &lt;div id=&#34;data-science-cheatsheets&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#data-science-cheatsheets&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Introduction 
    &lt;div id=&#34;introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;All these cheat sheets are kept at &lt;a href=&#34;https://drive.google.com/drive/folders/1dCHf52OYqbB17rXzJODYiBnM8JNneb2_?usp=sharing&#34; target=&#34;_blank&#34;&gt;my google drive link&lt;/a&gt;. 180+ cheatsheet on ML, DL, DE, DA, NLP, Algorithms, Pandas, Numpy, Dask, Bigdata, Statistics, Python, SQL, Docker, sklearn, git, GNN etc.&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;List of Cheatsheets 
    &lt;div id=&#34;list-of-cheatsheets&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#list-of-cheatsheets&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;21 Types of SQL joins-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;5W1H-DataScience-CHEATSHEET.jpg&lt;/li&gt;
&lt;li&gt;Acceptance Criteria Checklist.pdf&lt;/li&gt;
&lt;li&gt;Activation Functions-CHEATSHEET.jpg&lt;/li&gt;
&lt;li&gt;Advanced R-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;AI4All-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;AI-Cheatsheet+NN+ML+DL+BD.pdf&lt;/li&gt;
&lt;li&gt;AIML_Fundamental-CHEATSHEET.jpg&lt;/li&gt;
&lt;li&gt;AIML-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;AI-ML-DS Cheatsheets .pdf&lt;/li&gt;
&lt;li&gt;AI-NeuralNetworks.pdf&lt;/li&gt;
&lt;li&gt;All in One Mathematics Cheatsheet.pdf&lt;/li&gt;
&lt;li&gt;An Introduction to Convolutional Neural Networks-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Artificial Intelligence _ Super VIP Cheatsheet.pdf&lt;/li&gt;
&lt;li&gt;Azure-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Beginners Python-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Behavioral Interview-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Best_Machine_Learning_Algorithms-CHEATSHEET.jpg&lt;/li&gt;
&lt;li&gt;BI versus DS-CHEATSHEET.jpg&lt;/li&gt;
&lt;li&gt;Bias-Variance-Tradeoff-Cheatsheet.pdf&lt;/li&gt;
&lt;li&gt;Big Data Hadoop+Mapreduce-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Big Data-Hadoop-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Bigdata-Hadoop-hdfs-commands-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Bigdata-Hortonworks SQLtoHive-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Bigdata-Pig-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;BrainMapping-CHEATSHEET.jpg&lt;/li&gt;
&lt;li&gt;Calculus Cheat Sheet.pdf&lt;/li&gt;
&lt;li&gt;CalculusA_All-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;CalculusB_All-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Chart-Suggestion-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Cloud Comparison AWS AZURE GCP-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Cloud Computing Cheatsheet .pdf&lt;/li&gt;
&lt;li&gt;Combined Cheat Sheets of ML+DL Probability and LLMs-Cheatsheet.pdf&lt;/li&gt;
&lt;li&gt;Complete Collection of Data Science Cheatsheets.pdf&lt;/li&gt;
&lt;li&gt;Comprehensive Python -CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Computing Neural Network Gradients-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;CS229 - Machine Learning-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Dask-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Data Engineering _ Analytics Use Case Architecture on AWS-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Data Engineering Cookbook-GUIDE.pdf&lt;/li&gt;
&lt;li&gt;Data Science -CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Data Science -Data Prep with SQL -Quick Reference-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Data Science Regular Python Expressions-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Data Science with Python Workflow-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Data Visualization with ggplot2-CHEATSHEET.jpg&lt;/li&gt;
&lt;li&gt;Data VisualizationA-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Data Wrangling with Pandas-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Data_engineering_infographic-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Data_Wrangling_with_dplyr_and_tidyr-RStudio-CHEATSHEET.jpg&lt;/li&gt;
&lt;li&gt;DataScience1-CHEATSHEET.jpg&lt;/li&gt;
&lt;li&gt;DataScience2-CHEATSHEET.jpg&lt;/li&gt;
&lt;li&gt;DataScience3-CHEATSHEET.jpg&lt;/li&gt;
&lt;li&gt;DataScience4-CHEATSHEET.jpg&lt;/li&gt;
&lt;li&gt;DataScience-Cheatsheet.pdf&lt;/li&gt;
&lt;li&gt;Deep Learning Course Notes-Coursera-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Deep Learning-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Deep_Learning_Cheat_Sheet-Hacker Noon-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Deeplearning-Definitions-CHEATSHEET.png&lt;/li&gt;
&lt;li&gt;Docker-Cheatsheet-2016.pdf&lt;/li&gt;
&lt;li&gt;Docker-The Ultimate CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Ensemble Learning-CHEATSHEET.jpg&lt;/li&gt;
&lt;li&gt;Financial Formulas-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;ggplot2&amp;ndash;CHEATSHEET.jpg&lt;/li&gt;
&lt;li&gt;GitA-CHEATSHEET.png&lt;/li&gt;
&lt;li&gt;Git-atlassian-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;GitB-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;GitC-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Google-Data Engineering CheatSheet.pdf&lt;/li&gt;
&lt;li&gt;Google-Data-Engineering-Cheatsheets.pdf&lt;/li&gt;
&lt;li&gt;Graph4NLP-CHEATSHEET.jpg&lt;/li&gt;
&lt;li&gt;Graphics-Principles-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Great Python Cheatsheet by Dummies-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Handling Data Imbalance-CHEATSHEET.jpg&lt;/li&gt;
&lt;li&gt;Keras-CHEATSHEET.jpg&lt;/li&gt;
&lt;li&gt;Liner_Algebra-in-4Pages-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;LinkedIn-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;LinkedInGuide-Ultimate-Cheatsheet.pdf&lt;/li&gt;
&lt;li&gt;Machine learning algorithms with Python _ R code examples-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Machine Learning Algorithms-CHEATSHEET.jpg&lt;/li&gt;
&lt;li&gt;Machine Learning Algorithms-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Machine Learning Best Practices-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Machine Learning Interview-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Machine Learning_Data Science Interview Cheatsheets-InterviewQ.pdf&lt;/li&gt;
&lt;li&gt;Machine Learning-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Machine-Learnign-Cheatsheet.pdf&lt;/li&gt;
&lt;li&gt;Machine-Learning1-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Machine-Learning-Algorithm&amp;ndash;CHEATSHEET.svg&lt;/li&gt;
&lt;li&gt;Machine-learning-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Matplotlib-CHEATSHEET.png&lt;/li&gt;
&lt;li&gt;Merlion timeseries library-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Metrics and more-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Microservices-Cheatsheet.pdf&lt;/li&gt;
&lt;li&gt;Microsoft-Machine-Learning-Algorithm&amp;ndash;CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Microsoft-Office-Cheatsheets.pdf&lt;/li&gt;
&lt;li&gt;ML Algorithm Learning-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;ML dataset-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;ML-Algorithms-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;MySql-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Nested Queries And Aggregation-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Neural Network Architecture Types-CHEATSHEET.png&lt;/li&gt;
&lt;li&gt;Neural networks-CHEATSHEET.png&lt;/li&gt;
&lt;li&gt;Neural_Network_Cells-CHEATSHEET.png&lt;/li&gt;
&lt;li&gt;Neural_Network_Graphs-CHEATSHEET.png&lt;/li&gt;
&lt;li&gt;Neural_Networks_Zoo-CHEATSHEET.png&lt;/li&gt;
&lt;li&gt;NeuralNetwork-CHEATSHEET.png&lt;/li&gt;
&lt;li&gt;NLP-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Numpy&lt;em&gt;Python&lt;/em&gt;-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;NumpyA-CHEATSHEET.png&lt;/li&gt;
&lt;li&gt;NumpyB-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;NumpyC-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Open CV-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Pandas Data analysis-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Pandas Python-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Pandas_Cheatsheet-Pandas Basics-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Pandas1-CHEATSHEET.jpg&lt;/li&gt;
&lt;li&gt;Pandas2-CHEATSHEET.jpg&lt;/li&gt;
&lt;li&gt;Pandas-Basics-CHEATSHEET.png&lt;/li&gt;
&lt;li&gt;Pandas-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;PandasOne-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Postman Cheatsheet .pdf&lt;/li&gt;
&lt;li&gt;Probability-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Pros Cons of commonly used machine learning algorithms-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;PySpark Quick Reference Guide.pdf&lt;/li&gt;
&lt;li&gt;PySpark-RDD-CHEATSHEET.png&lt;/li&gt;
&lt;li&gt;PySpark-SQL-CHEATSHEET.png&lt;/li&gt;
&lt;li&gt;Python BasicsA-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Python BasicsB-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Python Security Best Practices-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Python_CheatSheet-by-WebsiteSetup.pdf&lt;/li&gt;
&lt;li&gt;Python_Matplotlib-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Python_SciPy_Linear_Algebra-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Python3A-CHEATSHEET.png&lt;/li&gt;
&lt;li&gt;Python3B-CHEATSHEET.png&lt;/li&gt;
&lt;li&gt;Python3C-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;PythonA-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;PythonB-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;PythonC-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Python-CheatSheet.pdf&lt;/li&gt;
&lt;li&gt;PythonD-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;PythonD-CHEATSHEET.png&lt;/li&gt;
&lt;li&gt;Python-for-DS-All-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Pytorch-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Quantitative Aptitude-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Query-Optimization-Techniques-SQL-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;R programming cheatsheet.pdf&lt;/li&gt;
&lt;li&gt;R Programming-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Reading and Writing Data with Pandas-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Regression-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Rest API Cheatsheet.pdf&lt;/li&gt;
&lt;li&gt;Risk Assessment Example-CheatSheet.pdf&lt;/li&gt;
&lt;li&gt;Roadmap of mathematics for Deep Learning-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Scikit_Learn_Python-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Scikit_Learn-CHEATSHEET.png&lt;/li&gt;
&lt;li&gt;Scikit-Learn1-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Seaborn-CHEATSHEET.png&lt;/li&gt;
&lt;li&gt;Sklearn-Algo-CHEATSHEET.png&lt;/li&gt;
&lt;li&gt;SQL &amp;amp; NoSQL-Cheatsheet.pdf&lt;/li&gt;
&lt;li&gt;SQL API with Python-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;SQL for MLI FAM-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;SQL Window Functions.pdf&lt;/li&gt;
&lt;li&gt;SQL-CHEATSHEET.jpg&lt;/li&gt;
&lt;li&gt;Statistics Test Decision-CHEATSHEET.png&lt;/li&gt;
&lt;li&gt;Statistics1-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Statistics2-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Statistics-A-Cheatsheet.pdf&lt;/li&gt;
&lt;li&gt;Statistics-Cheatsheet.pdf&lt;/li&gt;
&lt;li&gt;Statistics-Harvard-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Super VIP ML , DL , AI-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Super-VIP-Deep-learning-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Tableau-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;The Super Duper NLP Repo-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Theoretical Computer Science-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Top 56 Job Interview Questions.pdf&lt;/li&gt;
&lt;li&gt;Top Data Science Interview Question.pdf&lt;/li&gt;
&lt;li&gt;Top Data Science Libraries-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;Top Machine Learning Models Guides.pdf&lt;/li&gt;
&lt;li&gt;Top Prediction Algorithms-CHEATSHEET.jpg&lt;/li&gt;
&lt;li&gt;Ultimate Guide to AI, Data Science _ Machine Learning-LINKS.pdf&lt;/li&gt;
&lt;li&gt;VIP Cheatsheet-Recurrent Neural Networks-CHEATSHEET.pdf&lt;/li&gt;
&lt;li&gt;VIS-Know your data with ggplot2-NOTEBOOK.pdf&lt;/li&gt;
&lt;li&gt;Visualizing-Percentages-20-Ways-InfoNewt.pdf&lt;/li&gt;
&lt;/ol&gt;</description>
      
    </item>
    
    <item>
      <title>Python Software Development and Distribution</title>
      <link>http://localhost:1313/dsblog/Python-Software-Development-and-Distribution/</link>
      <pubDate>Thu, 30 Sep 2021 15:50:00 +0530</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Python-Software-Development-and-Distribution/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../assets/images/dspost/dsp6012-Python-Software-Development-and-Distribution.jpg&#34; alt=&#34;Software Distribution&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Software Distribution 
    &lt;div id=&#34;software-distribution&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#software-distribution&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Introduction 
    &lt;div id=&#34;introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;We don’t develop any good and valuable piece of software from scratch. We use pieces of code written by others. This piece of code can be a service running on another machine or software written but kept in a repository. This service may be created by some other company, individual, our company, our team, or ourselves. So any software has two components, one, which is created by us, and we are responsible for the maintenance of that. Another component is a piece of software that is created by someone else, and we are not responsible for the maintenance of that.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Data Science Interview Question Answers</title>
      <link>http://localhost:1313/dsblog/ds-ai-ml-interview-resources/</link>
      <pubDate>Thu, 02 Jul 2020 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/ds-ai-ml-interview-resources/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../assets/images/dsresources/dsr102-Data-Science-Interview-Question-Answers.jpg&#34; alt=&#34;Data Science Interview Question Answers&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Data Science Interview Question Answers 
    &lt;div id=&#34;data-science-interview-question-answers&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#data-science-interview-question-answers&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;Thousands of interview questions on various topic related to Machine Learning, Deep Learning, Computer Vision, NLP, AWS, GCP, MLOPS, Data Analytics, SQL, Python &amp;amp; Statistics. These questions are related to technology, architectures and solving business problem. &lt;a href=&#34;https://drive.google.com/drive/folders/1O9DcVhE5r0lBPpZd8bFjaA0FqPv94Vbm?usp=sharing&#34; target=&#34;_blank&#34;&gt;This gdrive link&lt;/a&gt; has 51 pdf files which contains the questions and answers.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Reinforcement Learning Git Repositories</title>
      <link>http://localhost:1313/dsblog/rl-git-repo/</link>
      <pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/rl-git-repo/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../assets/images/dsresources/dsr101-Reinforcement-Learning-Git-Repositories.jpg&#34; alt=&#34;Reinforcement Learning Git Repositories&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Reinforcement Learning Git Repositories 
    &lt;div id=&#34;reinforcement-learning-git-repositories&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#reinforcement-learning-git-repositories&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Sno.&lt;/th&gt;
          &lt;th&gt;URL&lt;/th&gt;
          &lt;th&gt;Description&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;1&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/openai/baselines&#34; target=&#34;_blank&#34;&gt;https://github.com/openai/baselines&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;OpenAI Baselines: high-quality implementations of reinforcement learning algorithms&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;2&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/hill-a/stable-baselines&#34; target=&#34;_blank&#34;&gt;https://github.com/hill-a/stable-baselines&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;A fork of OpenAI Baselines, implementations of reinforcement learning algorithms&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;3&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/openai/spinningup&#34; target=&#34;_blank&#34;&gt;https://github.com/openai/spinningup&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;An educational resource to help anyone learn deep reinforcement learning.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;4&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/google/dopamine&#34; target=&#34;_blank&#34;&gt;https://github.com/google/dopamine&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Dopamine is a research framework for fast prototyping of reinforcement learning algorithms.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;5&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/tensorflow/agents&#34; target=&#34;_blank&#34;&gt;https://github.com/tensorflow/agents&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;TF-Agents is a library for Reinforcement Learning in TensorFlow&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;6&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/deepmind/trfl&#34; target=&#34;_blank&#34;&gt;https://github.com/deepmind/trfl&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;TensorFlow Reinforcement Learning&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;7&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/facebookresearch/Horizon&#34; target=&#34;_blank&#34;&gt;https://github.com/facebookresearch/Horizon&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;A platform for Applied Reinforcement Learning (Applied RL)&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;8&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/facebookresearch/ELF&#34; target=&#34;_blank&#34;&gt;https://github.com/facebookresearch/ELF&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;An End-To-End, Lightweight and Flexible Platform for Game Research&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;9&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/NervanaSystems/coach&#34; target=&#34;_blank&#34;&gt;https://github.com/NervanaSystems/coach&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Reinforcement Learning Coach by Intel AI Lab enables easy experimentation with state of the art Reinforcement Learning algorithms&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;10&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/ray-project/ray/tree/master/python/ray/rllib&#34; target=&#34;_blank&#34;&gt;https://github.com/ray-project/ray/tree/master/python/ray/rllib&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;A fast and simple framework for building and running distributed applications.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;11&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/keras-rl/keras-rl&#34; target=&#34;_blank&#34;&gt;https://github.com/keras-rl/keras-rl&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Deep Reinforcement Learning for Keras.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;12&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail&#34; target=&#34;_blank&#34;&gt;https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;PyTorch implementation of Advantage Actor Critic (A2C), Proximal Policy Optimization (PPO), Scalable trust-region method for deep reinforcement learning using Kronecker-factored approximation (ACKTR) and Generative Adversarial Imitation Learning (GAIL).&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;13&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/Kaixhin/Rainbow&#34; target=&#34;_blank&#34;&gt;https://github.com/Kaixhin/Rainbow&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Rainbow: Combining Improvements in Deep Reinforcement Learning&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;14&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/MillionIntegrals/vel&#34; target=&#34;_blank&#34;&gt;https://github.com/MillionIntegrals/vel&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Velocity in deep-learning research&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;15&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/tensorforce/tensorforce&#34; target=&#34;_blank&#34;&gt;https://github.com/tensorforce/tensorforce&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Tensorforce: A TensorFlow library for applied reinforcement learning&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;16&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/kengz/SLM-Lab&#34; target=&#34;_blank&#34;&gt;https://github.com/kengz/SLM-Lab&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Modular Deep Reinforcement Learning framework in PyTorch.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;17&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/rlworkgroup/garage&#34; target=&#34;_blank&#34;&gt;https://github.com/rlworkgroup/garage&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;A framework for reproducible reinforcement learning research&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;18&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/catalyst-team/catalyst&#34; target=&#34;_blank&#34;&gt;https://github.com/catalyst-team/catalyst&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Reproducible and fast DL &amp;amp; RL.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;19&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/higgsfield/RL-Adventure&#34; target=&#34;_blank&#34;&gt;https://github.com/higgsfield/RL-Adventure&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Pytorch Implementation of DQN / DDQN / Prioritized replay/ noisy networks/ distributional values/ Rainbow/ hierarchical RL&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;20&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/qfettes/DeepRL-Tutorials&#34; target=&#34;_blank&#34;&gt;https://github.com/qfettes/DeepRL-Tutorials&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Contains high quality implementations of Deep Reinforcement Learning algorithms written in PyTorch&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;21&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/openai/gym&#34; target=&#34;_blank&#34;&gt;https://github.com/openai/gym&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;A toolkit for developing and comparing reinforcement learning algorithms.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;22&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/deepmind/lab&#34; target=&#34;_blank&#34;&gt;https://github.com/deepmind/lab&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;A customisable 3D platform for agent-based AI research&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;23&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/Microsoft/malmo&#34; target=&#34;_blank&#34;&gt;https://github.com/Microsoft/malmo&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Project Malmo is a platform for Artificial Intelligence experimentation and research built on top of Minecraft. We aim to inspire a new generation of research into challenging new problems presented by this unique environment. — For installation instruct&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;24&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/openai/retro&#34; target=&#34;_blank&#34;&gt;https://github.com/openai/retro&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Retro Games in Gym&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;25&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/deepmind/dm_control&#34; target=&#34;_blank&#34;&gt;https://github.com/deepmind/dm_control&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;The DeepMind Control Suite and Package&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;26&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/openai/neural-mmo&#34; target=&#34;_blank&#34;&gt;https://github.com/openai/neural-mmo&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Neural MMO – A Massively Multiagent Game Environment&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;27&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/openai/gym&#34; target=&#34;_blank&#34;&gt;https://github.com/openai/gym&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Gym @ OpenAI&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;28&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/deepmind/lab&#34; target=&#34;_blank&#34;&gt;https://github.com/deepmind/lab&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Lab @ DeepMind&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;29&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/Microsoft/malmo&#34; target=&#34;_blank&#34;&gt;https://github.com/Microsoft/malmo&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Project Malmo @ Microsoft&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;30&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/openai/retro&#34; target=&#34;_blank&#34;&gt;https://github.com/openai/retro&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Retro @ OpenAI&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;31&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/deepmind/dm_control&#34; target=&#34;_blank&#34;&gt;https://github.com/deepmind/dm_control&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Control Suite @ DeepMind&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;32&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/openai/neural-mmo&#34; target=&#34;_blank&#34;&gt;https://github.com/openai/neural-mmo&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Neural MMO @ OpenAI&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;33&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/openai/baselines&#34; target=&#34;_blank&#34;&gt;https://github.com/openai/baselines&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Tensorflow Maintained by OpenAI&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;34&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/hill-a/stable-baselines&#34; target=&#34;_blank&#34;&gt;https://github.com/hill-a/stable-baselines&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Tensorflow Maintained by Antonin Raffin, Ashley Hill&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;35&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/catalyst-team/catalyst&#34; target=&#34;_blank&#34;&gt;https://github.com/catalyst-team/catalyst&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;PyTorch Maintained by Sergey Kolesnikov&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;36&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/ray-project/ray/tree/master/python/ray/rllib&#34; target=&#34;_blank&#34;&gt;https://github.com/ray-project/ray/tree/master/python/ray/rllib&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Tensorflow Maintained by Ray Team&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;37&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/tensorflow/agents&#34; target=&#34;_blank&#34;&gt;https://github.com/tensorflow/agents&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Tensorflow Maintained by Google&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;38&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/facebookresearch/Horizon&#34; target=&#34;_blank&#34;&gt;https://github.com/facebookresearch/Horizon&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;PyTorch Maintained by Facebook&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;39&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/NervanaSystems/coach&#34; target=&#34;_blank&#34;&gt;https://github.com/NervanaSystems/coach&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Tensorflow Maintained by Intel&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;40&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/rlworkgroup/garage&#34; target=&#34;_blank&#34;&gt;https://github.com/rlworkgroup/garage&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Tensorflow Maintained by community&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;41&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/kengz/SLM-Lab&#34; target=&#34;_blank&#34;&gt;https://github.com/kengz/SLM-Lab&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;PyTorch Maintained by Wah Loon Keng, Laura Graesser&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;42&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/google/dopamine&#34; target=&#34;_blank&#34;&gt;https://github.com/google/dopamine&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Tensorflow Maintained by Google&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;43&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/openai/spinningup&#34; target=&#34;_blank&#34;&gt;https://github.com/openai/spinningup&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Tensorflow Maintained by OpenAI&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;44&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/deepmind/trfl&#34; target=&#34;_blank&#34;&gt;https://github.com/deepmind/trfl&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Tensorflow Maintained by DeepMind&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;45&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/deepmind/scalable_agent&#34; target=&#34;_blank&#34;&gt;https://github.com/deepmind/scalable_agent&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Tensorflow Maintained by DeepMind&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;46&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/facebookresearch/ELF&#34; target=&#34;_blank&#34;&gt;https://github.com/facebookresearch/ELF&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;PyTorch Maintained by Facebook&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;47&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/keras-rl/keras-rl&#34; target=&#34;_blank&#34;&gt;https://github.com/keras-rl/keras-rl&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Tensorflow Maintained by Matthias Plappert&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;48&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail&#34; target=&#34;_blank&#34;&gt;https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;PyTorch Maintained by Ilya Kostrikov&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;49&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/Kaixhin/Rainbow&#34; target=&#34;_blank&#34;&gt;https://github.com/Kaixhin/Rainbow&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;PyTorch Maintained by Kai Arulkumaran&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;50&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/MillionIntegrals/vel&#34; target=&#34;_blank&#34;&gt;https://github.com/MillionIntegrals/vel&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;PyTorch Maintained by Jerry (?)&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;51&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/Khrylx/PyTorch-RL&#34; target=&#34;_blank&#34;&gt;https://github.com/Khrylx/PyTorch-RL&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;PyTorch&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;52&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/tensorforce/tensorforce&#34; target=&#34;_blank&#34;&gt;https://github.com/tensorforce/tensorforce&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Tensorflow&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;53&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/higgsfield/RL-Adventure&#34; target=&#34;_blank&#34;&gt;https://github.com/higgsfield/RL-Adventure&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;PyTorch&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;54&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/qfettes/DeepRL-Tutorials&#34; target=&#34;_blank&#34;&gt;https://github.com/qfettes/DeepRL-Tutorials&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;PyTorch&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;55&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/SurrealAI/surreal&#34; target=&#34;_blank&#34;&gt;https://github.com/SurrealAI/surreal&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;TorchX&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;56&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/zuoxingdong/lagom&#34; target=&#34;_blank&#34;&gt;https://github.com/zuoxingdong/lagom&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;PyTorch&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;57&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/dennybritz/reinforcement-learning&#34; target=&#34;_blank&#34;&gt;https://github.com/dennybritz/reinforcement-learning&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Tensorflow&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;58&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/unixpickle/anyrl-py&#34; target=&#34;_blank&#34;&gt;https://github.com/unixpickle/anyrl-py&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Tensorflow&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;59&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/Scitator/rl-course-experiments&#34; target=&#34;_blank&#34;&gt;https://github.com/Scitator/rl-course-experiments&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Tensorflow&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;60&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/oxwhirl/pymarl&#34; target=&#34;_blank&#34;&gt;https://github.com/oxwhirl/pymarl&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;PyTorch&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;</description>
      
    </item>
    
  </channel>
</rss>
