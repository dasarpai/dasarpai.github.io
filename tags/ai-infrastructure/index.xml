<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI Infrastructure on </title>
    <link>/tags/ai-infrastructure/</link>
    <description>Recent content in AI Infrastructure on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <managingEditor>hari@dasarpai.com (Dr. Hari Thapliyaal)</managingEditor>
    <webMaster>hari@dasarpai.com (Dr. Hari Thapliyaal)</webMaster>
    <copyright>Â© 2025 Dr. Hari Thapliyaal</copyright>
    <lastBuildDate>Thu, 14 Nov 2024 00:00:00 +0000</lastBuildDate><atom:link href="/tags/ai-infrastructure/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Navigating the LLM Infrastructure Landscape</title>
      <link>/dsblog/navigating-llm-infrastructure-landscape/</link>
      <pubDate>Thu, 14 Nov 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>/dsblog/navigating-llm-infrastructure-landscape/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;/assets/images/dspost/dsp6181-llm-infrastructure.jpg&#34; alt=&#34;Navigating the LLM Infrastructure Landscape&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Navigating the LLM Infrastructure Landscape: From Cloud Giants to Specialized Providers 
    &lt;div id=&#34;navigating-the-llm-infrastructure-landscape-from-cloud-giants-to-specialized-providers&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#navigating-the-llm-infrastructure-landscape-from-cloud-giants-to-specialized-providers&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;&lt;strong&gt;1. Introduction&lt;/strong&gt; 
    &lt;div id=&#34;1-introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#1-introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;The rapid advancement of Large Language Models (LLMs) has revolutionized a wide range of industries, from customer support to content creation and beyond. As LLMs like GPT-4, T5, and BERT become integral to AI-driven applications, the need for specialized infrastructure to support their deployment, training, and scaling has grown significantly. Traditional cloud services, while effective for general-purpose computing, often fall short in addressing the unique challenges posed by these models, such as handling vast amounts of data, providing low-latency responses, and managing the immense computational load. As a result, businesses and developers are increasingly turning to platforms specifically optimized for LLMs.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Open Source vs Closed Source AI</title>
      <link>/dsblog/Open-Source-vs-Closed-Source-AI/</link>
      <pubDate>Tue, 06 Aug 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>/dsblog/Open-Source-vs-Closed-Source-AI/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;/assets/images/dspost/dsp6134-Open-Source-vs-Closed-Source-AI.jpg&#34; alt=&#34;Open-Source-vs-Closed-Source-AI&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Open Source AI vs Closed Source AI 
    &lt;div id=&#34;open-source-ai-vs-closed-source-ai&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#open-source-ai-vs-closed-source-ai&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;Major players in the AI industry, such as Google, Microsoft, IBM, Salesforce, etc each have their own proprietary models and infrastructure to host these models. They offer AI services that companies use to develop AI products for either their end customers or internal use. Training or developing AI models requires expensive hardware and highly skilled personnel, making it a costly process. However, the deployment and inference stages are even more expensive, as they involve ongoing costs for hardware and monitoring.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>How Much Memory Needed for LLM</title>
      <link>/dsblog/How-Much-Memory-Needed-for-LLM/</link>
      <pubDate>Mon, 05 Aug 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>/dsblog/How-Much-Memory-Needed-for-LLM/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;/assets/images/dspost/dsp6133-How-Much-Memory-Needed-for-LLM.jpg&#34; alt=&#34;How-Much-Memory-Needed-for-LLM&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;How Much Memory Needed for LLM? 
    &lt;div id=&#34;how-much-memory-needed-for-llm&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#how-much-memory-needed-for-llm&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What is LLM? 
    &lt;div id=&#34;what-is-llm&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-llm&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;LLM stands for &lt;strong&gt;Large Language Model&lt;/strong&gt;. These are machine learning models that are trained on massive amounts of text data to understand, generate, and work with human language in a way that mimics natural language understanding. They are called &amp;ldquo;large&amp;rdquo; because of the significant number of parameters they contain, often numbering in the billions or even trillions.&lt;/p&gt;</description>
      
    </item>
    
  </channel>
</rss>
