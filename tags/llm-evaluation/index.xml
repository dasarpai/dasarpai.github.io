<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LLM Evaluation on </title>
    <link>/tags/llm-evaluation/</link>
    <description>Recent content in LLM Evaluation on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <managingEditor>hari@dasarpai.com (Dr. Hari Thapliyaal)</managingEditor>
    <webMaster>hari@dasarpai.com (Dr. Hari Thapliyaal)</webMaster>
    <copyright>© 2025 Dr. Hari Thapliyaal</copyright>
    <lastBuildDate>Tue, 15 Apr 2025 00:00:00 +0000</lastBuildDate><atom:link href="/tags/llm-evaluation/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>LLM Internal Encoding of Truthfulness and Hallucinations</title>
      <link>/dsblog/ps-LLM-Internal-Encoding-of-Truthfulness-and-Hallucinations/</link>
      <pubDate>Tue, 15 Apr 2025 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>/dsblog/ps-LLM-Internal-Encoding-of-Truthfulness-and-Hallucinations/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;/assets/images/dspost/dsp6260-LLM-Internal-Encoding-of-Truthfulness-and-Hallucinations.jpg&#34; alt=&#34;LLM Internal Encoding of Truthfulness and Hallucinations&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Paper Summary: LLM Internal Encoding of Truthfulness and Hallucinations 
    &lt;div id=&#34;paper-summary-llm-internal-encoding-of-truthfulness-and-hallucinations&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#paper-summary-llm-internal-encoding-of-truthfulness-and-hallucinations&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;The objective of this paper is to gain a deeper understanding of errors produced by large language models (LLMs) by examining their internal representations. The authors aim to reveal how information about the truthfulness of LLM outputs is encoded internally, going beyond extrinsic, behavioral analysis. They also seek to investigate the relationship between these internal representations and the external behavior of LLMs, including their tendency to produce inaccuracies or &amp;ldquo;hallucinations&amp;rdquo;. Furthermore, the paper intends to explore whether internal representations can be used to predict the types of errors LLMs make and to detect the correct answer even when the model generates an incorrect one.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>AI Benchmarks for 2025</title>
      <link>/dsblog/ai-benchmarks-2025/</link>
      <pubDate>Wed, 09 Apr 2025 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>/dsblog/ai-benchmarks-2025/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;/assets/images/dspost/dsp6256-aibenchmarks-for-2025.jpg&#34; alt=&#34;AI Benchmark for 2025&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;AI Benchmarks for 2025 
    &lt;div id=&#34;ai-benchmarks-for-2025&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#ai-benchmarks-for-2025&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;A term &lt;strong&gt;&amp;ldquo;AI benchmark&amp;rdquo;&lt;/strong&gt; is thrown around a lot and can be confusing because it’s used in slightly different ways depending on the context. In this artcile we will try to understand what are the different meaning of this term and what are the latest AI benchmarks.&lt;/p&gt;</description>
      
    </item>
    
  </channel>
</rss>
