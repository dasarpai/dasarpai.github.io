<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI/ML Models on </title>
    <link>http://localhost:1313/categories/ai/ml-models/</link>
    <description>Recent content in AI/ML Models on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <managingEditor>hari@dasarpai.com (Dr. Hari Thapliyaal)</managingEditor>
    <webMaster>hari@dasarpai.com (Dr. Hari Thapliyaal)</webMaster>
    <copyright>© 2025 Dr. Hari Thapliyaal</copyright>
    <lastBuildDate>Mon, 21 Apr 2025 00:00:00 +0000</lastBuildDate><atom:link href="http://localhost:1313/categories/ai/ml-models/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>BitNet b1.58-2B4T: Revolutionary Binary Neural Network for Efficient AI</title>
      <link>http://localhost:1313/dsblog/BitNet-b1-58-2B4T-for-efficient-ai-processing/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/BitNet-b1-58-2B4T-for-efficient-ai-processing/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6263-BitNet-b1.58-2B4T.jpg&#34; alt=&#34;BitNet b1.58-2B4T&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2504.12285&#34; target=&#34;_blank&#34;&gt;Archive Paper Link&lt;/a&gt;&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;BitNet b1.58-2B4T: The Future of Efficient AI Processing 
    &lt;div id=&#34;bitnet-b158-2b4t-the-future-of-efficient-ai-processing&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#bitnet-b158-2b4t-the-future-of-efficient-ai-processing&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;A History of 1 bit Transformer Model 
    &lt;div id=&#34;a-history-of-1-bit-transformer-model&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#a-history-of-1-bit-transformer-model&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;A paper &amp;ldquo;The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits&amp;rdquo; was published by Stanford University, ETH Zürich, and EPFL. It was published on October 2023 (published on arXiv on October 17, 2023). &lt;a href=&#34;https://arxiv.org/pdf/2310.11453&#34; target=&#34;_blank&#34;&gt;Standord Paper Link&lt;/a&gt;. The core Concept of 1.58 bits per parameter, was introduced here. This demonstrated that LLMs could be effectively trained and operated with extremely low-bit representation while maintaining competitive performance&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Retrieval-Augmented Generation with Conflicting Evidence</title>
      <link>http://localhost:1313/dsblog/ps-Retrieval-Augmented-Generation-with-Conflicting-Evidence/</link>
      <pubDate>Thu, 17 Apr 2025 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/ps-Retrieval-Augmented-Generation-with-Conflicting-Evidence/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6261-Retrieval-Augmented-Generation-with-Conflicting-Evidence.jpg&#34; alt=&#34;&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Paper Summary: Retrieval-Augmented Generation with Conflicting Evidence 
    &lt;div id=&#34;paper-summary-retrieval-augmented-generation-with-conflicting-evidence&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#paper-summary-retrieval-augmented-generation-with-conflicting-evidence&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2504.13079&#34; target=&#34;_blank&#34;&gt;arXiv Paper&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The hypothesis of this paper is that &lt;strong&gt;real-world retrieval-augmented generation (RAG) systems must simultaneously handle various sources of conflicting information, including ambiguity in user queries and contradictory information arising from misinformation and noise in retrieved documents&lt;/strong&gt;. The authors argue that prior work has largely addressed these challenges in isolation.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Exploring Reasoning Models in AI Marketplace, Feb 25</title>
      <link>http://localhost:1313/dsblog/exploring-reasoning-models/</link>
      <pubDate>Wed, 26 Feb 2025 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/exploring-reasoning-models/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6229-Exploring-Reasoning-Models.jpg&#34; alt=&#34;&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Exploring Reasoning Models in AI Marketplace - Feb&#39;2025 
    &lt;div id=&#34;exploring-reasoning-models-in-ai-marketplace---feb2025&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#exploring-reasoning-models-in-ai-marketplace---feb2025&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;&lt;strong&gt;What Makes a Model a &amp;ldquo;Reasoning Model&amp;rdquo;?&lt;/strong&gt; 
    &lt;div id=&#34;what-makes-a-model-a&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-makes-a-model-a&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;The term &amp;ldquo;reasoning model&amp;rdquo; is not strictly defined but generally refers to models that &lt;strong&gt;explicitly demonstrate structured problem-solving abilities&lt;/strong&gt;, such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Logical inference&lt;/strong&gt; (deductive/inductive reasoning)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multi-step problem-solving&lt;/strong&gt; (e.g., math, coding, puzzles)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Common-sense reasoning&lt;/strong&gt; (understanding implicit context)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Causal reasoning&lt;/strong&gt; (connecting causes and effects).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Modern models achieve this through architectural innovations (e.g., chain-of-thought prompting, sparse attention) and training on datasets enriched with reasoning tasks (e.g., math problems, logic puzzles).&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Exploring DeepSeek R1: The AI That Thinks Like a Human</title>
      <link>http://localhost:1313/dsblog/exploring-deepseek-r1/</link>
      <pubDate>Tue, 25 Feb 2025 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/exploring-deepseek-r1/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6228-Exploring-DeepSeek-R1.jpg&#34; alt=&#34;&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Exploring DeepSeek R1: The AI That Thinks Like a Human 
    &lt;div id=&#34;exploring-deepseek-r1-the-ai-that-thinks-like-a-human&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#exploring-deepseek-r1-the-ai-that-thinks-like-a-human&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;Artificial Intelligence (AI) has come a long way, but few models have captured the imagination of researchers, developers, and businesses like &lt;strong&gt;DeepSeek R1&lt;/strong&gt;. Developed by &lt;strong&gt;DeepSeek&lt;/strong&gt;, a cutting-edge AI research organization, DeepSeek R1 is not just another AI model—it’s a reasoning engine designed to tackle complex tasks with human-like precision. Whether it’s solving intricate math problems, writing code, or analyzing data, DeepSeek R1 is reasoning in every step. In this article, we’ll explore into what makes DeepSeek R1 special, how it works, and why it’s a game-changer for industries and individuals alike.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Integrating Ollama AI Models and Open WebUI with Docker: A Step-by-Step Guide</title>
      <link>http://localhost:1313/dsblog/integrating-ollama-and-open-webui-with-docker/</link>
      <pubDate>Mon, 24 Feb 2025 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/integrating-ollama-and-open-webui-with-docker/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6227-Integrating-Ollama-and-Open-WebUI-on-Docker.jpg&#34; alt=&#34;&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Integrating Ollama AI Models and Open WebUI on Docker 
    &lt;div id=&#34;integrating-ollama-ai-models-and-open-webui-on-docker&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#integrating-ollama-ai-models-and-open-webui-on-docker&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Introduction 
    &lt;div id=&#34;introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Ollama, Opensource LLM Framework from Meta, provides a powerful way to work with large language models (LLMs) efficiently. While Open WebUI is a user-friendly interface that simplifies interaction with Ollama-hosted AI models. You can host Ollama and WebUI on your local machine. By using Docker, we can containerize these components, ensuring a seamless and reproducible setup across different environments. This guide will walk you through integrating Ollama and Open WebUI within Docker.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Exploring the Local Location of Ollama Models on WSL2</title>
      <link>http://localhost:1313/dsblog/exploring-ollama-models-location-on-wsl2/</link>
      <pubDate>Mon, 17 Feb 2025 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/exploring-ollama-models-location-on-wsl2/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6220-Exploring-the-Local-Location-of-Ollama-Models-on-wsl2.jpg&#34; alt=&#34;Exploring the Location of Ollama Models on Local Machine&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Exploring the Location of Ollama Models on Local Machine 
    &lt;div id=&#34;exploring-the-location-of-ollama-models-on-local-machine&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#exploring-the-location-of-ollama-models-on-local-machine&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Objective 
    &lt;div id=&#34;objective&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#objective&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Many times you may have a question like, I have installed ollama in wsl and download some ollama models. Ollama list shows me those models. I want to know where they are stored. Why it is needed? Because you want to use that location as volume in your docker container. And you don&amp;rsquo;t want to download the model everytime you start the container neither you want to have duplicate copy of the same model on your machine or network.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>State of the Art Image Generation Models in Computer Vision: A Comprehensive Overview</title>
      <link>http://localhost:1313/dsblog/state-of-the-art-image-generation-models-in-computer-vision/</link>
      <pubDate>Sun, 16 Feb 2025 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/state-of-the-art-image-generation-models-in-computer-vision/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6219-State-of-the-Art-Computer-Vision-Models.jpg&#34; alt=&#34;State-of-the-Art 3D Image Generation Models&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;State of the Art Computer Vision Models 
    &lt;div id=&#34;state-of-the-art-computer-vision-models&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#state-of-the-art-computer-vision-models&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What are the different methods of Image generation? 
    &lt;div id=&#34;what-are-the-different-methods-of-image-generation&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-are-the-different-methods-of-image-generation&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;There are several methods for image generation. Diffusion models are currently the state-of-the-art due to their balance of quality, flexibility, and scalability. However, other methods like GANs and autoregressive models remain relevant for specific use cases. Let&amp;rsquo;s see them one by one.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Exploring Tokenization and Embedding in NLP</title>
      <link>http://localhost:1313/dsblog/exploring-tokenization-and-embedding-in-nlp/</link>
      <pubDate>Fri, 31 Jan 2025 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/exploring-tokenization-and-embedding-in-nlp/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6215-Exploring-Tokenization-in-AI.jpg&#34; alt=&#34;Exploring Tokenization and Embedding in NLP&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Exploring Tokenization and Embedding in NLP 
    &lt;div id=&#34;exploring-tokenization-and-embedding-in-nlp&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#exploring-tokenization-and-embedding-in-nlp&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;Tokenization and embedding are key components of natural language processing (NLP) models. Sometimes people misunderstand tokenization and embedding and this article is to address those issues. This is in the question answer format and addressing following questions.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;What is tokenization?&lt;/li&gt;
&lt;li&gt;What are different Tokenzation schemes?&lt;/li&gt;
&lt;li&gt;What is OOV (Out-of-Vocabulary) in Tokenization?&lt;/li&gt;
&lt;li&gt;If a word does not exist in embedding model&amp;rsquo;s vocabulary, then how tokenization and embedding is done?&lt;/li&gt;
&lt;li&gt;What is criteria of splitting a word?&lt;/li&gt;
&lt;li&gt;What is Subword Tokenization?&lt;/li&gt;
&lt;li&gt;How FastText Tokenization works?&lt;/li&gt;
&lt;li&gt;What is role of [CLS] token?&lt;/li&gt;
&lt;li&gt;What is WordPiece and how it works?&lt;/li&gt;
&lt;li&gt;What is BPE (Byte Pair Encoding), and how it works?&lt;/li&gt;
&lt;li&gt;What is SentencePiece and how it works?&lt;/li&gt;
&lt;li&gt;For Indian languages what tokenization schemes is the best?&lt;/li&gt;
&lt;/ol&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What is tokenization? 
    &lt;div id=&#34;what-is-tokenization&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-tokenization&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Tokenization is the process of breaking text into smaller units (tokens), such as words, subwords, or characters, for NLP tasks.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Understanding Contextual Embedding in Transformers</title>
      <link>http://localhost:1313/dsblog/understanding-contextual-embedding-in-transformers/</link>
      <pubDate>Thu, 30 Jan 2025 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/understanding-contextual-embedding-in-transformers/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6214-Understanding-Contextual-Embedding-in-Transformer.jpg&#34; alt=&#34;Understanding Contextual Embedding in Transformers&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Introduction 
    &lt;div id=&#34;introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Embedding can be confusing for many people, and contextual embedding performed by transformers can be even more perplexing. Even after gaining an understanding, many questions remain. In this article, we aim to address the following questions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What is Embedding?&lt;/li&gt;
&lt;li&gt;What is Fixed Embedding?&lt;/li&gt;
&lt;li&gt;How Transformers Handle Context&lt;/li&gt;
&lt;li&gt;How this token &amp;lsquo;bank&amp;rsquo; and corresponding embedding is stored in embedding database?&lt;/li&gt;
&lt;li&gt;How contextural embedding is generated?&lt;/li&gt;
&lt;li&gt;What will be the output size of attention formula softmax?&lt;/li&gt;
&lt;li&gt;What is meaning of a LLM has context length of 2 million tokens?&lt;/li&gt;
&lt;li&gt;How many attention layers we keep in transformer like gpt4?&lt;/li&gt;
&lt;li&gt;What is the meaning of 96 attention layers, are they attention head count?&lt;/li&gt;
&lt;/ul&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What is Embedding? 
    &lt;div id=&#34;what-is-embedding&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-embedding&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;An embedding is a way to represent discrete data (like words or tokens) as continuous vectors of numbers.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Understanding the Working of CNN</title>
      <link>http://localhost:1313/dsblog/understanding-working-of-cnn/</link>
      <pubDate>Wed, 29 Jan 2025 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/understanding-working-of-cnn/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6213-Understanding-Working-of-CNN.jpg&#34; alt=&#34;Understanding the Working of CNN&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Understanding the Working of CNN 
    &lt;div id=&#34;understanding-the-working-of-cnn&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#understanding-the-working-of-cnn&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;In this article, we aim to delve deeper into the working of CNNs. This article is intended for readers who have a basic understanding of CNNs and have computation-related questions. If you have any other questions about CNNs, feel free to ask in the comments.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Power of Chinese AI Models</title>
      <link>http://localhost:1313/dsblog/power-of-chinese-ai-models/</link>
      <pubDate>Tue, 28 Jan 2025 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/power-of-chinese-ai-models/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6212-Power-of-Chinese-AI-Models.jpg&#34; alt=&#34;Power of Chinese AI Models&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Power of Chinese AI Models 
    &lt;div id=&#34;power-of-chinese-ai-models&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#power-of-chinese-ai-models&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Introduction 
    &lt;div id=&#34;introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;After the Deepseek R1 turmoil in the market, there has been a shift in attention towards China. The West is now looking towards the East, and even those in the East are turning their gaze northward.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Exploring Types of Models</title>
      <link>http://localhost:1313/dsblog/exploring-types-of-models/</link>
      <pubDate>Sat, 25 Jan 2025 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/exploring-types-of-models/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6209-Exploring-Types-of-Models.jpg&#34; alt=&#34;Exploring Types of Models&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Understanding Different Types of Models 
    &lt;div id=&#34;understanding-different-types-of-models&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#understanding-different-types-of-models&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Introduction 
    &lt;div id=&#34;introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;A model is a simplified representation or abstraction of a system, concept, or phenomenon around us. It is used to analyze, understand, predict, or simulate real-world behavior. Models can take many forms, depending on the context in which they are used. For example you also say that I have created a Data Model, Functional Model, UI Model, Simulation Model etc.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Exploring AI Agents</title>
      <link>http://localhost:1313/dsblog/exploring-ai-agents/</link>
      <pubDate>Thu, 23 Jan 2025 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/exploring-ai-agents/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6207-Exploring-AI-Agents.jpg&#34; alt=&#34;Exploring AI Agents&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Exploring AI Agents 
    &lt;div id=&#34;exploring-ai-agents&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#exploring-ai-agents&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Introduction 
    &lt;div id=&#34;introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;As of the start of 2025, we are hearing a lot of buzz around Agents, Workflow, System, AI Employee etc. In this article, we are trying to understand some important concepts around these terms in question answer format. These answers are derived from general AI knowledge, principles, and concepts based on publicly available information about AI agents, workflows, and systems. Specific sources include academic literature, industry whitepapers, and commonly understood practices in AI development and usage.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Adapting AI Models to the Latest Information: Methods and Approaches</title>
      <link>http://localhost:1313/dsblog/adapting-ai-models-to-the-latest-information/</link>
      <pubDate>Fri, 17 Jan 2025 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/adapting-ai-models-to-the-latest-information/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6202-Adapting-AI-Models-to-the-Latest-Information.jpg&#34; alt=&#34;&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Adapting AI Models to the Latest Information: Methods and Approaches 
    &lt;div id=&#34;adapting-ai-models-to-the-latest-information-methods-and-approaches&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#adapting-ai-models-to-the-latest-information-methods-and-approaches&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Introduction 
    &lt;div id=&#34;introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Artificial Intelligence offers numerous advantages over traditional search engines like Google or Bing, but it also has a notable limitation: its knowledge is often frozen in the past. Unless a model is retrained or updated with newly available data, it cannot respond effectively to current business, political, social, or scientific developments.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Visualizing Transformers and Attention</title>
      <link>http://localhost:1313/dsblog/Visualizing-transformers-and-attention/</link>
      <pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Visualizing-transformers-and-attention/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6189-Visualizing-transformers-and-attention.jpg&#34; alt=&#34;Visualizing transformers and attention&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Visualizing Transformers and Attention 
    &lt;div id=&#34;visualizing-transformers-and-attention&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#visualizing-transformers-and-attention&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;This is the summary note from Grant Sanderson&amp;rsquo;s talk at TNG Big Tech 2024. My earlir article on transformers can be found &lt;a href=&#34;../../../dsblog/transformers-demystified-a-step-by-step-guide&#34;&gt;here&lt;/a&gt;&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;&lt;strong&gt;Transformers and Their Flexibility&lt;/strong&gt; 
    &lt;div id=&#34;transformers-and-their-flexibility&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#transformers-and-their-flexibility&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;📜 &lt;strong&gt;Origin:&lt;/strong&gt; Introduced in 2017 in the &amp;ldquo;Attention is All You Need&amp;rdquo; paper, originally for machine translation.&lt;/li&gt;
&lt;li&gt;🌍 &lt;strong&gt;Applications Beyond Translation:&lt;/strong&gt; Used in transcription (e.g., Whisper), text-to-speech, and even image classification.&lt;/li&gt;
&lt;li&gt;🤖 &lt;strong&gt;Chatbot Models:&lt;/strong&gt; Focused on models trained to predict the next token in a sequence, generating text iteratively one token at a time.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;


&lt;h2 class=&#34;relative group&#34;&gt;&lt;strong&gt;Next Token Prediction and Creativity&lt;/strong&gt; 
    &lt;div id=&#34;next-token-prediction-and-creativity&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#next-token-prediction-and-creativity&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;🔮 &lt;strong&gt;Prediction Process:&lt;/strong&gt; Predicts probabilities for possible next tokens, selects one, and repeats the process.&lt;/li&gt;
&lt;li&gt;🌡️ &lt;strong&gt;Temperature Control:&lt;/strong&gt; Adjusting randomness in token selection affects creativity vs. predictability in outputs.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;


&lt;h2 class=&#34;relative group&#34;&gt;&lt;strong&gt;Tokens and Tokenization&lt;/strong&gt; 
    &lt;div id=&#34;tokens-and-tokenization&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#tokens-and-tokenization&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;🧩 &lt;strong&gt;What are Tokens?&lt;/strong&gt; Subdivisions of input data (words, subwords, punctuation, or image patches).&lt;/li&gt;
&lt;li&gt;🔡 &lt;strong&gt;Why Not Characters?&lt;/strong&gt; Using characters increases context size and computational complexity; tokens balance meaning and computational efficiency.&lt;/li&gt;
&lt;li&gt;📖 &lt;strong&gt;Byte Pair Encoding (BPE):&lt;/strong&gt; A common method for tokenization.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;


&lt;h2 class=&#34;relative group&#34;&gt;&lt;strong&gt;Embedding Tokens into Vectors&lt;/strong&gt; 
    &lt;div id=&#34;embedding-tokens-into-vectors&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#embedding-tokens-into-vectors&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;📏 &lt;strong&gt;Embedding:&lt;/strong&gt; Tokens are mapped to high-dimensional vectors representing their meaning.&lt;/li&gt;
&lt;li&gt;🗺️ &lt;strong&gt;Contextual Meaning:&lt;/strong&gt; Vectors evolve through the network to capture context, disambiguate meaning, and encode relationships.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;


&lt;h2 class=&#34;relative group&#34;&gt;&lt;strong&gt;The Attention Mechanism&lt;/strong&gt; 
    &lt;div id=&#34;the-attention-mechanism&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#the-attention-mechanism&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;🔍 &lt;strong&gt;Purpose:&lt;/strong&gt; Enables tokens to &amp;ldquo;attend&amp;rdquo; to others, updating their vectors based on relevance.&lt;/li&gt;
&lt;li&gt;🔑 &lt;strong&gt;Key Components:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Query Matrix: Encodes what a token is &amp;ldquo;looking for.&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Key Matrix: Encodes how a token responds to queries.&lt;/li&gt;
&lt;li&gt;Value Matrix: Encodes information passed between tokens.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;🧮 &lt;strong&gt;Calculations:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Dot Product: Measures alignment between keys and queries.&lt;/li&gt;
&lt;li&gt;Softmax: Converts dot products into normalized weights for updates.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;⛓️ &lt;strong&gt;Masked Attention:&lt;/strong&gt; Ensures causality by blocking future tokens from influencing past ones.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;


&lt;h2 class=&#34;relative group&#34;&gt;&lt;strong&gt;Multi-Headed Attention&lt;/strong&gt; 
    &lt;div id=&#34;multi-headed-attention&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#multi-headed-attention&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;💡 &lt;strong&gt;Parallel Heads:&lt;/strong&gt; Multiple attention heads allow different types of relationships (e.g., grammar, semantic context) to be processed simultaneously.&lt;/li&gt;
&lt;li&gt;🚀 &lt;strong&gt;Efficiency on GPUs:&lt;/strong&gt; Designed to maximize parallelization for faster computation.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;


&lt;h2 class=&#34;relative group&#34;&gt;&lt;strong&gt;Multi-Layer Perceptrons (MLPs)&lt;/strong&gt; 
    &lt;div id=&#34;multi-layer-perceptrons-mlps&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#multi-layer-perceptrons-mlps&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;🤔 &lt;strong&gt;Role in Transformers:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Add capacity for general knowledge and non-contextual reasoning.&lt;/li&gt;
&lt;li&gt;Store facts learned during training, e.g., associations like &amp;ldquo;Michael Jordan plays basketball.&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;🔢 &lt;strong&gt;Parameters:&lt;/strong&gt; MLPs hold the majority of the model’s parameters.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;


&lt;h2 class=&#34;relative group&#34;&gt;&lt;strong&gt;Training Transformers&lt;/strong&gt; 
    &lt;div id=&#34;training-transformers&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#training-transformers&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;📚 &lt;strong&gt;Learning Framework:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Models are trained on vast datasets using next-token prediction, requiring no manual labels.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cost Function:&lt;/strong&gt; Measures prediction accuracy using negative log probabilities, guiding parameter updates.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;🏔️ &lt;strong&gt;Optimization:&lt;/strong&gt; Gradient descent navigates a high-dimensional cost surface to minimize error.&lt;/li&gt;
&lt;li&gt;🌐 &lt;strong&gt;Pretraining:&lt;/strong&gt; Allows large-scale unsupervised learning before fine-tuning with human feedback.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;


&lt;h2 class=&#34;relative group&#34;&gt;&lt;strong&gt;Embedding Space and High Dimensions&lt;/strong&gt; 
    &lt;div id=&#34;embedding-space-and-high-dimensions&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#embedding-space-and-high-dimensions&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;🔄 &lt;strong&gt;Semantic Clusters:&lt;/strong&gt; Similar words cluster together; directions in the space encode relationships (e.g., gender: King - Male + Female = Queen).&lt;/li&gt;
&lt;li&gt;🌌 &lt;strong&gt;High Dimensionality:&lt;/strong&gt; Embedding spaces have thousands of dimensions, enabling distinct representations of complex concepts.&lt;/li&gt;
&lt;li&gt;📈 &lt;strong&gt;Scaling Efficiency:&lt;/strong&gt; High-dimensional spaces allow exponentially more &amp;ldquo;almost orthogonal&amp;rdquo; directions for encoding meanings.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;


&lt;h2 class=&#34;relative group&#34;&gt;&lt;strong&gt;Practical Applications&lt;/strong&gt; 
    &lt;div id=&#34;practical-applications&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#practical-applications&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;✍️ &lt;strong&gt;Language Models:&lt;/strong&gt; Effective for chatbots, summarization, and more due to their generality and parallel processing.&lt;/li&gt;
&lt;li&gt;🖼️ &lt;strong&gt;Multimodal Models:&lt;/strong&gt; Transformers can integrate text, images, and sound by treating all as tokens in a unified framework.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;


&lt;h2 class=&#34;relative group&#34;&gt;&lt;strong&gt;Challenges and Limitations&lt;/strong&gt; 
    &lt;div id=&#34;challenges-and-limitations&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#challenges-and-limitations&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;📏 &lt;strong&gt;Context Size Limitations:&lt;/strong&gt; Attention grows quadratically with context size, requiring optimization for large contexts.&lt;/li&gt;
&lt;li&gt;♻️ &lt;strong&gt;Inference Redundancy:&lt;/strong&gt; Token-by-token generation can involve redundant computations; caching mitigates this at inference time.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;


&lt;h2 class=&#34;relative group&#34;&gt;&lt;strong&gt;Engineering and Design&lt;/strong&gt; 
    &lt;div id=&#34;engineering-and-design&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#engineering-and-design&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;🛠️ &lt;strong&gt;Hardware Optimization:&lt;/strong&gt; Transformers are designed to exploit GPUs&amp;rsquo; parallelism for efficient matrix multiplication.&lt;/li&gt;
&lt;li&gt;🔗 &lt;strong&gt;Residual Connections:&lt;/strong&gt; Baked into the architecture to enhance stability and ease of training.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;


&lt;h2 class=&#34;relative group&#34;&gt;&lt;strong&gt;The Power of Scale&lt;/strong&gt; 
    &lt;div id=&#34;the-power-of-scale&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#the-power-of-scale&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;📈 &lt;strong&gt;Scaling Laws:&lt;/strong&gt; Larger models and more data improve performance, often qualitatively.&lt;/li&gt;
&lt;li&gt;🔄 &lt;strong&gt;Self-Supervised Pretraining:&lt;/strong&gt; Enables training on vast unlabeled datasets before fine-tuning.&lt;/li&gt;
&lt;/ul&gt;


&lt;h2 class=&#34;relative group&#34;&gt;&lt;strong&gt;BPE (Byte Pair Encoding)&lt;/strong&gt; 
    &lt;div id=&#34;bpe-byte-pair-encoding&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#bpe-byte-pair-encoding&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;BPE is a widely used tokenization method in natural language processing (NLP) and machine learning. It is designed to balance between breaking text into characters and full words by representing text as a sequence of subword units. This approach helps models handle rare and unseen words effectively while keeping the vocabulary size manageable.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>AI Models and Creators</title>
      <link>http://localhost:1313/dsblog/AI-Models-and-Creators/</link>
      <pubDate>Tue, 10 Dec 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/AI-Models-and-Creators/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6187-ai-models-and-creators.jpg&#34; alt=&#34;AI Models and Creators&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;AI Models and Creators 
    &lt;div id=&#34;ai-models-and-creators&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#ai-models-and-creators&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Popular Models and Their Creator 
    &lt;div id=&#34;popular-models-and-their-creator&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#popular-models-and-their-creator&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Nova - Amazon&lt;/li&gt;
&lt;li&gt;Gemini, Gemma - Google&lt;/li&gt;
&lt;li&gt;Granite - Oracle&lt;/li&gt;
&lt;li&gt;GPT - OpenAI&lt;/li&gt;
&lt;li&gt;Phi - Microsoft Azure&lt;/li&gt;
&lt;li&gt;Einstein - Salesforce&lt;/li&gt;
&lt;li&gt;Joule - SAP&lt;/li&gt;
&lt;li&gt;Grok - X (formerly Twitter)&lt;/li&gt;
&lt;li&gt;Llama - Meta&lt;/li&gt;
&lt;li&gt;Qwen - Alibaba&lt;/li&gt;
&lt;li&gt;Claude - Anthropic&lt;/li&gt;
&lt;li&gt;Bard - Google&lt;/li&gt;
&lt;li&gt;PaLM - Google&lt;/li&gt;
&lt;li&gt;Mistral - Mistral AI&lt;/li&gt;
&lt;li&gt;Falcon - Technology Innovation Institute (TII), UAE&lt;/li&gt;
&lt;li&gt;Gato - DeepMind&lt;/li&gt;
&lt;li&gt;Jasper - Jasper AI&lt;/li&gt;
&lt;li&gt;Bloom - BigScience (collaborative project)&lt;/li&gt;
&lt;li&gt;Ernie - Baidu&lt;/li&gt;
&lt;li&gt;Alpaca - Stanford University (fine-tuned LLaMA model)&lt;/li&gt;
&lt;li&gt;Stable Diffusion - Stability AI&lt;/li&gt;
&lt;li&gt;HuggingChat - Hugging Face&lt;/li&gt;
&lt;li&gt;Cohere of Command&lt;/li&gt;
&lt;li&gt;Alpha fold of deepmind&lt;/li&gt;
&lt;/ol&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Models Developed by Microsoft 
    &lt;div id=&#34;models-developed-by-microsoft&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#models-developed-by-microsoft&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Microsoft has developed or collaborated on several AI models and frameworks, especially as part of its Azure AI ecosystem and its partnership with OpenAI. Below is a list of models and AI systems associated with Microsoft:&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Exploring GGUF and Other Model Formats</title>
      <link>http://localhost:1313/dsblog/exploring-gguf-and-other-model-formats/</link>
      <pubDate>Tue, 12 Nov 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/exploring-gguf-and-other-model-formats/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6180-exploring-gguf.jpg&#34; alt=&#34;Understanding GGUF and Other Model Formats in Machine Learning&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;&lt;strong&gt;Understanding GGUF and Other Model Formats in Machine Learning&lt;/strong&gt; 
    &lt;div id=&#34;understanding-gguf-and-other-model-formats-in-machine-learning&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#understanding-gguf-and-other-model-formats-in-machine-learning&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;As machine learning models continue to grow in complexity, the need for efficient, flexible, and versatile model formats becomes more pronounced. While formats like ONNX, TensorFlow’s SavedModel, and PyTorch’s native format have been around for some time, newer formats like GGUF are gaining attention for their unique benefits. This article explores these formats, their use cases, and how they support various aspects of machine learning, including deployment, compatibility, and optimization.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Exploring AnythingLLM</title>
      <link>http://localhost:1313/dsblog/exploring-anythingllm/</link>
      <pubDate>Mon, 11 Nov 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/exploring-anythingllm/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6179-exploring-anythingllm.jpg&#34; alt=&#34;Exploring AnythingLLM &#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Exploring AnythingLLM 
    &lt;div id=&#34;exploring-anythingllm&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#exploring-anythingllm&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What is AnythingLLM? 
    &lt;div id=&#34;what-is-anythingllm&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-anythingllm&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;AnythingLLM is an open-source project developed by Mintplex Labs that offers a highly flexible platform for creating personalized language models and knowledge databases. It operates using Retrieval-Augmented Generation (RAG), which combines language models with data from custom document collections. AnythingLLM supports embedding models (e.g., BERT), language models, and vector databases to index and query data, allowing users to fine-tune or deploy various models tailored to their needs, from local deployments to cloud integrations with OpenAI or Azure OpenAI.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Transfer Learning Key AI Techniques Explained</title>
      <link>http://localhost:1313/dsblog/Transfer-Learning-Key-AI-Techniques-Explained/</link>
      <pubDate>Fri, 25 Oct 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Transfer-Learning-Key-AI-Techniques-Explained/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6172-Transfer-Learning-Key-AI-Techniques-Explained.jpg&#34; alt=&#34;Transfer Learning Key AI Techniques Explained&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Transfer Learning Key AI Techniques Explained 
    &lt;div id=&#34;transfer-learning-key-ai-techniques-explained&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#transfer-learning-key-ai-techniques-explained&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;In this article we will understand some important concepts used within machine learning.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What is in-context Learning?&lt;/li&gt;
&lt;li&gt;What is Prompt-Engineering?&lt;/li&gt;
&lt;li&gt;What is the relationship between Prompt Engineering and In-Context Learning?&lt;/li&gt;
&lt;li&gt;What is Zero-shot learning?&lt;/li&gt;
&lt;li&gt;How Zero-shot learning is different from In-context Learning?&lt;/li&gt;
&lt;li&gt;What is Meta-Learning?&lt;/li&gt;
&lt;li&gt;What is Few-shot learning?&lt;/li&gt;
&lt;li&gt;Do we need foundational models for Meta-learning and Few-shot learning?&lt;/li&gt;
&lt;li&gt;What is transfer learning?&lt;/li&gt;
&lt;li&gt;How do we do transfer learning from existing model?&lt;/li&gt;
&lt;li&gt;What is finetuning?&lt;/li&gt;
&lt;li&gt;Which layers to update, what weight to update during finetuning?&lt;/li&gt;
&lt;/ul&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Prompt Engineering, In Context Learning and Zero-shot Learning 
    &lt;div id=&#34;prompt-engineering-in-context-learning-and-zero-shot-learning&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#prompt-engineering-in-context-learning-and-zero-shot-learning&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;


&lt;h3 class=&#34;relative group&#34;&gt;What is in-context Learning? 
    &lt;div id=&#34;what-is-in-context-learning&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-in-context-learning&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h3&gt;
&lt;p&gt;In-Context Learning refers to a model&amp;rsquo;s ability to adapt its responses based on the context provided in the input prompt without updating its parameters or undergoing explicit training. The model uses the examples, instructions, or context given in the input to influence its behavior during inference.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Types of Large Language Models (LLM)</title>
      <link>http://localhost:1313/dsblog/Types-of-LLM/</link>
      <pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Types-of-LLM/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6171-Types-of-LLM.jpg&#34; alt=&#34;&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;&lt;strong&gt;Introduction:&lt;/strong&gt; 
    &lt;div id=&#34;introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;The world of Generative AI (GenAI) is expanding at an astonishing rate, with new models emerging almost daily, each sporting unique names, capabilities, versions, and sizes. For AI professionals, keeping track of these models can feel like a full-time job. But for business users, IT professionals, and software developers trying to make the right choice, understanding the model’s name and what it represents can seem overwhelming. Wouldn’t it be helpful if we could decode the meaning behind these names to know if a model fits our needs and is worth the investment? In this article, we’ll break down how the names of GenAI models can reveal clues about their functionality and suitability for specific tasks, helping you make informed decisions with confidence.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>AI/ML with Oracle Cloud</title>
      <link>http://localhost:1313/dsblog/AI-ML-With-Oracle-Cloud/</link>
      <pubDate>Sat, 19 Oct 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/AI-ML-With-Oracle-Cloud/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6166-AI-ML-With-Oracle-Cloud.jpg&#34; alt=&#34;AI/ML with Oracle Cloud&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;AI/ML with Oracle Cloud 
    &lt;div id=&#34;aiml-with-oracle-cloud&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#aiml-with-oracle-cloud&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/Content/services.htm&#34; target=&#34;_blank&#34;&gt;Oracle Infrastructure Services&lt;/a&gt; 
    &lt;div id=&#34;oracle-infrastructure-services&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#oracle-infrastructure-services&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Register for &lt;a href=&#34;https://www.oracle.com/cloud/free/?source=:ow:o:h:po:OHPPanel1nav0625&amp;amp;intcmp=:ow:o:h:po:OHPPanel1nav0625&#34; target=&#34;_blank&#34;&gt;Oracle Cloud Free Tier&lt;/a&gt;&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Oracle AI Main services 
    &lt;div id=&#34;oracle-ai-main-services&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#oracle-ai-main-services&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cloud.oracle.com/digital-assistant/oda-instances?region=ap-mumbai-1&#34; target=&#34;_blank&#34;&gt;Digital Assistant&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/Content/document-understanding/using/home.htm&#34; target=&#34;_blank&#34;&gt;Document Understanding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/language/using/pretrain-models.htm#lang-detect&#34; target=&#34;_blank&#34;&gt;Language&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/Content/vision/using/pretrained-model-using-image.htm&#34; target=&#34;_blank&#34;&gt;Vision&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/Content/speech/home.htm&#34; target=&#34;_blank&#34;&gt;Speech&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/Content/Streaming/home.htm&#34; target=&#34;_blank&#34;&gt;Stream&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/process-automation/oci-process-automation/overview-oci-process-automation.html&#34; target=&#34;_blank&#34;&gt;Cloud Infra Automation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h2 class=&#34;relative group&#34;&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/Content/generative-ai/home.htm&#34; target=&#34;_blank&#34;&gt;Generative AI&lt;/a&gt; 
    &lt;div id=&#34;generative-ai&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#generative-ai&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Generative AI is a fully managed Oracle Cloud Infrastructure service that provides a set of state-of-the-art, customizable large language models (LLMs) that cover a wide range of use cases, including chat, text generation, summarization, and creating text embeddings.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Exploring Synthetic Data Generation Capabilities</title>
      <link>http://localhost:1313/dsblog/Exploring-Synthetic-Data-Generation-Capabilities/</link>
      <pubDate>Wed, 16 Oct 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Exploring-Synthetic-Data-Generation-Capabilities/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6163-Exploring-Synthetic-Data-Generation-Capabilities.jpg&#34; alt=&#34;Exploring Synthetic Data Generation Capabilities&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Exploring Synthetic Data Generation Capabilities 
    &lt;div id=&#34;exploring-synthetic-data-generation-capabilities&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#exploring-synthetic-data-generation-capabilities&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Is this article for me? 
    &lt;div id=&#34;is-this-article-for-me&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#is-this-article-for-me&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Are you looking answers to these questions?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What is Synthetic Data?&lt;/li&gt;
&lt;li&gt;What is data anonymization?&lt;/li&gt;
&lt;li&gt;What are different techniques for generating Anonymized Data?&lt;/li&gt;
&lt;li&gt;Why is anonymizing not sufficient to address PII data issues?&lt;/li&gt;
&lt;li&gt;When there is lots of data available around then why do we need synthetic data?&lt;/li&gt;
&lt;li&gt;What are the challenges in synthetic data generation?&lt;/li&gt;
&lt;li&gt;What are the tools for Synthetic Data Generator for Marketing&lt;/li&gt;
&lt;li&gt;What are the tools for Graph Synthetic Data generation?&lt;/li&gt;
&lt;li&gt;List of popular synthetic data generation tools for different industries&lt;/li&gt;
&lt;/ul&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What is Synthetic Data? 
    &lt;div id=&#34;what-is-synthetic-data&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-synthetic-data&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Synthetic data&lt;/strong&gt; is artificially generated data that mimics the characteristics and statistical properties of real-world data but is not derived directly from real-world events or observations. It is created using algorithms, simulations, or models to represent patterns, structures, and relationships found in actual datasets. Synthetic data can take various forms, such as text, images, audio, or structured tabular data, depending on the context. It is used across various industries to train AI models, simulate environments, and conduct research.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Exploring Dense Embedding Models in AI</title>
      <link>http://localhost:1313/dsblog/Exploring-Dense-Embedding-Models-in-AI/</link>
      <pubDate>Thu, 10 Oct 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Exploring-Dense-Embedding-Models-in-AI/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6157-Exploring-Dense-Embedding-Models-in-AI.jpg&#34; alt=&#34;Exploring Dense Embedding Models in AI&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What is dense embedding in AI? 
    &lt;div id=&#34;what-is-dense-embedding-in-ai&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-dense-embedding-in-ai&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Dense embeddings are critical in many AI applications, particularly in deep learning, where they help reduce data complexity and enhance the model’s ability to generalize from patterns in data.&lt;/p&gt;
&lt;p&gt;In artificial intelligence (AI), &lt;strong&gt;dense embedding&lt;/strong&gt; refers to a method of representing data (like words, sentences, images, or other inputs) as dense vectors in a continuous, lower-dimensional (lessor number of dimensions) space. These vectors, known as &lt;strong&gt;embeddings&lt;/strong&gt;, encode semantic information, enabling AI models to work with data in a more meaningful way.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Introduction to Perplexity AI</title>
      <link>http://localhost:1313/dsblog/Introduction-to-Perplexity-AI/</link>
      <pubDate>Tue, 08 Oct 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Introduction-to-Perplexity-AI/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6156-Introduction-to-Perplexity-AI.jpg&#34; alt=&#34;Introduction to Perplexity AI&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Introduction to Perplexity AI 
    &lt;div id=&#34;introduction-to-perplexity-ai&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction-to-perplexity-ai&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What is Perplexity AI? 
    &lt;div id=&#34;what-is-perplexity-ai&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-perplexity-ai&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Perplexity AI Founded in 2022 is based in San Francisco, California. Perplexity AI is an AI-powered search engine that uses a large language model to answer questions and provide information. It is a free, open-source search engine that is built on top of the latest advancements in AI and natural language processing. Perplexity AI distinguishes itself as a unique blend of a search engine and an AI chatbot, offering several features that set it apart from traditional search engines like Google and other AI models such as ChatGPT.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Exploring Ollama &amp; LM Studio</title>
      <link>http://localhost:1313/dsblog/Exploring-Ollama/</link>
      <pubDate>Wed, 18 Sep 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Exploring-Ollama/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6143-Exploring-Ollama.jpg&#34; alt=&#34;Exploring Ollama &amp;amp; LM Studio&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Exploring Ollama &amp;amp; LM Studio 
    &lt;div id=&#34;exploring-ollama--lm-studio&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#exploring-ollama--lm-studio&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Is this article for me? 
    &lt;div id=&#34;is-this-article-for-me&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#is-this-article-for-me&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;If you are looking answers to the following questions, then this article is for you:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Question: What is Ollama? Is it like Docker?&lt;/li&gt;
&lt;li&gt;Question: How is Ollama different from Docker?&lt;/li&gt;
&lt;li&gt;Question: How to install ollama on my machine?&lt;/li&gt;
&lt;li&gt;Question: How to create customized LLM Model (docker like image)?&lt;/li&gt;
&lt;li&gt;Question: What are the LLM available on ollama?&lt;/li&gt;
&lt;li&gt;Question: Can we integrate these hundreds with different UI like ChatGPT?&lt;/li&gt;
&lt;li&gt;Question: If I want to use all these Ollama models via Jupyter Notebook then what to do?&lt;/li&gt;
&lt;li&gt;Question: Does Ollama have plugins like github copilot? Can I use those from my visual code?&lt;/li&gt;
&lt;li&gt;Question: What kind of software are LM Studio or Ollama?&lt;/li&gt;
&lt;li&gt;Question: What is LM Studio and how different it is from Ollama?&lt;/li&gt;
&lt;li&gt;Question: What are different formats to save model, specifically LLMs?&lt;/li&gt;
&lt;li&gt;Question: What is gguf model extention?&lt;/li&gt;
&lt;li&gt;Question: If I have finetuned my models using clouds like aws sagemaker, vertexai, azure and kept there then can I use them inside my ollama and LM Studio?&lt;/li&gt;
&lt;/ul&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Question: What is Ollama? Is it like Docker? 
    &lt;div id=&#34;question-what-is-ollama-is-it-like-docker&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#question-what-is-ollama-is-it-like-docker&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Ollama is a platform designed to make running and interacting with large language models (LLMs) easier. It abstracts away the complexities of managing LLM models, GPU resources, and related configurations by offering a simple CLI interface. With Ollama, you can run, manage, and deploy LLMs locally or in various cloud environments without having to worry about the intricate details of setting up environments, downloading models, or configuring them.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Variations of Language Model in Huggingface</title>
      <link>http://localhost:1313/dsblog/Variations-of-Language-Model-in-Huggingface/</link>
      <pubDate>Thu, 22 Aug 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Variations-of-Language-Model-in-Huggingface/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6138-Variations-of-Language-Model-in-Huggingface.jpg&#34; alt=&#34;Variations-of-LanguageModel&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Variations of Language Model in Huggingface 
    &lt;div id=&#34;variations-of-language-model-in-huggingface&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#variations-of-language-model-in-huggingface&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What the Model variable in Huggingface? 
    &lt;div id=&#34;what-the-model-variable-in-huggingface&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-the-model-variable-in-huggingface&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;We know base moels like BERT, T5, GPT2, GPT3 etc are developed by researchers working with different companies. But when we look into huggingface model repository we see other models like GPT2LMHeadModel, GPT2ForSequenceClassification, etc what are these?&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>LLM Architecture and Training</title>
      <link>http://localhost:1313/dsblog/LLM-Architecture-and-Training/</link>
      <pubDate>Sun, 04 Aug 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/LLM-Architecture-and-Training/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6129-LLM-Architecture-and-Training.jpg&#34; alt=&#34;LLM-Architecture-and-Training&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;&lt;strong&gt;Understanding LLM Architectures and Model Training&lt;/strong&gt; 
    &lt;div id=&#34;understanding-llm-architectures-and-model-training&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#understanding-llm-architectures-and-model-training&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;Large Language Models (LLMs) are transforming the field of artificial intelligence by enabling machines to understand and generate human language with unprecedented accuracy. This article delves into the architecture, training methods, and practical applications of LLMs. We’ll explore the core components that make these models so powerful and explain how they are trained and fine-tuned for real-world use cases.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Why to Finetune LLM?</title>
      <link>http://localhost:1313/dsblog/why-to-finetune-llm/</link>
      <pubDate>Sun, 28 Jul 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/why-to-finetune-llm/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6115-why-to-finetune-llm.jpg&#34; alt=&#34;Why to Finetune LLM?&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Finetuning, Fewshot Learning, Why and How? 
    &lt;div id=&#34;finetuning-fewshot-learning-why-and-how&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#finetuning-fewshot-learning-why-and-how&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Why to finetune a LLM? 
    &lt;div id=&#34;why-to-finetune-a-llm&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#why-to-finetune-a-llm&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Fine-tuning a large language model (LLM) can provide several benefits, depending on your specific needs and objectives. Here are some key reasons to consider fine-tuning an LLM:&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Stanford Alpaca</title>
      <link>http://localhost:1313/dsblog/Stanford-Alpaca/</link>
      <pubDate>Sat, 27 Jul 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Stanford-Alpaca/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6116-Stanford-Alpaca.jpg&#34; alt=&#34;Stanford-Alpaca&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Stanford Alpaca 
    &lt;div id=&#34;stanford-alpaca&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#stanford-alpaca&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Introduction 
    &lt;div id=&#34;introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca&#34; target=&#34;_blank&#34;&gt;Stanford Alpaca Github Report&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Stanford Alpaca is An &amp;ldquo;Instruction-following&amp;rdquo; LLaMA Model&lt;/li&gt;
&lt;li&gt;This is the repo aims to build and share an instruction-following LLaMA model. The repo contains:
&lt;ul&gt;
&lt;li&gt;The 52K &lt;a href=&#34;https://raw.githubusercontent.com/tatsu-lab/stanford_alpaca/main/alpaca_data.json&#34; target=&#34;_blank&#34;&gt;instruction-following data&lt;/a&gt; used for fine-tuning the model.&lt;/li&gt;
&lt;li&gt;The code for generating the data.&lt;/li&gt;
&lt;li&gt;The code for fine-tuning the model.&lt;/li&gt;
&lt;li&gt;The code for recovering Alpaca-7B weights from our released weight diff.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Overview 
    &lt;div id=&#34;overview&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#overview&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The current &amp;ldquo;Alpaca 7B model&amp;rdquo; is fine-tuned from a &amp;ldquo;7B LLaMA&amp;rdquo; model on 52K instruction-following data generated by the techniques in the Self-Instruct paper.&lt;/li&gt;
&lt;li&gt;Alpaca 7B model behaves similarly to the text-davinci-003 model on the Self-Instruct instruction-following evaluation suite.&lt;/li&gt;
&lt;li&gt;Alpaca is still under development, and there are many limitations that have to be addressed.&lt;/li&gt;
&lt;li&gt;Alphaca is not yet fine-tuned to be safe and harmless.&lt;/li&gt;
&lt;li&gt;Initial release contains the data generation procedure, dataset, and training recipe.&lt;/li&gt;
&lt;li&gt;Model weights can be released if the creators of LLaMA gives permission.&lt;/li&gt;
&lt;li&gt;Live demo to help readers better understand the capabilities and limits of Alpaca is available.&lt;/li&gt;
&lt;li&gt;Based on followin papers:
&lt;ul&gt;
&lt;li&gt;LLaMA: Open and Efficient Foundation Language Models. &lt;a href=&#34;https://arxiv.org/abs/2302.13971v1&#34; target=&#34;_blank&#34;&gt;Hugo2023&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Self-Instruct: Aligning Language Model with Self Generated Instructions. &lt;a href=&#34;https://arxiv.org/abs/2212.10560&#34; target=&#34;_blank&#34;&gt;Yizhong2022&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data Release
&lt;ul&gt;
&lt;li&gt;alpaca_data.json contains 52K instruction-following data we used for fine-tuning the Alpaca model. This JSON file is a list of dictionaries, each dictionary contains the following fields: Instruction, input, output (text-davinci-003 geneated answer).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Highlevel Activities of the Alpaca Project 
    &lt;div id=&#34;highlevel-activities-of-the-alpaca-project&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#highlevel-activities-of-the-alpaca-project&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Highlevel Actitivies done by Stanford Alpaca team and Project Output&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Understanding LLM GAN and Transformers</title>
      <link>http://localhost:1313/dsblog/Understanding-LLM-GAN-and-Transformers/</link>
      <pubDate>Fri, 26 Jul 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Understanding-LLM-GAN-and-Transformers/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6127-Understanding-LLM-GAN-and-Transformers.jpg&#34; alt=&#34;Understanding-LLM-GAN-Transformers&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Understanding LLM, GAN and Transformers 
    &lt;div id=&#34;understanding-llm-gan-and-transformers&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#understanding-llm-gan-and-transformers&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;LLM Layers 
    &lt;div id=&#34;llm-layers&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#llm-layers&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Large Language Models (LLMs) are typically based on Transformer architectures, which consist of several types of layers that work together to process and generate text. Here are the primary kinds of layers found in an LLM:&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Transformers Demystified A Step-by-Step Guide</title>
      <link>http://localhost:1313/dsblog/transformers-demystified-a-step-by-step-guide/</link>
      <pubDate>Thu, 25 Jul 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/transformers-demystified-a-step-by-step-guide/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6113-transformers-demystified-a-step-by-step-guide.jpg&#34; alt=&#34;Transformers Demystified A Step-by-Step Guide&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Transformers Demystified A Step-by-Step Guide 
    &lt;div id=&#34;transformers-demystified-a-step-by-step-guide&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#transformers-demystified-a-step-by-step-guide&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;All modern Transformers are based on a paper &amp;ldquo;Attention is all you need&amp;rdquo;&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Introduction 
    &lt;div id=&#34;introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;This was the mother paper of all the transformer architectures we see today around NLP, Multimodal, Deep Learning. It was presented by Ashish Vaswani et al from Deep Learning / Google in 2017. We will discuss following and anything whatever question/observation/idea I have.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Topic Modeling with BERT</title>
      <link>http://localhost:1313/dsblog/topic-modeling-with-bert/</link>
      <pubDate>Mon, 13 Nov 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/topic-modeling-with-bert/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6105-Topic-Modeling-with-BERT.jpg&#34; alt=&#34;Topic Modeling with BERT&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Topic Modeling with BERT 
    &lt;div id=&#34;topic-modeling-with-bert&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#topic-modeling-with-bert&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;Key steps in BERTopic modelling are as following.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use &amp;ldquo;Sentence Embedding&amp;rdquo; models to embed the sentences of the article&lt;/li&gt;
&lt;li&gt;Reduce the dimensionality of embedding using UMAP&lt;/li&gt;
&lt;li&gt;Cluster these documents (reduced dimensions) using HDBSAN&lt;/li&gt;
&lt;li&gt;Use c-TF-IDF extract keywords, their frequency and IDF for each cluster.&lt;/li&gt;
&lt;li&gt;MMR: Maximize Candidate Relevance. How many words in a topic can represent the topic?&lt;/li&gt;
&lt;li&gt;Intertopic Distance Map&lt;/li&gt;
&lt;li&gt;Use similarity matrix (heatmap), dandogram (hierarchical map), to visualize the topics and key_words.&lt;/li&gt;
&lt;li&gt;Traction of topic over time period. Some may be irrelevant and for other traction may be increasing or decreasing.&lt;/li&gt;
&lt;/ul&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Installation 
    &lt;div id=&#34;installation&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#installation&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Installation, with sentence-transformers, can be done using pypi:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;pip&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;install&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;bertopic&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# If you want to install BERTopic with other embedding models, you can choose one of the following:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Choose an embedding backend&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;pip&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;install&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;bertopic&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;flair&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;gensim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;spacy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;use&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Topic modeling with images&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;pip&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;install&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;bertopic&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vision&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h1 class=&#34;relative group&#34;&gt;Supported Topic Modelling Techniques 
    &lt;div id=&#34;supported-topic-modelling-techniques&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#supported-topic-modelling-techniques&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;BERTopic supports all kinds of topic modeling techniques as below.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Basics of Word Embedding</title>
      <link>http://localhost:1313/dsblog/basics-of-word-embedding/</link>
      <pubDate>Sat, 11 Nov 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/basics-of-word-embedding/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6101-Basics-of-Word-Embedding.jpg&#34; alt=&#34;Basics of Word Embedding&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Basics of Word Embedding 
    &lt;div id=&#34;basics-of-word-embedding&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#basics-of-word-embedding&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What is Context, target and window? 
    &lt;div id=&#34;what-is-context-target-and-window&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-context-target-and-window&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The &amp;ldquo;context&amp;rdquo; word is the surrounding word.&lt;/li&gt;
&lt;li&gt;The &amp;ldquo;target&amp;rdquo; word is the middle word.&lt;/li&gt;
&lt;li&gt;The &amp;ldquo;window distance&amp;rdquo; is number of words (including) between context words and target word. Window distance 1 means, one word surronding the target, one left side context word, one right context word. Two window distance means 2 words left and 2 words right.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let&amp;rsquo;s take a sentence&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Compressing Large Language Model</title>
      <link>http://localhost:1313/dsblog/compressing-llm/</link>
      <pubDate>Tue, 07 Nov 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/compressing-llm/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6099-Compressing-LLM.jpg&#34; alt=&#34;Compressing Large Language Model&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Compressing Large Language Model 
    &lt;div id=&#34;compressing-large-language-model&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#compressing-large-language-model&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Is this article for me? 
    &lt;div id=&#34;is-this-article-for-me&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#is-this-article-for-me&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;If you are looking answers to following question then &amp;ldquo;Yes&amp;rdquo;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What is LLM compression?&lt;/li&gt;
&lt;li&gt;Why is LLM compression necessary?&lt;/li&gt;
&lt;li&gt;What are the different techniques for LLM compression?&lt;/li&gt;
&lt;li&gt;How does quantization work in LLM compression?&lt;/li&gt;
&lt;li&gt;What is pruning, and how does it help in compressing LLMs?&lt;/li&gt;
&lt;li&gt;Can you explain knowledge distillation in the context of LLMs?&lt;/li&gt;
&lt;li&gt;What is low-rank factorization and its role in LLM compression?&lt;/li&gt;
&lt;li&gt;How effective are weight sharing techniques in compressing LLMs?&lt;/li&gt;
&lt;li&gt;What are the trade-offs involved in LLM compression?&lt;/li&gt;
&lt;li&gt;How does fine-tuning work in the context of compressed LLMs?&lt;/li&gt;
&lt;li&gt;What are the benefits of fine-tuning in compressed LLMs?&lt;/li&gt;
&lt;li&gt;What role does hardware play in LLM compression?&lt;/li&gt;
&lt;li&gt;What are the ethical considerations in LLM compression?&lt;/li&gt;
&lt;li&gt;What are the future directions in LLM compression?&lt;/li&gt;
&lt;/ul&gt;


&lt;h2 class=&#34;relative group&#34;&gt;1. &lt;strong&gt;What is LLM Compression?&lt;/strong&gt; 
    &lt;div id=&#34;1-what-is-llm-compression&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#1-what-is-llm-compression&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;LLM (Large Language Model) compression refers to a set of techniques and methodologies aimed at reducing the size of large language models while maintaining their performance as much as possible. Large language models, such as GPT, BERT, and their variants, often contain hundreds of millions to billions of parameters, making them resource-intensive to deploy and run. The sheer size of these models poses challenges in terms of storage, computation, and real-time inference, especially when deploying on devices with limited hardware resources like mobile phones or edge devices.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>What is Pinecone</title>
      <link>http://localhost:1313/dsblog/What-is-Pinecone/</link>
      <pubDate>Sun, 03 Sep 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/What-is-Pinecone/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6097-What-is-Pinecone.jpg&#34; alt=&#34;What is Pinecone&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What is pinecone? 
    &lt;div id=&#34;what-is-pinecone&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-pinecone&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Pinecone is a managed vector database that provides vector search (or “similarity search”) for developers with a straightforward API and usage-based pricing. It’s free to try. &lt;a href=&#34;https://www.pinecone.io/learn/vector-search-basics/&#34; target=&#34;_blank&#34;&gt;Introduction to Vector Search for Developers&lt;/a&gt;.&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What is a &lt;a href=&#34;https://www.pinecone.io/learn/vector-database/&#34; target=&#34;_blank&#34;&gt;Vector Database&lt;/a&gt;? 
    &lt;div id=&#34;what-is-a-vector-database&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-a-vector-database&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Your must have heard about relational database, graph database, object datbase. But this article is about Vector Database.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>ML Model Respository from Pinto0309</title>
      <link>http://localhost:1313/dsblog/ML-Model-Repository-from-Pinto0309/</link>
      <pubDate>Fri, 01 Sep 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/ML-Model-Repository-from-Pinto0309/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6095-ML-Model-Repository-from-Pinto0309.jpg&#34; alt=&#34;ML Model Respository from Pinto0309&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;ML Model Repository from Pinto0309 
    &lt;div id=&#34;ml-model-repository-from-pinto0309&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#ml-model-repository-from-pinto0309&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Introduction 
    &lt;div id=&#34;introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Using AI we can solve many kinds of tasks for this input can be text, structured data, image, video, audio, time-series, etc. To solve these problems we need to train model. These models may be computer vision, NLP, or traditional machine learning kind. There are hundreds of architectures and algorithms to solve business problems and create models. There a hundreds of different datasets that can be along with a particular architecture or algorithm to solve the problem. If you have any of these tasks then you can explore using these pre-trained models to solve your problem. There is a GitHub user &amp;ldquo;Katsuya Hyodo&amp;rdquo; with GitHub account &amp;ldquo;PINTO0309&amp;rdquo;. He has trained hundreds of models and created these pre-trained models for the community. You can scan and explore them from there. From there you can download the pre-trained models.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Model Tuning with VertexAI</title>
      <link>http://localhost:1313/dsblog/Model-Tuning-with-VertexAI/</link>
      <pubDate>Mon, 24 Jul 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Model-Tuning-with-VertexAI/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6081-Model-Tuning-with-VertexAI.jpg&#34; alt=&#34;Model Tuning with VertexAI&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Tuning Large Language Model with VertexAI 
    &lt;div id=&#34;tuning-large-language-model-with-vertexai&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#tuning-large-language-model-with-vertexai&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Why Model Tuning? 
    &lt;div id=&#34;why-model-tuning&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#why-model-tuning&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Tuning is required when you want the model to learn something niche or specific that deviates from general language patterns.&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Goal of Tuning 
    &lt;div id=&#34;goal-of-tuning&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#goal-of-tuning&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;


&lt;h3 class=&#34;relative group&#34;&gt;Classification 
    &lt;div id=&#34;classification&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#classification&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h3&gt;
&lt;p&gt;prompt: &amp;ldquo;Classify the following text into one of the following classes: [business, entertainment].&amp;rdquo;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Introduction to ML Model Deployment</title>
      <link>http://localhost:1313/dsblog/Introduction-to-ML-Model-deployment/</link>
      <pubDate>Wed, 19 Jul 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Introduction-to-ML-Model-deployment/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6077-Introduction-to-ML-Model-deployment.jpg&#34; alt=&#34;Introduction to AI Model Deployement&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Introduction to AI Model deployment 
    &lt;div id=&#34;introduction-to-ai-model-deployment&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction-to-ai-model-deployment&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Big Players 
    &lt;div id=&#34;big-players&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#big-players&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Amazon
&lt;ul&gt;
&lt;li&gt;Amazon has many products and one of their product is &lt;strong&gt;AWS Cloud&lt;/strong&gt;. Under this product they sell IT infrastructure (storage, memory, network, VM, webhosting etc.)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Amazon SageMaker&lt;/strong&gt; is Cloud based Machine Learning Platform, and this is one of the product under AWS Cloud.&lt;/li&gt;
&lt;li&gt;Amazon SageMaker can be used to train AI model, host AI model, monitor the model and hosts many other services which any Data Science project need from data gathering to model serving.&lt;/li&gt;
&lt;li&gt;AWS is oldest cloud service provider in the market.&lt;/li&gt;
&lt;li&gt;AWS Sagemaker was launched in Nov&#39;17.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Google
&lt;ul&gt;
&lt;li&gt;Google has hundreds of products like gmail, youtube, google drive etc. One of their product is called &lt;strong&gt;Google Cloud&lt;/strong&gt;. Under this product they sell IT infrastrcture like Amazon sells under AWS.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;VertexAI&lt;/strong&gt; is Cloud based Machine Learning platform of Google. VertexAI is part of Google Cloud.&lt;/li&gt;
&lt;li&gt;VertexAI can be used to train AI Model,host AI model, monitor the model etc.&lt;/li&gt;
&lt;li&gt;VertexAI was launched in Jun&#39;21&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Microsoft
&lt;ul&gt;
&lt;li&gt;Like Amazon&amp;rsquo;s cloud platform which is called AWS Cloud, Microsoft&amp;rsquo;s cloud plateform is called &lt;strong&gt;Azure&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Microsoft&amp;rsquo;s AI product is called &lt;strong&gt;Azure Machine Learning&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Today (Jul&#39;23) Azure Machine Learning has has most of the capabilites than any other player&amp;rsquo;s AI product.&lt;/li&gt;
&lt;li&gt;Azure Machine Learning was launched Feb&#39;14&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What is GenAI? 
    &lt;div id=&#34;what-is-genai&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-genai&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;There are many kinds of AI models like classifier models, regressor models, clustering models, reinforcement models, etc. An AI model which has the ability to generate text, images, video, and music is called GenAI. They all take inspiration from the human brain, therefore they all have neural network (NN) architecture. There are dozens (if not hundreds) types of NN architecture that can be used to create different kinds of AI models. The type of NN architecture depends upon the data which is used for developing the model and the problem which we want to solve using AI model. Researchers in universities or big corporations like Google, Facebook, Amazon, and Microsoft keep developing new architecture, and using these architectures they develop the foundational models. Once foundational models are developed, they release a research paper. In this, they inform the world what architecture they used, what data they used, what parameters (weights &amp;amp; biases) the model has learned, what are the results of their product and compare that with other existing models. They can develop these foundational models with one set of hyperparameters, and they can release these foundational models of different sizes (it depends upon the number of parameters used). AI product builders pick up these foundational models and fine-tune these based on the exact business problem in their hands. Which foundational model do they choose, it also depends upon the size of the model, the kind of data it has used to create those foundational models, and what was the performance of the model on a similar task which the product developer want to solve.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>AWS SageMaker Jumpstart Models</title>
      <link>http://localhost:1313/dsblog/AWS-SageMaker-Jumpstart-Models/</link>
      <pubDate>Tue, 18 Jul 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/AWS-SageMaker-Jumpstart-Models/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6076-AWS-SageMaker-Jumpstart-Models.jpg&#34; alt=&#34;AWS SageMaker Jumpstart Models&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;AWS SageMaker Jumpstart Models 
    &lt;div id=&#34;aws-sagemaker-jumpstart-models&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#aws-sagemaker-jumpstart-models&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;As of 17-Jul-23, AWS Sagemaker has 463 models in its Model Zoo. They call these models as Jumstart Models. What are the capabilities of these models, who are the developer of these models, where these models are hosted in given in the table below.&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;SNo.&lt;/th&gt;
          &lt;th&gt;Task Type&lt;/th&gt;
          &lt;th&gt;Company&lt;/th&gt;
          &lt;th&gt;Model Description&lt;/th&gt;
          &lt;th&gt;Model ID&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;1.&lt;/td&gt;
          &lt;td&gt;Text Generation&lt;/td&gt;
          &lt;td&gt;Huggingface&lt;/td&gt;
          &lt;td&gt;Falcon-40B-Instruct is a 40B parameters causal decoder-only model built by TII based on Falcon-40B and finetuned on a mixture of Baize It is ready-to-use chat/instruct model based on Falcon 40B&lt;/td&gt;
          &lt;td&gt;Model draft: false&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;id: huggingface-textgeneration-falcon-40b-instruct-bf16
|2. |Text Generation |Huggingface |This is a Text Generation model built upon a Transformer model from Hugging Face |Model draft: false
id: huggingface-textgeneration-open-llama
|3. |Text to Image |StabilityAI |Extend beyond just text-to-image prompting. Stable Diffusion XL offers several ways to modify the images: Inpainting - edit inside the image, Outpainting - extend the image outside of the original image, Image-to-image - prompt a new image using a sourced image. |
|4. |Text Generation |Cohere |Generative model that responds well with instruction-like prompts. This model provides businesses and enterprises with best quality, performance and accuracy in all generative tasks. And with our intuitive SDK, unlocking the full potential of LLMs for your applications has never been easier. |
|5. |Text Generation |AI21 Labs |Jurassic-2 Ultra is optimized to follow natural language instructions and context, so there is no need to provide it with any examples. |
|6. |Text Generation |AI21 Labs | |
|7. |Text Generation |AI21 Labs |Condense lengthy texts into short, easy-to-read bites that remain factually consistent with the source. No prompting needed – simply input the text that needs to be summarized. The model is specifically trained to generate summaries that capture the essence and key ideas of the original text. |
|8. |Text Generation |AI21 Labs |Get the AI21 Paraphrase model, the top-of-the-line paraphrasing engine, and deploy it in your private environment. The model aims to generate 10 alternative suggestions with every activation. It may return fewer suggestions when rewriting very short texts for which it cannot produce as many as 10 sensible paraphrases. |
|9. |Text Generation |AI21 Labs |Jurassic-2 Mid is optimized to follow natural language instructions and context, so there is no need to provide it with any examples. Pre-trained language model trained by AI21 Labs on a corpus of web text including natural language and computer programs with recent data - updated to mid 2022. This model has a 8192 token context window (i.e. the length of the prompt + completion should be at most 8192 tokens). |
|10. |Text Generation |AI21 Labs |Detects and suggests corrections for Grammar, Spelling, Punctuation mistakes, as well as word misuse, and accidental repetition or omission. |
|11. |Text to Image |StabilityAI |Extend beyond just text-to-image prompting. Stable Diffusion XL offers several ways to modify the images: Inpainting - edit inside the image, Outpainting - extend the image outside of the original image, Image-to-image - prompt a new image using a sourced image. |
|12. |Text to Image |Stabilityai |This is a text-to-image model from Stability AI and downloaded from HuggingFace It takes a textual description as input and returns a generated image from the description |Model draft: false
id: model-txt2img-stabilityai-stable-diffusion-v2-1-base
|13. | |Huggingface |This is a Text2Text Generation model built upon a T5 model from Hugging Face The deployed model can be used for running inference on any input text |Model draft: false
id: huggingface-text2text-flan-t5-xl
|14. | |Huggingface |This is a Text Generation model built upon a Transformer model from Hugging Face It takes a text string as input and predicts next words in the sequence |Model draft: false
id: huggingface-textgeneration1-gpt-j-6b
|15. | |Huggingface |This is a Text2Text Generation model built upon a T5 model from Hugging Face The deployed model can be used for running inference on any input text |Model draft: false
id: huggingface-text2text-flan-ul2-bf16
|16. |Text Generation |Pytorch |AlexaTM 20B is a multitask, multilingual, large-scale sequence-to-sequence (seq2seq) model, trained on a mixture of Common Crawl (mC4) and Wikipedia data across 12 languages, using denoising and Causal Language Modeling (CLM) tasks |Model draft: false
id: pytorch-textgeneration1-alexa20b
|17. |Text Generation |Huggingface |This is a Text Generation model built upon a Transformer model from Hugging Face It takes a text string as input and predicts next words in the sequence |Model draft: false
id: huggingface-textgeneration-bloom-1b7
|18. |Image Classification |Tensorflow |This is an Image Classification model from TensorFlow Hub It takes an image as input and classifies the image to one of the 1001 classes |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v2-100-224-classification-4
|19. |Object Detection |Tensorflow |This is an object detection model from Tensorflow It takes an image as input and returns bounding boxes for the objects in the image |Model draft: false
id: tensorflow-od1-ssd-resnet50-v1-fpn-640x640-coco17-tpu-8
|20. |Object Detection |Pytorch |This is an object detection model from PyTorch Hub It takes an image as input and returns bounding boxes for the objects in the image |Model draft: false
id: pytorch-od1-fasterrcnn-resnet50-fpn
|21. |Text Classification |Tensorflow |This is a Text Classification model built upon a Text Embedding model from TensorFlow Hub It takes a text string as input and classifies the input text as either a positive or negative movie review |Model draft: false
id: tensorflow-tc-bert-en-uncased-L-12-H-768-A-12-2
|22. |Question Answering |Huggingface |This is an Extractive Question Answering model built on a Transformer model from Hugging Face It takes two strings as inputs: the first string is a question and the second string is the context or any text you want to use to find the answer of the question, and it returns a sub-string from the context as an answer to the question |Model draft: false
id: huggingface-eqa-distilbert-base-uncased
|23. |Zero-Shot Text Classification |Huggingface |This is Zero Shot Text Classification model built on a Transformer model from Hugging Face It can classify sentences in English language It takes a sequence and a list of candidate labels as inputs and predicts score that the sequence is associated with the particular label |Model draft: false
id: huggingface-zstc-facebook-bart-large-mnli
|24. |Semantic Segmentation |Mxnet |This is an Semantic Segmentation model from Gluon CV It takes an image as input and returns class label for each pixel in the image |Model draft: false
id: mxnet-semseg-fcn-resnet101-coco
|25. |Sentence Pair Classification |Huggingface |This is a Sentence Pair Classification model built upon a Text Embedding model from Hugging Face It takes a pair of sentences as input and classifies the input pair to &amp;rsquo;entailment&amp;rsquo; or &amp;rsquo;no-entailment&amp;rsquo; |Model draft: false
id: huggingface-spc-distilbert-base-uncased
|26. |Named Entity Recognition |Huggingface |This is a Named Entity Generation model built upon a Transformer model from Hugging Face It takes a text string as input and predicts named entities in the input text |Model draft: false
id: huggingface-ner-distilbert-base-cased-finetuned-conll03-english
|27. |Text Summarization |Huggingface |This is a Text Summarization model built upon a Transformer model from Hugging Face It takes a text string as input and returns a summary of the text |Model draft: false
id: huggingface-summarization-distilbart-xsum-1-1
|28. |Machine Translation |Huggingface |This is a Machine Translation model built upon a Transformer model from Hugging Face It takes a text string as input and predicts its translation |Model draft: false
id: huggingface-translation-t5-small
|29. |Text Embedding |Tensorflow |This is a Text Embedding model from TensorFlow Hub It takes a text string as input and outputs an embedding vector The Text Embedding model is pre-trained on Wikipedia and BookCorpus datasets |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-2-H-128-A-2-2
|30. |Text Embedding |Mxnet |This is a Text Embedding model from GluonNLP pre-trained on the decade (2010-2019) of S&amp;amp;P 500 10-K/10-Q reports It takes a text string as input and outputs an embedding vector For pre-training, the entire text of the 10K/Q filing was used, not just the MD&amp;amp;A (Management Discussion and Analysis) section, so as to ensure that a broader context of financial language is captured Embeddings from the pre-trained modelare then used for fine-tuning specific classifiers |Model draft: false
id: mxnet-tcembedding-robertafin-base-uncased
|31. |Sentence Pair Classification |Tensorflow |This is a Sentence Pair Classification model built upon a Text Embedding model from TensorFlow Hub It takes a pair of sentences as input and classifies the input pair to &amp;rsquo;entailment&amp;rsquo; or &amp;rsquo;no-entailment&amp;rsquo; |Model draft: false
id: tensorflow-spc-bert-en-uncased-L-12-H-768-A-12-2
|32. |Instance Segmentation |Mxnet |This is an Instance Segmentation model from Gluon CV It detects and delineates each distinct object in the image |Model draft: false
id: mxnet-is-mask-rcnn-fpn-resnet101-v1d-coco
|33. |Image Embedding |Tensorflow |This is an Image Feature Vector model from TensorFlow Hub It takes an image as input and returns a feature vector (embedding) of the image |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v2-100-224-featurevector-4
|34. |Image Classification |Pytorch |This is an Image Classification model from PyTorch Hub It takes an image as input and classifies the image to one of the 1000 classes |Model draft: false
id: pytorch-ic-mobilenet-v2
|35. |Object Detection |Mxnet |This is an object detection model from Gluon CV It takes an image as input and returns bounding boxes for the objects in the image |Model draft: false
id: mxnet-od-ssd-512-mobilenet1-0-coco
|36. |Object Detection |Tensorflow |This is an object detection model from TensorFlow Hub It takes an image as input and returns bounding boxes for the objects in the image |Model draft: false
id: tensorflow-od-ssd-mobilenet-v2-fpnlite-320x320-1
|37. |Object Detection |Pytorch |This is an object detection model from PyTorch Hub It takes an image as input and returns bounding boxes for the objects in the image |Model draft: false
id: pytorch-od-nvidia-ssd
|38. |Image Classification |Tensorflow |This is an Image Classification model from TensorFlow Hub It takes an image as input and classifies the image to one of the 1001 classes |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v2-075-224-classification-4
|39. |Image Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v2-050-224-classification-4
|40. |Image Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v2-035-224-classification-4
|41. |Image Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v2-140-224-classification-4
|42. |Image Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v2-130-224-classification-4
|43. |Object Detection |Pytorch |This is an object detection model from PyTorch Hub It takes an image as input and returns bounding boxes for the objects in the image |Model draft: false
id: pytorch-od1-fasterrcnn-mobilenet-v3-large-320-fpn
|44. |Object Detection |Pytorch |Same |Model draft: false
id: pytorch-od1-fasterrcnn-mobilenet-v3-large-fpn
|45. |Semantic Segmentation |Mxnet |This is an Semantic Segmentation model from Gluon CV It takes an image as input and returns class label for each pixel in the image |Model draft: false
id: mxnet-semseg-fcn-resnet101-voc
|46. |Semantic Segmentation |Mxnet |Same as above |Model draft: false
id: mxnet-semseg-fcn-resnet101-ade
|47. |Instance Segmentation |Mxnet |Same as above |Model draft: false
id: mxnet-semseg-fcn-resnet50-ade
|48. |Image Classification |Pytorch |This is an Image Classification model from PyTorch Hub It takes an image as input and classifies the image to one of the 1000 classes |Model draft: false
id: pytorch-ic-resnet18
|49. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-resnet34
|50. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-resnet50
|51. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-resnet101
|52. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-resnet152
|53. |Object Detection |Mxnet |This is an object detection model from Gluon CV It takes an image as input and returns bounding boxes for the objects in the image |Model draft: false
id: mxnet-od-ssd-512-mobilenet1-0-voc
|54. |Object Detection |Mxnet |Same |Model draft: false
id: mxnet-od-ssd-512-resnet50-v1-coco
|55. |Object Detection |Mxnet |Same |Model draft: false
id: mxnet-od-ssd-512-resnet50-v1-voc
|56. |Object Detection |Mxnet |Same |Model draft: false
id: mxnet-od-ssd-300-vgg16-atrous-coco
|57. |Object Detection |Mxnet |Same |Model draft: false
id: mxnet-od-ssd-300-vgg16-atrous-voc
|58. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od1-ssd-efficientdet-d0-512x512-coco17-tpu-8
|59. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od1-ssd-efficientdet-d1-640x640-coco17-tpu-8
|60. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od1-ssd-efficientdet-d2-768x768-coco17-tpu-8
|61. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od1-ssd-efficientdet-d3-896x896-coco17-tpu-32
|62. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od1-ssd-mobilenet-v1-fpn-640x640-coco17-tpu-8
|63. |Instance Segmentation |Mxnet |This is an Instance Segmentation model from Gluon CV It detects and delineates each distinct object in the image |Model draft: false
id: mxnet-is-mask-rcnn-fpn-resnet50-v1b-coco
|64. |Instance Segmentation |Mxnet |Same |Model draft: false
id: mxnet-is-mask-rcnn-fpn-resnet18-v1b-coco
|65. | |Mxnet |Same |Model draft: false
id: mxnet-is-mask-rcnn-resnet18-v1b-coco
|66. |Image Embedding |Tensorflow |This is an Image Feature Vector model from TensorFlow Hub It takes an image as input and returns a feature vector (embedding) of the image |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v2-075-224-featurevector-4
|67. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v2-050-224-featurevector-4
|68. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v2-035-224-featurevector-4
|69. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v2-140-224-featurevector-4
|70. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v2-130-224-featurevector-4
|71. |Object Detection |Tensorflow |This is an object detection model from TensorFlow Hub It takes an image as input and returns bounding boxes for the objects in the image |Model draft: false
id: tensorflow-od-ssd-mobilenet-v2-fpnlite-640x640-1
|72. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-ssd-mobilenet-v2-2
|73. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-ssd-mobilenet-v1-fpn-640x640-1
|74. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-faster-rcnn-resnet50-v1-640x640-1
|75. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-faster-rcnn-resnet50-v1-800x1333-1
|76. |Zero-Shot Text Classification |Huggingface |This is Zero Shot Text Classification model built on a Transformer model from Hugging Face It can classify sentences in English language It takes a sequence and a list of candidate labels as inputs and predicts score that the sequence is associated with the particular label |Model draft: false
id: huggingface-zstc-narsil-deberta-large-mnli-zero-cls
|77. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-moritzlaurer-deberta-v3-large-mnli-fever-anli-ling-wanli
|78. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-cross-encoder-nli-distilroberta-base
|79. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-recognai-bert-base-spanish-wwm-cased-xnli
|80. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-moritzlaurer-mdeberta-v3-base-xnli-multilingual-nli-2mil7
|81. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-cross-encoder-nli-roberta-base
|82. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-cross-encoder-nli-deberta-base
|83. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-cross-encoder-nli-minilm2-l6-h768
|84. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-recognai-zeroshot-selectra-medium
|85. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-navteca-bart-large-mnli
|86. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-jiva-xlm-roberta-large-it-mnli
|87. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-digitalepidemiologylab-covid-twitter-bert-v2-mnli
|88. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-recognai-zeroshot-selectra-small
|89. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-emrecan-distilbert-base-turkish-cased-snli-tr
|90. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-emrecan-bert-base-turkish-cased-allnli-tr
|91. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-emrecan-bert-base-turkish-cased-snli-tr
|92. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-emrecan-bert-base-multilingual-cased-allnli-tr
|93. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-narsil-bart-large-mnli-opti
|94. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-emrecan-convbert-base-turkish-mc4-cased-allnli-tr
|95. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-lighteternal-nli-xlm-r-greek
|96. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-emrecan-distilbert-base-turkish-cased-allnli-tr
|97. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-emrecan-bert-base-multilingual-cased-multinli-tr
|98. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-eleldar-theme-classification
|99. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-emrecan-bert-base-turkish-cased-multinli-tr
|100. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-emrecan-bert-base-multilingual-cased-snli-tr
|101. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-emrecan-convbert-base-turkish-mc4-cased-multinli-tr
|102. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-emrecan-distilbert-base-turkish-cased-multinli-tr
|103. |Zero-Shot Text Classification |Huggingface |Same |Model draft: false
id: huggingface-zstc-emrecan-convbert-base-turkish-mc4-cased-snli-tr
|104. |Image Classification |Tensorflow |This is an Image Classification model from TensorFlow Hub It takes an image as input and classifies the image to one of the 1001 classes |Model draft: false
id: tensorflow-ic-tf2-preview-mobilenet-v2-classification-4
|105. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-inception-v3-classification-4
|106. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-inception-v2-classification-4
|107. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-inception-v1-classification-4
|108. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-tf2-preview-inception-v3-classification-4
|109. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-inception-resnet-v2-classification-4
|110. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-resnet-v2-50-classification-4
|111. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-resnet-v2-101-classification-4
|112. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-resnet-v2-152-classification-4
|113. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-resnet-v1-50-classification-4
|114. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-resnet-v1-101-classification-4
|115. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-resnet-v1-152-classification-4
|116. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-resnet-50-classification-1
|117. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-efficientnet-b0-classification-1
|118. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-efficientnet-b1-classification-1
|119. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-efficientnet-b2-classification-1
|120. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-efficientnet-b3-classification-1
|121. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-efficientnet-b4-classification-1
|122. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-efficientnet-b5-classification-1
|123. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-efficientnet-b6-classification-1
|124. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-efficientnet-b7-classification-1
|125. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-efficientnet-lite0-classification-2
|126. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-efficientnet-lite1-classification-2
|127. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-efficientnet-lite2-classification-2
|128. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-efficientnet-lite3-classification-2
|129. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-efficientnet-lite4-classification-2
|130. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v1-100-224-classification-4
|131. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v1-100-192-classification-4
|132. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v1-100-160-classification-4
|133. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v1-100-128-classification-4
|134. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v1-075-224-classification-4
|135. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v1-075-192-classification-4
|136. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v1-075-160-classification-4
|137. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v1-075-128-classification-4
|138. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v1-050-224-classification-4
|139. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v1-050-192-classification-4
|140. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v1-050-160-classification-4
|141. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v1-050-128-classification-4
|142. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v1-025-224-classification-4
|143. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v1-025-192-classification-4
|144. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v1-025-160-classification-4
|145. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-imagenet-mobilenet-v1-025-128-classification-4
|146. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-bit-s-r50x1-ilsvrc2012-classification-1
|147. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-bit-s-r50x3-ilsvrc2012-classification-1
|148. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-bit-s-r101x1-ilsvrc2012-classification-1
|149. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-bit-s-r101x3-ilsvrc2012-classification-1
|150. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-bit-m-r50x1-ilsvrc2012-classification-1
|151. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-bit-m-r50x3-ilsvrc2012-classification-1
|152. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-bit-m-r101x1-ilsvrc2012-classification-1
|153. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-bit-m-r101x3-ilsvrc2012-classification-1
|154. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-bit-m-r50x1-imagenet21k-classification-1
|155. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-bit-m-r50x3-imagenet21k-classification-1
|156. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-bit-m-r101x1-imagenet21k-classification-1
|157. |Image Classification |Tensorflow |Same |Model draft: false
id: tensorflow-ic-bit-m-r101x3-imagenet21k-classification-1
|158. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-alexnet
|159. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-densenet121
|160. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-densenet169
|161. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-densenet201
|162. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-densenet161
|163. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-resnext50-32x4d
|164. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-resnext101-32x8d
|165. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-shufflenet-v2-x1-0
|166. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-squeezenet1-0
|167. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-squeezenet1-1
|168. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-vgg11
|169. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-vgg11-bn
|170. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-vgg13
|171. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-vgg13-bn
|172. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-vgg16
|173. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-vgg16-bn
|174. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-vgg19
|175. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-vgg19-bn
|176. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-wide-resnet50-2
|177. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-wide-resnet101-2
|178. |Image Classification |Pytorch |Same |Model draft: false
id: pytorch-ic-googlenet
|179. |Object Detection |Mxnet |This is an object detection model from Gluon CV It takes an image as input and returns bounding boxes for the objects in the image |Model draft: false
id: mxnet-od-ssd-512-vgg16-atrous-coco
|180. |Object Detection |Mxnet |Same |Model draft: false
id: mxnet-od-ssd-512-vgg16-atrous-voc
|181. |Object Detection |Mxnet |Same |Model draft: false
id: mxnet-od-yolo3-darknet53-voc
|182. |Object Detection |Mxnet |Same |Model draft: false
id: mxnet-od-yolo3-mobilenet1-0-voc
|183. |Object Detection |Mxnet |Same |Model draft: false
id: mxnet-od-yolo3-darknet53-coco
|184. |Object Detection |Mxnet |Same |Model draft: false
id: mxnet-od-yolo3-mobilenet1-0-coco
|185. |Object Detection |Mxnet |Same |Model draft: false
id: mxnet-od-faster-rcnn-resnet50-v1b-voc
|186. |Object Detection |Mxnet |Same |Model draft: false
id: mxnet-od-faster-rcnn-resnet50-v1b-coco
|187. |Object Detection |Mxnet |Same |Model draft: false
id: mxnet-od-faster-rcnn-resnet101-v1d-coco
|188. |Object Detection |Mxnet |Same |Model draft: false
id: mxnet-od-faster-rcnn-fpn-resnet50-v1b-coco
|189. |Object Detection |Mxnet |Same |Model draft: false
id: mxnet-od-faster-rcnn-fpn-resnet101-v1d-coco
|190. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od1-ssd-mobilenet-v2-fpnlite-320x320-coco17-tpu-8
|191. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od1-ssd-mobilenet-v2-fpnlite-640x640-coco17-tpu-8
|192. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od1-ssd-resnet50-v1-fpn-1024x1024-coco17-tpu-8
|193. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od1-ssd-resnet101-v1-fpn-640x640-coco17-tpu-8
|194. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od1-ssd-resnet101-v1-fpn-1024x1024-coco17-tpu-8
|195. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od1-ssd-resnet152-v1-fpn-640x640-coco17-tpu-8
|196. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od1-ssd-resnet152-v1-fpn-1024x1024-coco17-tpu-8
|197. |Image Embedding |Tensorflow |This is an Image Feature Vector model from TensorFlow Hub It takes an image as input and returns a feature vector (embedding) of the image |Model draft: false
id: tensorflow-icembedding-imagenet-inception-v3-featurevector-4
|198. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-inception-v2-featurevector-4
|199. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-inception-v1-featurevector-4
|200. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-tf2-preview-inception-v3-featurevector-4
|201. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-tf2-preview-mobilenet-v2-featurevector-4
|202. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-resnet-v2-50-featurevector-4
|203. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-resnet-v2-101-featurevector-4
|204. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-resnet-v2-152-featurevector-4
|205. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-resnet-v1-50-featurevector-4
|206. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-resnet-v1-101-featurevector-4
|207. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-resnet-v1-152-featurevector-4
|208. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-resnet-50-featurevector-1
|209. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-efficientnet-b0-featurevector-1
|210. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-efficientnet-b1-featurevector-1
|211. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-efficientnet-b2-featurevector-1
|212. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-efficientnet-b3-featurevector-1
|213. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-efficientnet-b6-featurevector-1
|214. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-efficientnet-lite0-featurevector-2
|215. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-efficientnet-lite1-featurevector-2
|216. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-efficientnet-lite2-featurevector-2
|217. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-efficientnet-lite3-featurevector-2
|218. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-efficientnet-lite4-featurevector-2
|219. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v1-100-224-featurevector-4
|220. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v1-100-192-featurevector-4
|221. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v1-100-160-featurevector-4
|222. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v1-100-128-featurevector-4
|223. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v1-075-224-featurevector-4
|224. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v1-075-192-featurevector-4
|225. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v1-075-160-featurevector-4
|226. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v1-075-128-featurevector-4
|227. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v1-050-224-featurevector-4
|228. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v1-050-192-featurevector-4
|229. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v1-050-160-featurevector-4
|230. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v1-050-128-featurevector-4
|231. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v1-025-224-featurevector-4
|232. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v1-025-192-featurevector-4
|233. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v1-025-160-featurevector-4
|234. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-imagenet-mobilenet-v1-025-128-featurevector-4
|235. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-bit-s-r50x1-ilsvrc2012-featurevector-1
|236. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-bit-s-r50x3-ilsvrc2012-featurevector-1
|237. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-bit-s-r101x1-ilsvrc2012-featurevector-1
|238. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-bit-s-r101x3-ilsvrc2012-featurevector-1
|239. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-bit-m-r50x1-ilsvrc2012-featurevector-1
|240. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-bit-m-r50x3-imagenet21k-featurevector-1
|241. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-bit-m-r101x1-ilsvrc2012-featurevector-1
|242. |Image Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-icembedding-bit-m-r101x3-imagenet21k-featurevector-1
|243. |Object Detection |Tensorflow |This is an object detection model from TensorFlow Hub It takes an image as input and returns bounding boxes for the objects in the image |Model draft: false
id: tensorflow-od-faster-rcnn-resnet50-v1-1024x1024-1
|244. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-faster-rcnn-resnet101-v1-640x640-1
|245. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-faster-rcnn-resnet101-v1-800x1333-1
|246. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-faster-rcnn-resnet101-v1-1024x1024-1
|247. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-faster-rcnn-resnet152-v1-640x640-1
|248. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-faster-rcnn-resnet152-v1-800x1333-1
|249. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-faster-rcnn-resnet152-v1-1024x1024-1
|250. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-faster-rcnn-inception-resnet-v2-640x640-1
|251. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-faster-rcnn-inception-resnet-v2-1024x1024-1
|252. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-efficientdet-d0-1
|253. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-efficientdet-d1-1
|254. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-efficientdet-d2-1
|255. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-efficientdet-d3-1
|256. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-efficientdet-d4-1
|257. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-efficientdet-d5-1
|258. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-retinanet-resnet50-v1-fpn-640x640-1
|259. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-retinanet-resnet50-v1-fpn-1024x1024-1
|260. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-retinanet-resnet101-v1-fpn-640x640-1
|261. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-retinanet-resnet101-v1-fpn-1024x1024-1
|262. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-retinanet-resnet152-v1-fpn-640x640-1
|263. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-retinanet-resnet152-v1-fpn-1024x1024-1
|264. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-centernet-hourglass-512x512-1
|265. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-centernet-hourglass-512x512-kpts-1
|266. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-centernet-hourglass-1024x1024-1
|267. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-centernet-hourglass-1024x1024-kpts-1
|268. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-centernet-resnet50v1-fpn-512x512-1
|269. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-centernet-resnet50v1-fpn-512x512-kpts-1
|270. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-centernet-resnet50v2-512x512-1
|271. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-centernet-resnet50v2-512x512-kpts-1
|272. |Object Detection |Tensorflow |Same |Model draft: false
id: tensorflow-od-centernet-resnet101v1-fpn-512x512-1
|273. |Text Classification |Tensorflow |This is a Text Classification model built upon a Text Embedding model from TensorFlow Hub It takes a text string as input and classifies the input text as either a positive or negative movie review |Model draft: false
id: tensorflow-tc-bert-en-cased-L-12-H-768-A-12-2
|274. |Text Classification |Tensorflow |Same |Model draft: false
id: tensorflow-tc-bert-multi-cased-L-12-H-768-A-12-2
|275. |Text Classification |Tensorflow |Same |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-2-H-128-A-2
|276. |Text Classification |Tensorflow |Same |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-2-H-256-A-4
|277. |Text Classification |Tensorflow |Same |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-2-H-512-A-8
|278. |Question Answering |Huggingface |This is an Extractive Question Answering model built on a Transformer model from Hugging Face It takes two strings as inputs: the first string is a question and the second string is the context or any text you want to use to find the answer of the question, and it returns a sub-string from the context as an answer to the question |Model draft: false
id: huggingface-eqa-distilbert-base-cased
|279. |Question Answering |Huggingface |Same |Model draft: false
id: huggingface-eqa-distilbert-base-multilingual-cased
|280. |Question Answering |Huggingface |Same |Model draft: false
id: huggingface-eqa-bert-base-uncased
|281. |Question Answering |Huggingface |Same |Model draft: false
id: huggingface-eqa-bert-base-cased
|282. |Question Answering |Huggingface |Same |Model draft: false
id: huggingface-eqa-bert-base-multilingual-uncased
|283. |Sentence Pair Classification |Tensorflow |This is a Sentence Pair Classification model built upon a Text Embedding model from TensorFlow Hub It takes a pair of sentences as input and classifies the input pair to &amp;rsquo;entailment&amp;rsquo; or &amp;rsquo;no-entailment&amp;rsquo; |Model draft: false
id: tensorflow-spc-bert-en-cased-L-12-H-768-A-12-2
|284. |Sentence Pair Classification |Tensorflow |Same |Model draft: false
id: tensorflow-spc-bert-multi-cased-L-12-H-768-A-12-2
|285. |Sentence Pair Classification |Tensorflow |Same |Model draft: false
id: tensorflow-spc-bert-en-uncased-L-24-H-1024-A-16-2
|286. |Sentence Pair Classification |Tensorflow |Same |Model draft: false
id: tensorflow-spc-electra-small-1
|287. |Sentence Pair Classification |Tensorflow |Same |Model draft: false
id: tensorflow-spc-electra-base-1
|288. |Sentence Pair Classification |Huggingface |Same |Model draft: false
id: huggingface-spc-distilbert-base-cased
|289. |Sentence Pair Classification |Huggingface |Same |Model draft: false
id: huggingface-spc-distilbert-base-multilingual-cased
|290. |Sentence Pair Classification |Huggingface |Same |Model draft: false
id: huggingface-spc-bert-base-uncased
|291. |Sentence Pair Classification |Huggingface |Same |Model draft: false
id: huggingface-spc-bert-base-cased
|292. |Sentence Pair Classification |Huggingface |Same |Model draft: false
id: huggingface-spc-bert-base-multilingual-uncased
|293. |Named Entity Recognition |Huggingface |This is a Named Entity Generation model built upon a Transformer model from Hugging Face It takes a text string as input and predicts named entities in the input text |Model draft: false
id: huggingface-ner-distilbert-base-uncased-finetuned-conll03-english
|294. |Text Generation |Huggingface |Same |Model draft: false
id: huggingface-textgeneration-bloom-1b1
|295. |Text Generation |Huggingface |Same |Model draft: false
id: huggingface-textgeneration-bloom-560m
|296. |Text Generation |Huggingface |Same |Model draft: false
id: huggingface-textgeneration-gpt2
|297. |Text Generation |Huggingface |Same |Model draft: false
id: huggingface-textgeneration-distilgpt2
|298. |Text Summarization |Huggingface |This is a Text Summarization model built upon a Transformer model from Hugging Face It takes a text string as input and returns a summary of the text |Model draft: false
id: huggingface-summarization-bert-small2bert-small-finetuned-cnn-daily-mail-summarization
|299. |Text Summarization |Huggingface |Same |Model draft: false
id: huggingface-summarization-distilbart-cnn-6-6
|300. |Text Summarization |Huggingface |Same |Model draft: false
id: huggingface-summarization-distilbart-xsum-12-3
|301. |Text Summarization |Huggingface |Same |Model draft: false
id: huggingface-summarization-distilbart-cnn-12-6
|302. |Text Summarization |Huggingface |Same |Model draft: false
id: huggingface-summarization-bart-large-cnn-samsum
|303. |Machine Translation |Huggingface |This is a Machine Translation model built upon a Transformer model from Hugging Face It takes a text string as input and predicts its translation |Model draft: false
id: huggingface-translation-t5-base
|304. |Machine Translation |Huggingface |Same |Model draft: false
id: huggingface-translation-t5-large
|305. |Machine Translation |Huggingface |Same |Model draft: false
id: huggingface-translation-opus-mt-en-es
|306. |Machine Translation |Huggingface |Same |Model draft: false
id: huggingface-translation-opus-mt-en-vi
|307. |Text Embedding |Tensorflow |This is a Text Embedding model from TensorFlow Hub It takes a text string as input and outputs an embedding vector The Text Embedding model is pre-trained on Wikipedia and BookCorpus datasets |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-2-H-256-A-4
|308. |Text Embedding |Tensorflow |same |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-2-H-512-A-8-2
|309. |Text Embedding |Tensorflow |same |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-2-H-768-A-12-2
|310. |Text to Image |Stabilityai |This is a text-to-image model from Stability AI and downloaded from HuggingFace It takes a textual description as input and returns a generated image from the description |Model draft: false
id: model-txt2img-stabilityai-stable-diffusion-v2
|311. |Text Embedding |Tensorflow |This is a Text Embedding model from TensorFlow Hub It takes a text string as input and outputs an embedding vector The Text Embedding model is pre-trained on Wikipedia and BookCorpus datasets |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-4-H-128-A-2-2
|312. |Text Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-4-H-256-A-4-2
|313. |Text Embedding |Mxnet |Same |Model draft: false
id: mxnet-tcembedding-robertafin-base-wiki-uncased
|314. |Text Embedding |Mxnet |Same |Model draft: false
id: mxnet-tcembedding-robertafin-large-uncased
|315. |Text Embedding |Mxnet |Same |Model draft: false
id: mxnet-tcembedding-robertafin-large-wiki-uncased
|316. |Text Classification |Tensorflow |This is a Text Classification model built upon a Text Embedding model from TensorFlow Hub It takes a text string as input and classifies the input text as either a positive or negative movie review |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-2-H-768-A-12
|317. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-4-H-128-A-2
|318. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-4-H-256-A-4
|319. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-4-H-512-A-8
|320. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-4-H-768-A-12
|321. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-6-H-128-A-2
|322. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-6-H-256-A-4
|323. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-6-H-512-A-8
|324. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-6-H-768-A-12
|325. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-8-H-128-A-2
|326. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-8-H-256-A-4
|327. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-8-H-512-A-8
|328. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-8-H-768-A-12
|329. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-10-H-128-A-2
|330. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-10-H-256-A-4
|331. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-10-H-512-A-8
|332. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-10-H-768-A-12
|333. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-12-H-128-A-2
|334. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-12-H-256-A-4
|335. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-12-H-512-A-8
|336. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-small-bert-bert-en-uncased-L-12-H-768-A-12
|337. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-bert-en-uncased-L-24-H-1024-A-16-2
|338. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-bert-en-cased-L-24-H-1024-A-16-2
|339. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-bert-en-wwm-uncased-L-24-H-1024-A-16-2
|340. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-bert-en-wwm-cased-L-24-H-1024-A-16-2
|341. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-albert-en-base
|342. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-electra-small-1
|343. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-electra-base-1
|344. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-experts-bert-wiki-books-1
|345. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-experts-bert-pubmed-1
|346. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-talking-heads-base
|347. |Text Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-tc-talking-heads-large
|348. |Question Answering |Huggingface |This is an Extractive Question Answering model built on a Transformer model from Hugging Face It takes two strings as inputs: the first string is a question and the second string is the context or any text you want to use to find the answer of the question, and it returns a sub-string from the context as an answer to the question |Model draft: false
id: huggingface-eqa-bert-base-multilingual-cased
|349. |Question Answering |Huggingface |Same as above |Model draft: false
id: huggingface-eqa-bert-large-uncased
|350. |Question Answering |Huggingface |Same as above |Model draft: false
id: huggingface-eqa-bert-large-cased
|351. |Question Answering |Huggingface |Same as above |Model draft: false
id: huggingface-eqa-bert-large-uncased-whole-word-masking
|352. |Question Answering |Huggingface |Same as above |Model draft: false
id: huggingface-eqa-bert-large-cased-whole-word-masking
|353. |Question Answering |Huggingface |Same as above |Model draft: false
id: huggingface-eqa-distilroberta-base
|354. |Question Answering |Huggingface |Same as above |Model draft: false
id: huggingface-eqa-roberta-base
|355. |Question Answering |Huggingface |Same as above |Model draft: false
id: huggingface-eqa-roberta-base-openai-detector
|356. |Question Answering |Huggingface |Same as above |Model draft: false
id: huggingface-eqa-roberta-large
|357. |Sentence Pair Classification |Tensorflow |This is a Sentence Pair Classification model built upon a Text Embedding model from TensorFlow Hub It takes a pair of sentences as input and classifies the input pair to &amp;rsquo;entailment&amp;rsquo; or &amp;rsquo;no-entailment&amp;rsquo; |Model draft: false
id: tensorflow-spc-bert-en-wwm-uncased-L-24-H-1024-A-16-2
|358. |Sentence Pair Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-spc-bert-en-wwm-cased-L-24-H-1024-A-16-2
|359. |Sentence Pair Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-spc-experts-bert-wiki-books-1
|360. |Sentence Pair Classification |Tensorflow |Same as above |Model draft: false
id: tensorflow-spc-experts-bert-pubmed-1
|361. |Sentence Pair Classification |Huggingface |Same as above |Model draft: false
id: huggingface-spc-bert-base-multilingual-cased
|362. |Sentence Pair Classification |Huggingface |Same as above |Model draft: false
id: huggingface-spc-bert-large-uncased
|363. |Sentence Pair Classification |Huggingface |Same as above |Model draft: false
id: huggingface-spc-bert-large-cased
|364. |Sentence Pair Classification |Huggingface |Same as above |Model draft: false
id: huggingface-spc-bert-large-uncased-whole-word-masking
|365. |Sentence Pair Classification |Huggingface |Same as above |Model draft: false
id: huggingface-spc-bert-large-cased-whole-word-masking
|366. |Sentence Pair Classification |Huggingface |Same as above |Model draft: false
id: huggingface-spc-distilroberta-base
|367. |Sentence Pair Classification |Huggingface |Same as above |Model draft: false
id: huggingface-spc-roberta-base
|368. |Sentence Pair Classification |Huggingface |Same as above |Model draft: false
id: huggingface-spc-roberta-base-openai-detector
|369. |Sentence Pair Classification |Huggingface |Same as above |Model draft: false
id: huggingface-spc-roberta-large
|370. |Sentence Pair Classification |Huggingface |Same as above |Model draft: false
id: huggingface-spc-roberta-large-openai-detector
|371. |Sentence Pair Classification |Huggingface |Same as above |Model draft: false
id: huggingface-spc-xlm-mlm-ende-1024
|372. |Sentence Pair Classification |Huggingface |Same as above |Model draft: false
id: huggingface-spc-xlm-mlm-enro-1024
|373. |Sentence Pair Classification |Huggingface |Same as above |Model draft: false
id: huggingface-spc-xlm-mlm-xnli15-1024
|374. |Sentence Pair Classification |Huggingface |Same as above |Model draft: false
id: huggingface-spc-xlm-mlm-tlm-xnli15-1024
|375. |Sentence Pair Classification |Huggingface |Same as above |Model draft: false
id: huggingface-spc-xlm-clm-ende-1024
|376. |Text Summarization |Huggingface |This is a Text Summarization model built upon a Transformer model from Hugging Face It takes a text string as input and returns a summary of the text |Model draft: false
id: huggingface-summarization-bigbird-pegasus-large-arxiv
|377. |Text Summarization |Huggingface |Same as above |Model draft: false
id: huggingface-summarization-bigbird-pegasus-large-pubmed
|378. |Text Embedding |Tensorflow |This is a Text Embedding model from TensorFlow Hub It takes a text string as input and outputs an embedding vector The Text Embedding model is pre-trained on Wikipedia and BookCorpus datasets |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-4-H-512-A-8-2
|379. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-4-H-768-A-12-2
|380. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-6-H-128-A-2-2
|381. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-6-H-256-A-4
|382. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-6-H-512-A-8-2
|383. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-6-H-768-A-12-2
|384. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-8-H-256-A-4-2
|385. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-8-H-512-A-8-2
|386. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-8-H-768-A-12-2
|387. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-10-H-128-A-2-2
|388. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-10-H-256-A-4-2
|389. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-10-H-512-A-8-2
|390. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-10-H-768-A-12-2
|391. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-12-H-128-A-2-2
|392. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-12-H-256-A-4
|393. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-12-H-512-A-8-2
|394. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-12-H-768-A-12-2
|395. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-en-uncased-L-12-H-768-A-12-4
|396. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-wiki-books-sst2
|397. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-bert-wiki-books-mnli-2
|398. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-universal-sentence-encoder-cmlm-en-large-1
|399. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-universal-sentence-encoder-cmlm-en-base-1
|400. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-talkheads-ggelu-bert-en-base-2
|401. |Text Embedding |Tensorflow |Same as above |Model draft: false
id: tensorflow-tcembedding-talkheads-ggelu-bert-en-large-2
|402. |Tabular Classification | |This is the LightGBM algorithm for tabular classification task LightGBM is a gradient boosting framework that uses tree based learning algorithms |Model draft: false
id: lightgbm-classification-model
|403. |Tabular Classification |Catboost |This is the CatBoost algorithm for tabular classification task CatBoost is a machine learning algorithm that uses gradient boosting on decision trees |Model draft: false
id: catboost-classification-model
|404. |Tabular Classification | |This is the AutoGluon-Tabular algorithm for tabular classification task AutoGluon-Tabular is an open-source AutoML framework that trains highly accurate machine learning models on an unprocessed tabular dataset Unlike existing AutoML frameworks that primarily focus on model/hyperparameter selection, AutoGluon-Tabular succeeds by ensembling multiple models and stacking them in multiple layers |Model draft: false
id: autogluon-classification-ensemble
|405. |Tabular Classification | |This is the TabTransformer algorithm for tabular classification task TabTransformer is a deep tabular data modeling architecture that built upon self-attention based Transformers |Model draft: false
id: pytorch-tabtransformerclassification-model
|406. |Tabular Classification |Sklearn |This is the scikit-learn linear algorithm for tabular classification task Linear Classification is a linear approach to classify data into labels (targets) based on a linear combination of its input features (predictors) |Model draft: false
id: sklearn-classification-linear
|407. |Tabular Classification |Xgboost |This is the XGBoost algorithm for tabular classification task XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable It implements machine learning algorithms under the Gradient Boosting framework |Model draft: false
id: xgboost-classification-model
|408. |Tabular Regression | |This is the LightGBM algorithm for tabular regression task LightGBM is a gradient boosting framework that uses tree based learning algorithms |Model draft: false
id: lightgbm-regression-model
|409. |Tabular Regression |Catboost |This is the CatBoost algorithm for tabular regression task CatBoost is a machine learning algorithm that uses gradient boosting on decision trees |Model draft: false
id: catboost-regression-model
|410. |Tabular Regression | |This is the AutoGluon-Tabular algorithm for tabular regression task AutoGluon-Tabular is an open-source AutoML framework that trains highly accurate machine learning models on an unprocessed tabular dataset Unlike existing AutoML frameworks that primarily focus on model/hyperparameter selection, AutoGluon-Tabular succeeds by ensembling multiple models and stacking them in multiple layers |Model draft: false
id: autogluon-regression-ensemble
|411. |Tabular Regression | |This is the TabTransformer algorithm for tabular regression task TabTransformer is a deep tabular data modeling architecture that built upon self-attention based Transformers |Model draft: false
id: pytorch-tabtransformerregression-model
|412. |Tabular Regression |Sklearn |This is the scikit-learn linear algorithm for tabular regression task Linear Regression is a linear approach for modelling the relationship between a scalar response and one or more explanatory variables |Model draft: false
id: sklearn-regression-linear
|413. |Tabular Regression |Xgboost |This is the XGBoost algorithm for tabular regression task XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable It implements machine learning algorithms under the Gradient Boosting framework |Model draft: false
id: xgboost-regression-model
|414. |Question Answering |Pytorch |This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question |Model draft: false
id: pytorch-eqa-distilbert-base-uncased
|415. |Question Answering |Pytorch |Same as above |Model draft: false
id: pytorch-eqa-bert-large-uncased-whole-word-masking
|416. |Question Answering |Pytorch |Same as above |Model draft: false
id: pytorch-eqa-bert-large-uncased
|417. |Question Answering |Pytorch |Same as above |Model draft: false
id: pytorch-eqa-bert-large-cased
|418. |Question Answering |Pytorch |Same as above |Model draft: false
id: pytorch-eqa-roberta-base
|419. |Question Answering |Pytorch |Same as above |Model draft: false
id: pytorch-eqa-distilbert-base-multilingual-cased
|420. |Object detection |SageMaker |Identify birds species in a scene using a SageMaker object detection model. |
|421. |Question Answering |Pytorch |This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question |Model draft: false
id: pytorch-eqa-distilroberta-base
|422. |Audio Embedding |Tensorflow |This is an audio embedding model from Tensorflow Hub It takes a wav (audio file format) file as input and outputs an embedding vector |Model draft: false
id: tensorflow-audioembedding-trill-distilled-3
|423. |Question Answering |Pytorch |This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question |Model draft: false
id: pytorch-eqa-roberta-large-openai-detector
|424. |Object detection |SageMaker |Identify defective regions in product images either by training an object detection model from scratch or fine-tuning pretrained SageMaker models. |
|425. |Audio Embedding |Tensorflow |This is an audio embedding model from Tensorflow Hub It takes a wav (audio file format) file as input and outputs an embedding vector |Model draft: false
id: tensorflow-audioembedding-trillsson2-1
|426. |Tabular classification |SageMaker |Automatically detect potentially fraudulent activity in transactions using SageMaker XGBoost with the over-sampling technique Synthetic Minority Over-sampling (SMOTE). |
|427. |Feature importance using shap |SageMaker | |
|428. |Question Answering |Pytorch |This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question |Model draft: false
id: pytorch-eqa-distilbert-base-cased
|429. |Graph neural network classification |SageMaker |Detect fraud in financial transactions by training a graph convolutional network with the deep graph library and a SageMaker XGBoost model. |
|430. |Tabular classification |SageMaker |Classify financial payments based on transaction information using SageMaker XGBoost. Use this solution template as an intermediate step in fraud detection, personalization, or anomaly detection. |
|431. |Tabular classification |SageMaker |Identify unhappy mobile phone customers using SageMaker XGBoost. |
|432. |Question Answering |Pytorch |This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question |Model draft: false
id: pytorch-eqa-bert-base-cased
|433. |RL |SageMaker |Distributed reinforcement learning starter kit for NeurIPS 2020 Procgen Reinforcement learning challenge. |
|434. |Question Answering |Pytorch |This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question |Model draft: false
id: pytorch-eqa-bert-large-cased-whole-word-masking-finetuned-squad
|435. |Tabular classification |SageMaker | |
|436. |RL |SageMaker | |
|437. |Entity resolution |SageMaker | |
|438. |Tabular classification |SageMaker | |
|439. |Tabular and text classification |SageMaker | |
|440. |Text classification |SageMaker |Anonymize text to better preserve user privacy in sentiment classification. |
|441. |Tabular, image, and text classification. |SageMaker | |
|442. |Tabular classification |SageMaker | |
|443. |Text to Image |Stabilityai |This is a text-to-image model from Stability AI and downloaded from HuggingFace It takes a textual description as input and returns a generated image from the description |Model draft: false
id: model-txt2img-stabilityai-stable-diffusion-v2-fp16
|444. |Text to Image |Stabilityai |Same |Model draft: false
id: model-txt2img-stabilityai-stable-diffusion-v1-4-fp16
|445. |ext to Image |Stabilityai |Same |Model draft: false
id: model-txt2img-stabilityai-stable-diffusion-v1-4
|446. |Question Answering |Pytorch |This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question |Model draft: false
id: pytorch-eqa-bert-base-multilingual-cased
|447. |Question Answering |Pytorch |This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question |Model draft: false
id: pytorch-eqa-roberta-large
|448. |Audio Embedding |Tensorflow |This is an audio embedding model from Tensorflow Hub It takes a wav (audio file format) file as input and outputs an embedding vector |Model draft: false
id: tensorflow-audioembedding-frill-1
|449. |Audio Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-audioembedding-trillsson3-1
|450. |Audio Embedding |Tensorflow |Same |Model draft: false
id: tensorflow-audioembedding-trill-3
|451. |Tabular and text classification |SageMaker | |
|452. |Question Answering |Pytorch |This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question |Model draft: false
id: pytorch-eqa-roberta-base-openai-detector
|453. |Question Answering |Pytorch |Same |Model draft: false
id: pytorch-eqa-bert-large-cased-whole-word-masking
|454. |Time series |SageMaker |Demand forecasting for multivariate time series data using three state-of-the-art time series forecasting algorithms: LSTNet, Prophet, and SageMaker DeepAR. |
|455. |Question Answering |Pytorch |This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question |Model draft: false
id: pytorch-eqa-bert-large-uncased-whole-word-masking-finetuned-squad
|456. |Question Answering |Pytorch |Same |Model draft: false
id: pytorch-eqa-bert-base-multilingual-uncased
|457. |Question Answering |Pytorch |Same |Model draft: false
id: pytorch-eqa-bert-base-uncased
|458. |Audio Embedding |Tensorflow |This is an audio embedding model from Tensorflow Hub It takes a wav (audio file format) file as input and outputs an embedding vector |Model draft: false
id: tensorflow-audioembedding-trillsson1-1
|459. |Object detection |SageMaker | |
|460. |Causal inference |SageMaker |Generate a counterfactual analysis of corn response to nitrogen. This solution learns the crop phenology cycle in its entirety using multi-spectral satellite imagery and ground-level observations. |
|461. |Price optimization |SageMaker |Estimate price elasticity using Double Machine Learning (ML) for causal inference and the Prophet forecasting procedure. Use these estimates to optimize daily prices. |
|462. |Tabular and text classification |SageMaker | |
|463. |Upscaling |Stabilityai |This is a upscaling model from Stability AI downloaded from HuggingFace with FP16 precision Given a low resolution image and a textual prompt, it generates a higher resolution image with size up to four times the original image size |Model draft: false
id: model-upscaling-stabilityai-stable-diffusion-x4-upscaler-fp16&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Embedding with FastText</title>
      <link>http://localhost:1313/dsblog/Embedding-with-FastText/</link>
      <pubDate>Sat, 15 Jul 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Embedding-with-FastText/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6073-Embedding-with-FastText.jpg&#34; alt=&#34;Embedding with FastText&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Embedding with FastText 
    &lt;div id=&#34;embedding-with-fasttext&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#embedding-with-fasttext&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;../../../dsblog/what-is-nlp#what-is-embedding&#34;&gt;What is Embedding?&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;../../../dsblog/what-is-nlp#what-are-different-embedding-types&#34;&gt;What are Different Types of Embedding&lt;/a&gt;&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What is FastText? 
    &lt;div id=&#34;what-is-fasttext&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-fasttext&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;FastText is an open-source library for efficient learning of word representations and sentence classification developed by Facebook AI Research. It is designed to handle large-scale text data and provides tools for &lt;strong&gt;training&lt;/strong&gt; and &lt;strong&gt;using word embeddings&lt;/strong&gt;.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>What is GAN Architecture?</title>
      <link>http://localhost:1313/dsblog/What-is-GAN-Architecture/</link>
      <pubDate>Mon, 03 Jul 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/What-is-GAN-Architecture/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6069-What-is-GAN-Architecture.jpg&#34; alt=&#34;What is GAN Architecture?&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;What is GAN Architecture? 
    &lt;div id=&#34;what-is-gan-architecture&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-gan-architecture&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;Generative Adversarial Networks (GANs) are a powerful class of neural networks that are used for unsupervised learning. It was developed and introduced by Ian J. Goodfellow in 2014. It is a type of artificial intelligence (AI) model that consists of two neural networks: a generator and a discriminator. GANs are used for generative tasks, such as creating realistic images, videos, or even audio.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>A Guide to Model Fine Tuning with OpenAI API</title>
      <link>http://localhost:1313/dsblog/Model-Fine-Tuning-with-OpenAI-API/</link>
      <pubDate>Sun, 02 Jul 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Model-Fine-Tuning-with-OpenAI-API/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6068-A-Guide-to-Model-Fine-Tuning-with-OpenAI-API.jpg&#34; alt=&#34;A Guide to Model Fine Tuning with OpenAI API&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;A Guide to Model Fine Tuning with OpenAI API 
    &lt;div id=&#34;a-guide-to-model-fine-tuning-with-openai-api&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#a-guide-to-model-fine-tuning-with-openai-api&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Account Setup and API Key Generation 
    &lt;div id=&#34;account-setup-and-api-key-generation&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#account-setup-and-api-key-generation&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Go to &lt;a href=&#34;https://platform.openai.com/&#34; target=&#34;_blank&#34;&gt;openai&lt;/a&gt;, sign up there and create your account. After than you need to create an API using &lt;a href=&#34;https://platform.openai.com/account/api-keys&#34; target=&#34;_blank&#34;&gt;API Key Link&lt;/a&gt;. You need to copy the api key and you replace the text below &amp;lt;OPENAI_API_KEY&amp;gt;. Being string the key should be within &amp;ldquo;&amp;rdquo;. Keeping security in mind it is highly recommended that you do not put the API in the code file. Keep it at some secured place and read that file to fetch the API key. OpenAI gives you USD 5 free usage. After that you need to pay. For that you need to setup your credit card details on their system. They are very fair on the charges, just keep track of your usage. If you don&amp;rsquo;t use any of their service they won&amp;rsquo;t charge anything for just having account with them. While doing any model finetuning or prediction openai tells you how much they will charge you for that particular command. My suggestion is if you are just experimenting then keep your dataset small so that you can manage your learning with USD 10-20.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Capabilities of AI Transformers</title>
      <link>http://localhost:1313/dsblog/Capabilities-of-AI-Transformers/</link>
      <pubDate>Sat, 01 Jul 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Capabilities-of-AI-Transformers/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6067-Capabilities-of-AI-Transformers.jpg&#34; alt=&#34;Capabilities of AI Transformers&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Capabilities of AI Transformers 
    &lt;div id=&#34;capabilities-of-ai-transformers&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#capabilities-of-ai-transformers&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Background 
    &lt;div id=&#34;background&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#background&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Whether GPT, ChatGPT, DALL-E, Whisper, Satablity AI or whatever significant you see in the AI worlds nowdays it is because of Transformer Architecture. Transformers are a type of neural network architecture that have several properties that make them effective for modeling data with long-range dependencies. They generally feature a combination of multi-headed attention mechanisms, residual connections, layer normalization, feedforward connections, and positional embeddings.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Model Garden of VertexAI</title>
      <link>http://localhost:1313/dsblog/Model-Garden-of-VertexAI/</link>
      <pubDate>Wed, 21 Jun 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Model-Garden-of-VertexAI/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6065-Model-Garden-of-VertexAI.jpg&#34; alt=&#34;All Resources to Learn Data Science&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Model Garden of VertexAI: 
    &lt;div id=&#34;model-garden-of-vertexai&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#model-garden-of-vertexai&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Unlocking the Power of Google&amp;rsquo;s VertexAI: Exploring the World of Pre-Built Models for AI Tasks 
    &lt;div id=&#34;unlocking-the-power-of-googles-vertexai-exploring-the-world-of-pre-built-models-for-ai-tasks&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#unlocking-the-power-of-googles-vertexai-exploring-the-world-of-pre-built-models-for-ai-tasks&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Introduction: 
    &lt;div id=&#34;introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Artificial Intelligence (AI) has transformed numerous industries, from healthcare and finance to e-commerce, logistic, eduction and entertainment. But the complexity of developing machine learning models often poses a challenge. As the demand for AI-powered solutions continues to rise, data scientists seek efficient ways to leverage pre-trained models or build custom models to address specific tasks. In this regard, Google&amp;rsquo;s VertexAI emerges as a robust platform that offers an extensive selection of pre-built models for a wide range of AI tasks. VertexAI platform has revolutionized the landscape by seamlessly leveraging LLM (Large Language Models) and Prompt Engineering techniques to perform complex machine learning tasks effortlessly. With VertexAI, data scientists can harness the power of state-of-the-art language models, such as LLM, to accelerate their ML development process. Additionally, the innovative concept of Prompt Engineering enables users to effectively communicate with the models, guiding them to deliver precise and accurate results. From computer vision and natural language processing to speech processing and structured tabular data analysis, Vertex AI&amp;rsquo;s repertoire includes over 100 models catering to diverse application domains. This article explores how Vertex AI, through its integration of LLM and Prompt Engineering, empowers users to effortlessly tackle intricate machine learning tasks across diverse domains, revolutionizing the AI development experience.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Types of Machine Learning</title>
      <link>http://localhost:1313/dsblog/Types-of-Machine-Learning/</link>
      <pubDate>Thu, 27 Apr 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Types-of-Machine-Learning/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6056-Types-of-Machine-Learning.jpg&#34; alt=&#34;Types of Machine Learning&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Types of Machine Learning 
    &lt;div id=&#34;types-of-machine-learning&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#types-of-machine-learning&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Introduction 
    &lt;div id=&#34;introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Machine learning is a field of artificial intelligence that focuses on developing algorithms that can learn from data and make predictions or decisions. There are several types of machine learning techniques, each with its strengths and weaknesses. In this post, we will explore some of the most commonly used machine learning techniques, including supervised learning, unsupervised learning, reinforcement learning, and more. This post is not about deep diving into these topics but to give you a oneliner understanding and the difference between these different techniques.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Introduction to Neural Network</title>
      <link>http://localhost:1313/dsblog/Introduction-to-Neural-Network/</link>
      <pubDate>Tue, 17 Jan 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Introduction-to-Neural-Network/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6034-Introduction-to-Neural-Network.jpg&#34; alt=&#34;Introduction to Neural Network&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Introduction to Neural Network 
    &lt;div id=&#34;introduction-to-neural-network&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction-to-neural-network&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Introduction to a Perceptron 
    &lt;div id=&#34;introduction-to-a-perceptron&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction-to-a-perceptron&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;A perceptron is a type of artificial neural network that can be used for binary classification. It is a simple model that consists of a single layer of artificial neurons and is used to classify input data into one of two categories. The perceptron algorithm learns the weights of the artificial neurons by adjusting them based on the input data and the desired output. The perceptron is considered a basic building block for more complex neural networks.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>What is GAN?</title>
      <link>http://localhost:1313/dsblog/What-is-GAN/</link>
      <pubDate>Tue, 17 Jan 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/What-is-GAN/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6043-gan.jpg&#34; alt=&#34;Partial Dependence Plots&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;What is GAN? 
    &lt;div id=&#34;what-is-gan&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-gan&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What is GAN (Generative Adversarial Network)? 
    &lt;div id=&#34;what-is-gan-generative-adversarial-network&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-gan-generative-adversarial-network&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Generative adversarial networks (GANs) are besing used to generate images, videos, text, audio and music. GAN is a class of machine-learning models introduced by Ian Goodfellow and his colleagues in 2014. The GANs became popular among researchers quickly because of their property to generate new data with the same statistics as the input training set. It can be applied to images, videos, textual data, tabular data and more, proving useful for semi-supervised, fully supervised, and reinforcement learning.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Linear Regression Interview Questions</title>
      <link>http://localhost:1313/dsblog/Linear-Regression-Interview-Questions/</link>
      <pubDate>Sat, 07 Jan 2023 15:50:00 +0530</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Linear-Regression-Interview-Questions/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6022-Linear-Regression-Interview-Questions.jpg&#34; alt=&#34;Prompt Engineering for GPT4&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Linear Regression Interview Questions and Answers 
    &lt;div id=&#34;linear-regression-interview-questions-and-answers&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#linear-regression-interview-questions-and-answers&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;In this question-answer article, I will try that the start of every answer from example rather than theory (some unavoidable variation may be possible). I firmly believe if examples are clear, human mind is smart enough in generlization and creating theories.&lt;/p&gt;&lt;/blockquote&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Question 1: What is linear regression? What is the difference between simple linear regression and multiple linear regression? 
    &lt;div id=&#34;question-1-what-is-linear-regression-what-is-the-difference-between-simple-linear-regression-and-multiple-linear-regression&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#question-1-what-is-linear-regression-what-is-the-difference-between-simple-linear-regression-and-multiple-linear-regression&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Linear regression is a statistical method used to model the linear relationship between a dependent variable and one or more independent variables. It is used to predict the value of the dependent variable based on the values of the independent variables.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Generalized AI Model for Prediction</title>
      <link>http://localhost:1313/dsblog/Generalized-AI-Model-for-Prediction/</link>
      <pubDate>Fri, 17 Sep 2021 15:50:00 +0530</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Generalized-AI-Model-for-Prediction/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6009-Generalized-AI-Model-for-Prediction.jpg&#34; alt=&#34;Generalized AI Model for Prediction&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Can we really Develop AI solutions that can predict human behavior? If you are not a technical person then don’t get overwhelmed by the next paragraph, you can read further, and it will make sense to you.&lt;/p&gt;
&lt;p&gt;We know the basic equation, y = mx + c. This comes from algebra and trigonometry. Here, y is the predicted value, and x is the input. The x can be a simple scalar value or a vector. Similarly, m is the coefficient in this equation, and it can be a simple scalar value or a vector. If m or x is a vector, then it can hold multiple values. The value of m corresponding to x is also called slope in trigonometry. If a plane is 2 dimensional, then you have one m and one x. But if a plane is complex, and it has, let us say, 10 dimensions then it has 9 m and 9 x. 10th dimensions is predicted by these 9 m and 9 x, using the earlier formula. How that multiplication happens is easy for those who know vector and matrix multiplication, but for others, it is really complicated. So, you can leave it for the time being.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>What Are Transformers in AI</title>
      <link>http://localhost:1313/dsblog/What-Are-Transformers-in-AI/</link>
      <pubDate>Tue, 03 Aug 2021 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/What-Are-Transformers-in-AI/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6031-What-are-Transformers-in-AI.jpg&#34; alt=&#34;What-are-Transformers-in-AI&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;What Are Transformers in AI 
    &lt;div id=&#34;what-are-transformers-in-ai&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-are-transformers-in-ai&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Transformer Architecture 
    &lt;div id=&#34;transformer-architecture&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#transformer-architecture&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/transformer/transformer-arch.jpg&#34; alt=&#34;Transformer&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Background 
    &lt;div id=&#34;background&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#background&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Whether GPT, ChatGPT, DALL-E, Whisper, Satablity AI or whatever significant you see in the AI worlds nowdays it is because of Transformer Architecture. Transformers are a type of neural network architecture that have several properties that make them effective for modeling data with long-range dependencies. They generally feature a combination of multi-headed attention mechanisms, residual connections, layer normalization, feedforward connections, and positional embeddings.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>How Naive Bayes Classifier Works</title>
      <link>http://localhost:1313/dsblog/How-Naive-Bayes-Classifier-Works/</link>
      <pubDate>Wed, 31 Mar 2021 15:50:00 +0530</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/How-Naive-Bayes-Classifier-Works/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6005-How-Naive-Bayes-Work-for-Recommendation.jpg&#34; alt=&#34;Naive Bayes&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;How Naive Bayes Classifier Works? 
    &lt;div id=&#34;how-naive-bayes-classifier-works&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#how-naive-bayes-classifier-works&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Naive Bayes classifier example 
    &lt;div id=&#34;naive-bayes-classifier-example&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#naive-bayes-classifier-example&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;In this presentation, I am not going into the depth of the Naive Bayes algorithm. I am assuming you have heard this term many times but are not able to visualize it mentally or struggling to comprehend this. If that is the case, then you are on the right page.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>What is XAI?</title>
      <link>http://localhost:1313/dsblog/What-is-XAI/</link>
      <pubDate>Fri, 15 May 2020 15:50:00 +0530</pubDate>
      <author>hari@dasarpai.com (Dr. Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/What-is-XAI/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;../../../assets/images/dspost/dsp6003-XAI.jpg&#34; alt=&#34;XAI&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;What is XAI? 
    &lt;div id=&#34;what-is-xai&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-xai&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;XAI in Simple Language! 
    &lt;div id=&#34;xai-in-simple-language&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#xai-in-simple-language&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;The discipline of Data Science and AI has introduced many terms into discussions that might seem complicated at first. In reality, many of these terms are intuitive and straightforward when considered from a natural intelligence perspective. However, from a technological standpoint, they can be complex. To understand XAI, let’s explore a few examples.&lt;/p&gt;</description>
      
    </item>
    
  </channel>
</rss>
